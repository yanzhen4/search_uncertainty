2025-12-06 13:41:23,847 INFO    MainThread:56748 [wandb_setup.py:_flush():81] Current SDK version is 0.22.3
2025-12-06 13:41:23,847 INFO    MainThread:56748 [wandb_setup.py:_flush():81] Configure stats pid to 56748
2025-12-06 13:41:23,847 INFO    MainThread:56748 [wandb_setup.py:_flush():81] Loading settings from /Users/yanzhenshen/.config/wandb/settings
2025-12-06 13:41:23,847 INFO    MainThread:56748 [wandb_setup.py:_flush():81] Loading settings from /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/wandb/settings
2025-12-06 13:41:23,847 INFO    MainThread:56748 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-12-06 13:41:23,847 INFO    MainThread:56748 [wandb_init.py:setup_run_log_directory():706] Logging user logs to /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-13-41/wandb/run-20251206_134123-g7nlaeew/logs/debug.log
2025-12-06 13:41:23,848 INFO    MainThread:56748 [wandb_init.py:setup_run_log_directory():707] Logging internal logs to /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-13-41/wandb/run-20251206_134123-g7nlaeew/logs/debug-internal.log
2025-12-06 13:41:23,848 INFO    MainThread:56748 [wandb_init.py:init():833] calling init triggers
2025-12-06 13:41:23,848 INFO    MainThread:56748 [wandb_init.py:init():838] wandb.init called with sweep_config: {}
config: {'learning_rate': 4e-05, 'dataset_builder': {'batch_size': 4, 'group_size': 4, 'model_name_for_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507', 'renderer_name': 'qwen3_instruct', 'chroma_tool_config': {'chroma_host': 'localhost', 'chroma_port': 8000, 'chroma_collection_name': 'researchyqa_corpus', 'retrieval_config': {'n_results': 3, 'embedding_config': {'model_name': 'gemini-embedding-001', 'embedding_dim': 768, 'task_type': 'RETRIEVAL_QUERY'}}, 'max_retries': 10, 'initial_retry_delay': 1}, 'judge_model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'judge_model_path': 'tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final', 'judge_rubric': 'Consider the following aspects when evaluating the answer:\n\n1. **Factual Accuracy (Highest Priority)**: Is the information correct and verifiable against the reference answers?\n2. **Relevance**: Does the answer directly address the question asked?\n3. **Completeness**: Are all important aspects of the question covered adequately?\n4. **Use of Retrieved Context**: Does the answer appropriately incorporate information from the retrieved documents?\n5. **Clarity and Structure**: Is the answer well-organized, concise, and easy to understand?\n\nPrioritize factual accuracy and relevance. An answer that is factually correct but less eloquent \nshould score higher than a well-written but inaccurate answer.', 'convo_prefix': 'standard', 'seed': 42, 'max_eval_size': 1024, 'max_trajectory_tokens': 8192, 'quality_threshold': 0.6, 'questions_path': 'CS329x_Final/ResearchyQA_Large/ResearchyQA_questions_500.jsonl'}, 'model_name': 'Qwen/Qwen3-4B-Instruct-2507', 'max_tokens': 1024, 'compute_post_kl': False, 'evaluator_builders': [], 'lora_rank': 32, 'kl_penalty_coef': 0.0, 'kl_discount_factor': 0.0, 'loss_fn': 'importance_sampling', 'num_substeps': 1, 'wandb_project': 'researchyqa-llm-judge', 'wandb_name': 'researchyqa_large_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-5_rank32_2025-12-06-13-41', 'log_path': '/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-13-41', 'base_url': None, 'enable_trace': False, 'remove_constant_reward_groups': False, 'eval_every': 0, 'save_every': 20, 'load_checkpoint_path': None, 'async_config': None, 'stream_minibatch_config': None, 'num_groups_to_log': 4, '_wandb': {}}
2025-12-06 13:41:23,848 INFO    MainThread:56748 [wandb_init.py:init():881] starting backend
2025-12-06 13:41:24,064 INFO    MainThread:56748 [wandb_init.py:init():884] sending inform_init request
2025-12-06 13:41:24,089 INFO    MainThread:56748 [wandb_init.py:init():892] backend started and connected
2025-12-06 13:41:24,091 INFO    MainThread:56748 [wandb_init.py:init():962] updated telemetry
2025-12-06 13:41:24,107 INFO    MainThread:56748 [wandb_init.py:init():986] communicating run to backend with 90.0 second timeout
2025-12-06 13:41:24,514 INFO    MainThread:56748 [wandb_init.py:init():1033] starting run threads in backend
2025-12-06 13:41:24,602 INFO    MainThread:56748 [wandb_run.py:_console_start():2506] atexit reg
2025-12-06 13:41:24,602 INFO    MainThread:56748 [wandb_run.py:_redirect():2354] redirect: wrap_raw
2025-12-06 13:41:24,602 INFO    MainThread:56748 [wandb_run.py:_redirect():2423] Wrapping output streams.
2025-12-06 13:41:24,602 INFO    MainThread:56748 [wandb_run.py:_redirect():2446] Redirects installed.
2025-12-06 13:41:24,604 INFO    MainThread:56748 [wandb_init.py:init():1073] run started, returning control to user process
2025-12-06 13:41:24,653 INFO    MainThread:56748 [wandb_run.py:_config_callback():1390] config_cb None None {'learning_rate': 4e-05, 'dataset_builder': {'batch_size': 4, 'group_size': 4, 'model_name_for_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507', 'renderer_name': 'qwen3_instruct', 'chroma_tool_config': {'chroma_host': 'localhost', 'chroma_port': 8000, 'chroma_collection_name': 'researchyqa_corpus', 'retrieval_config': {'n_results': 3, 'embedding_config': {'model_name': 'gemini-embedding-001', 'embedding_dim': 768, 'task_type': 'RETRIEVAL_QUERY'}}, 'max_retries': 10, 'initial_retry_delay': 1}, 'judge_model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'judge_model_path': 'tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final', 'judge_rubric': 'Consider the following aspects when evaluating the answer:\n\n1. **Factual Accuracy (Highest Priority)**: Is the information correct and verifiable against the reference answers?\n2. **Relevance**: Does the answer directly address the question asked?\n3. **Completeness**: Are all important aspects of the question covered adequately?\n4. **Use of Retrieved Context**: Does the answer appropriately incorporate information from the retrieved documents?\n5. **Clarity and Structure**: Is the answer well-organized, concise, and easy to understand?\n\nPrioritize factual accuracy and relevance. An answer that is factually correct but less eloquent \nshould score higher than a well-written but inaccurate answer.', 'convo_prefix': 'standard', 'seed': 42, 'max_eval_size': 1024, 'max_trajectory_tokens': 8192, 'quality_threshold': 0.6, 'questions_path': 'CS329x_Final/ResearchyQA_Large/ResearchyQA_questions_500.jsonl'}, 'model_name': 'Qwen/Qwen3-4B-Instruct-2507', 'max_tokens': 1024, 'compute_post_kl': False, 'evaluator_builders': [], 'lora_rank': 32, 'kl_penalty_coef': 0.0, 'kl_discount_factor': 0.0, 'loss_fn': 'importance_sampling', 'num_substeps': 1, 'wandb_project': 'researchyqa-llm-judge', 'wandb_name': 'researchyqa_large_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-5_rank32_2025-12-06-13-41', 'log_path': '/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-13-41', 'base_url': None, 'enable_trace': False, 'remove_constant_reward_groups': False, 'eval_every': 0, 'save_every': 20, 'load_checkpoint_path': None, 'async_config': None, 'stream_minibatch_config': None, 'num_groups_to_log': 4}
2025-12-06 14:53:27,786 INFO    wandb-AsyncioManager-main:56748 [service_client.py:_forward_responses():80] Reached EOF.
2025-12-06 14:53:27,786 INFO    wandb-AsyncioManager-main:56748 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
