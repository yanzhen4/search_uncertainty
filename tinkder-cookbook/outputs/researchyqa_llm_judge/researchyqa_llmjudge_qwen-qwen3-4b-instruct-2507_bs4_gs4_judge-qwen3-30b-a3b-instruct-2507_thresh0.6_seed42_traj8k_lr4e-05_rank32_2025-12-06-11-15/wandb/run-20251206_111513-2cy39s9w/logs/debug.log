2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_setup.py:_flush():81] Current SDK version is 0.22.3
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_setup.py:_flush():81] Configure stats pid to 45560
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_setup.py:_flush():81] Loading settings from /Users/yanzhenshen/.config/wandb/settings
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_setup.py:_flush():81] Loading settings from /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/wandb/settings
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_init.py:setup_run_log_directory():706] Logging user logs to /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-11-15/wandb/run-20251206_111513-2cy39s9w/logs/debug.log
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_init.py:setup_run_log_directory():707] Logging internal logs to /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-11-15/wandb/run-20251206_111513-2cy39s9w/logs/debug-internal.log
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_init.py:init():833] calling init triggers
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_init.py:init():838] wandb.init called with sweep_config: {}
config: {'learning_rate': 4e-05, 'dataset_builder': {'batch_size': 4, 'group_size': 4, 'model_name_for_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507', 'renderer_name': 'qwen3_instruct', 'chroma_tool_config': {'chroma_host': 'localhost', 'chroma_port': 8000, 'chroma_collection_name': 'researchyqa_corpus', 'retrieval_config': {'n_results': 3, 'embedding_config': {'model_name': 'gemini-embedding-001', 'embedding_dim': 768, 'task_type': 'RETRIEVAL_QUERY'}}, 'max_retries': 10, 'initial_retry_delay': 1}, 'judge_model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'judge_model_path': 'tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final', 'judge_rubric': 'Consider the following aspects when evaluating the answer: 1. **Factual Accuracy (Highest Priority)**: Is the information correct and verifiable against the reference answers? 2. **Relevance**: Does the answer directly address the question asked? 3. **Completeness**: Are all important aspects of the question covered adequately? 4. **Use of Retrieved Context**: Does the answer appropriately incorporate information from the retrieved documents? 5. **Clarity and Structure**: Is the answer well-organized, concise, and easy to understand? Prioritize factual accuracy and relevance. An answer that is factually correct but less eloquent should score higher than a well-written but inaccurate answer.', 'convo_prefix': 'standard', 'seed': 42, 'max_eval_size': 1024, 'max_trajectory_tokens': 8192, 'quality_threshold': 0.6, 'questions_path': 'CS329x_Final/ResearchyQA/ResearchyQA_questions_with_answers_100.jsonl'}, 'model_name': 'Qwen/Qwen3-4B-Instruct-2507', 'max_tokens': 1024, 'compute_post_kl': False, 'evaluator_builders': [], 'lora_rank': 32, 'kl_penalty_coef': 0.0, 'kl_discount_factor': 0.0, 'loss_fn': 'importance_sampling', 'num_substeps': 1, 'wandb_project': 'researchyqa-llm-judge', 'wandb_name': 'researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-11-15', 'log_path': '/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-11-15', 'base_url': None, 'enable_trace': False, 'remove_constant_reward_groups': False, 'eval_every': 0, 'save_every': 20, 'load_checkpoint_path': None, 'async_config': None, 'stream_minibatch_config': None, 'num_groups_to_log': 4, '_wandb': {}}
2025-12-06 11:15:13,519 INFO    MainThread:45560 [wandb_init.py:init():881] starting backend
2025-12-06 11:15:13,742 INFO    MainThread:45560 [wandb_init.py:init():884] sending inform_init request
2025-12-06 11:15:13,766 INFO    MainThread:45560 [wandb_init.py:init():892] backend started and connected
2025-12-06 11:15:13,768 INFO    MainThread:45560 [wandb_init.py:init():962] updated telemetry
2025-12-06 11:15:13,785 INFO    MainThread:45560 [wandb_init.py:init():986] communicating run to backend with 90.0 second timeout
2025-12-06 11:15:14,280 INFO    MainThread:45560 [wandb_init.py:init():1033] starting run threads in backend
2025-12-06 11:15:14,368 INFO    MainThread:45560 [wandb_run.py:_console_start():2506] atexit reg
2025-12-06 11:15:14,368 INFO    MainThread:45560 [wandb_run.py:_redirect():2354] redirect: wrap_raw
2025-12-06 11:15:14,368 INFO    MainThread:45560 [wandb_run.py:_redirect():2423] Wrapping output streams.
2025-12-06 11:15:14,368 INFO    MainThread:45560 [wandb_run.py:_redirect():2446] Redirects installed.
2025-12-06 11:15:14,370 INFO    MainThread:45560 [wandb_init.py:init():1073] run started, returning control to user process
2025-12-06 11:15:14,418 INFO    MainThread:45560 [wandb_run.py:_config_callback():1390] config_cb None None {'learning_rate': 4e-05, 'dataset_builder': {'batch_size': 4, 'group_size': 4, 'model_name_for_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507', 'renderer_name': 'qwen3_instruct', 'chroma_tool_config': {'chroma_host': 'localhost', 'chroma_port': 8000, 'chroma_collection_name': 'researchyqa_corpus', 'retrieval_config': {'n_results': 3, 'embedding_config': {'model_name': 'gemini-embedding-001', 'embedding_dim': 768, 'task_type': 'RETRIEVAL_QUERY'}}, 'max_retries': 10, 'initial_retry_delay': 1}, 'judge_model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'judge_model_path': 'tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final', 'judge_rubric': 'Consider the following aspects when evaluating the answer: 1. **Factual Accuracy (Highest Priority)**: Is the information correct and verifiable against the reference answers? 2. **Relevance**: Does the answer directly address the question asked? 3. **Completeness**: Are all important aspects of the question covered adequately? 4. **Use of Retrieved Context**: Does the answer appropriately incorporate information from the retrieved documents? 5. **Clarity and Structure**: Is the answer well-organized, concise, and easy to understand? Prioritize factual accuracy and relevance. An answer that is factually correct but less eloquent should score higher than a well-written but inaccurate answer.', 'convo_prefix': 'standard', 'seed': 42, 'max_eval_size': 1024, 'max_trajectory_tokens': 8192, 'quality_threshold': 0.6, 'questions_path': 'CS329x_Final/ResearchyQA/ResearchyQA_questions_with_answers_100.jsonl'}, 'model_name': 'Qwen/Qwen3-4B-Instruct-2507', 'max_tokens': 1024, 'compute_post_kl': False, 'evaluator_builders': [], 'lora_rank': 32, 'kl_penalty_coef': 0.0, 'kl_discount_factor': 0.0, 'loss_fn': 'importance_sampling', 'num_substeps': 1, 'wandb_project': 'researchyqa-llm-judge', 'wandb_name': 'researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-11-15', 'log_path': '/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-06-11-15', 'base_url': None, 'enable_trace': False, 'remove_constant_reward_groups': False, 'eval_every': 0, 'save_every': 20, 'load_checkpoint_path': None, 'async_config': None, 'stream_minibatch_config': None, 'num_groups_to_log': 4}
2025-12-06 11:26:15,473 INFO    MainThread:45560 [wandb_run.py:_finish():2272] finishing run yanzhen4_stanford-stanford-university/researchyqa-llm-judge/2cy39s9w
2025-12-06 11:26:15,474 INFO    MainThread:45560 [wandb_run.py:_atexit_cleanup():2471] got exitcode: 0
2025-12-06 11:26:15,474 INFO    MainThread:45560 [wandb_run.py:_restore():2453] restore
2025-12-06 11:26:15,475 INFO    MainThread:45560 [wandb_run.py:_restore():2459] restore done
2025-12-06 11:26:16,230 INFO    MainThread:45560 [wandb_run.py:_footer_sync_info():3835] logging synced files
