2025-12-07 21:22:21,209 INFO    MainThread:17752 [wandb_setup.py:_flush():81] Current SDK version is 0.22.3
2025-12-07 21:22:21,209 INFO    MainThread:17752 [wandb_setup.py:_flush():81] Configure stats pid to 17752
2025-12-07 21:22:21,209 INFO    MainThread:17752 [wandb_setup.py:_flush():81] Loading settings from /Users/yanzhenshen/.config/wandb/settings
2025-12-07 21:22:21,209 INFO    MainThread:17752 [wandb_setup.py:_flush():81] Loading settings from /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/wandb/settings
2025-12-07 21:22:21,209 INFO    MainThread:17752 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-12-07 21:22:21,210 INFO    MainThread:17752 [wandb_init.py:setup_run_log_directory():706] Logging user logs to /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-07-21-22/wandb/run-20251207_212221-n1hndhch/logs/debug.log
2025-12-07 21:22:21,210 INFO    MainThread:17752 [wandb_init.py:setup_run_log_directory():707] Logging internal logs to /Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-07-21-22/wandb/run-20251207_212221-n1hndhch/logs/debug-internal.log
2025-12-07 21:22:21,210 INFO    MainThread:17752 [wandb_init.py:init():833] calling init triggers
2025-12-07 21:22:21,210 INFO    MainThread:17752 [wandb_init.py:init():838] wandb.init called with sweep_config: {}
config: {'learning_rate': 4e-05, 'dataset_builder': {'batch_size': 4, 'group_size': 4, 'model_name_for_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507', 'renderer_name': 'qwen3_instruct', 'chroma_tool_config': {'chroma_host': 'localhost', 'chroma_port': 8000, 'chroma_collection_name': 'researchyqa_corpus', 'retrieval_config': {'n_results': 3, 'embedding_config': {'model_name': 'gemini-embedding-001', 'embedding_dim': 768, 'task_type': 'RETRIEVAL_QUERY'}}, 'max_retries': 10, 'initial_retry_delay': 1}, 'judge_model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'judge_model_path': 'tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final', 'judge_rubric': 'Evaluate the answer based on the following aspects:\n\n1. **Search Tool Usage & Strategy**: How effectively did the model use the search tool? High-quality responses demonstrate strategic search behavior:\n   - Multiple searches (typically 2-4) covering different aspects of the question\n   - Well-formulated queries that target specific information needs\n   - Follow-up searches that build upon initial results to fill gaps\n   - Appropriate search breadth for complex or multi-faceted questions\n\n2. **Document-Based Reasoning & Citation**: How well does the answer use and cite retrieved documents?\n   - Explicit document citations using numbered references (e.g., "According to Document 1...", "Document 2 indicates...")\n   - All claims are grounded in specific retrieved documents, not speculation\n   - Proper attribution showing which document supports each claim\n   - Synthesizes information from multiple documents with clear citations\n   - Does NOT make unsupported claims or add information not found in the retrieved documents\n\n3. **Balanced Perspective & Completeness**: For topics with multiple viewpoints:\n   - Acknowledges different perspectives from different documents (e.g., "Document 1 argues... while Document 3 contends...")\n   - Presents controversial topics fairly by citing multiple document sources\n   - Indicates when documents show debates or disagreements\n   - Addresses multiple aspects of complex questions using evidence from retrieved documents\n\nScoring guidance:\n- 0.8-1.0: Excellent search strategy, strong document-based reasoning with explicit citations (e.g., "Document 1", "Document 2"), balanced perspective\n- 0.6-0.7: Good search usage, mostly document-based with citations, generally balanced\n- 0.4-0.5: Adequate searches but weaker citation practice, some unsupported claims or vague references\n- 0.2-0.3: Limited search effectiveness, weak document grounding, missing or poor citations\n- 0.0-0.1: Poor quality, failed to cite documents properly, or made claims without document support', 'system_prompt': '\nYou are an expert research assistant who uses a Wikipedia search tool to find accurate, well-sourced information. You MUST base your answers on the retrieved documents and cite them properly.\n\nTool calling: Execute the tool by wrapping calls in <tool_call>...</tool_call>\n\nThe search tool you have access to:\n```\n{\n    "name": "search",\n    "title": "Wikipedia search",\n    "description": "Searches Wikipedia for relevant information based on the given query.",\n    "inputSchema": {\n        "type": "object",\n        "properties": {\n            "query_list": {\n                "type": "array",\n                "items": {"type": "string"},\n                "description": "A list of fully-formed semantic queries. The tool will return search results for each query.",\n            }\n        },\n        "required": ["query_list"],\n    },\n    "outputSchema": {\n        "type": "string",\n        "description": "The search results in JSON format",\n    },\n}\n```\n\nHow to approach research questions:\n\n1. **Plan your searches**: Think about what information you need. Formulate 1-3 initial search queries that target key aspects of the question.\n\n2. **Execute searches**: Call the search tool with your queries:\n   <tool_call>{"name": "search", "args": {"query_list": ["query1", "query2", ...]}}</tool_call>\n   \n   The tool will return numbered documents (Document 1, Document 2, Document 3, etc.) for each query.\n\n3. **Assess and iterate**: Review the results. Do you have enough information? If not, perform follow-up searches to fill gaps or explore different angles.\n\n4. **Consider multiple perspectives**: For complex or controversial topics (politics, ethics, debates), search for different viewpoints using queries like "arguments for X", "criticisms of X", "perspectives on X".\n\n5. **Answer ONLY based on retrieved documents**: Your answer MUST be grounded in the documents returned by the search tool. Do NOT make claims without document support.\n\n6. **Cite documents by number**: When referencing information, explicitly cite which document(s) you are using. Use formats like:\n   - "According to Document 1, ..."\n   - "Document 2 indicates that ..."\n   - "As stated in Document 3 and Document 5, ..."\n   - "Based on the information in Document 1, ..."\n\n7. **Present balanced views**: When documents present multiple perspectives, acknowledge them: "Document 1 argues... while Document 3 contends..." or "Documents 2 and 4 suggest... however, Document 5 points out...".\n\n8. **Format your answer**: Present your final answer after the "Answer:" prefix with proper document citations.\n\nExample workflow:\nQuestion: "Between 2020 and 2025, which year did New York City see the most population growth and how did San Francisco population change in that year?"\n\nThink: I need NYC and SF population data for 2020-2025.\n<tool_call>{"name": "search", "args": {"query_list": ["New York City population growth 2020-2025", "San Francisco population change 2020-2025"]}}</tool_call>\n\n[Tool returns: Document 1 with NYC data, Document 2 with SF data]\n\n(After results) Think: Document 1 shows NYC peak was 2024. Need more specific SF 2024 data.\n<tool_call>{"name": "search", "args": {"query_list": ["San Francisco population 2024"]}}</tool_call>\n\n[Tool returns: Document 3 with detailed SF 2024 data]\n\nAnswer: According to Document 1, New York City saw the most population growth in 2024 with an increase of [X]. Document 3 indicates that San Francisco\'s population changed by [Y] in 2024, showing [increase/decrease].\n', 'convo_prefix': 'standard', 'seed': 42, 'max_eval_size': 1024, 'max_trajectory_tokens': 8192, 'quality_threshold': 0.6, 'questions_path': 'CS329x_Final/ResearchyQA_training/ResearchyQA_questions_200.jsonl'}, 'model_name': 'Qwen/Qwen3-4B-Instruct-2507', 'max_tokens': 1024, 'compute_post_kl': False, 'evaluator_builders': [], 'lora_rank': 32, 'kl_penalty_coef': 0.0, 'kl_discount_factor': 0.0, 'loss_fn': 'importance_sampling', 'num_substeps': 1, 'wandb_project': 'researchyqa-llm-judge', 'wandb_name': 'researchyqa_multiperspective_cite_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-5_rank32_2025-12-07-21-22', 'log_path': '/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-07-21-22', 'base_url': None, 'enable_trace': False, 'remove_constant_reward_groups': False, 'eval_every': 0, 'save_every': 20, 'load_checkpoint_path': None, 'async_config': None, 'stream_minibatch_config': None, 'num_groups_to_log': 4, '_wandb': {}}
2025-12-07 21:22:21,210 INFO    MainThread:17752 [wandb_init.py:init():881] starting backend
2025-12-07 21:22:21,439 INFO    MainThread:17752 [wandb_init.py:init():884] sending inform_init request
2025-12-07 21:22:21,471 INFO    MainThread:17752 [wandb_init.py:init():892] backend started and connected
2025-12-07 21:22:21,473 INFO    MainThread:17752 [wandb_init.py:init():962] updated telemetry
2025-12-07 21:22:21,490 INFO    MainThread:17752 [wandb_init.py:init():986] communicating run to backend with 90.0 second timeout
2025-12-07 21:22:21,903 INFO    MainThread:17752 [wandb_init.py:init():1033] starting run threads in backend
2025-12-07 21:22:21,992 INFO    MainThread:17752 [wandb_run.py:_console_start():2506] atexit reg
2025-12-07 21:22:21,992 INFO    MainThread:17752 [wandb_run.py:_redirect():2354] redirect: wrap_raw
2025-12-07 21:22:21,993 INFO    MainThread:17752 [wandb_run.py:_redirect():2423] Wrapping output streams.
2025-12-07 21:22:21,993 INFO    MainThread:17752 [wandb_run.py:_redirect():2446] Redirects installed.
2025-12-07 21:22:21,994 INFO    MainThread:17752 [wandb_init.py:init():1073] run started, returning control to user process
2025-12-07 21:22:22,042 INFO    MainThread:17752 [wandb_run.py:_config_callback():1390] config_cb None None {'learning_rate': 4e-05, 'dataset_builder': {'batch_size': 4, 'group_size': 4, 'model_name_for_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507', 'renderer_name': 'qwen3_instruct', 'chroma_tool_config': {'chroma_host': 'localhost', 'chroma_port': 8000, 'chroma_collection_name': 'researchyqa_corpus', 'retrieval_config': {'n_results': 3, 'embedding_config': {'model_name': 'gemini-embedding-001', 'embedding_dim': 768, 'task_type': 'RETRIEVAL_QUERY'}}, 'max_retries': 10, 'initial_retry_delay': 1}, 'judge_model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'judge_model_path': 'tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final', 'judge_rubric': 'Evaluate the answer based on the following aspects:\n\n1. **Search Tool Usage & Strategy**: How effectively did the model use the search tool? High-quality responses demonstrate strategic search behavior:\n   - Multiple searches (typically 2-4) covering different aspects of the question\n   - Well-formulated queries that target specific information needs\n   - Follow-up searches that build upon initial results to fill gaps\n   - Appropriate search breadth for complex or multi-faceted questions\n\n2. **Document-Based Reasoning & Citation**: How well does the answer use and cite retrieved documents?\n   - Explicit document citations using numbered references (e.g., "According to Document 1...", "Document 2 indicates...")\n   - All claims are grounded in specific retrieved documents, not speculation\n   - Proper attribution showing which document supports each claim\n   - Synthesizes information from multiple documents with clear citations\n   - Does NOT make unsupported claims or add information not found in the retrieved documents\n\n3. **Balanced Perspective & Completeness**: For topics with multiple viewpoints:\n   - Acknowledges different perspectives from different documents (e.g., "Document 1 argues... while Document 3 contends...")\n   - Presents controversial topics fairly by citing multiple document sources\n   - Indicates when documents show debates or disagreements\n   - Addresses multiple aspects of complex questions using evidence from retrieved documents\n\nScoring guidance:\n- 0.8-1.0: Excellent search strategy, strong document-based reasoning with explicit citations (e.g., "Document 1", "Document 2"), balanced perspective\n- 0.6-0.7: Good search usage, mostly document-based with citations, generally balanced\n- 0.4-0.5: Adequate searches but weaker citation practice, some unsupported claims or vague references\n- 0.2-0.3: Limited search effectiveness, weak document grounding, missing or poor citations\n- 0.0-0.1: Poor quality, failed to cite documents properly, or made claims without document support', 'system_prompt': '\nYou are an expert research assistant who uses a Wikipedia search tool to find accurate, well-sourced information. You MUST base your answers on the retrieved documents and cite them properly.\n\nTool calling: Execute the tool by wrapping calls in <tool_call>...</tool_call>\n\nThe search tool you have access to:\n```\n{\n    "name": "search",\n    "title": "Wikipedia search",\n    "description": "Searches Wikipedia for relevant information based on the given query.",\n    "inputSchema": {\n        "type": "object",\n        "properties": {\n            "query_list": {\n                "type": "array",\n                "items": {"type": "string"},\n                "description": "A list of fully-formed semantic queries. The tool will return search results for each query.",\n            }\n        },\n        "required": ["query_list"],\n    },\n    "outputSchema": {\n        "type": "string",\n        "description": "The search results in JSON format",\n    },\n}\n```\n\nHow to approach research questions:\n\n1. **Plan your searches**: Think about what information you need. Formulate 1-3 initial search queries that target key aspects of the question.\n\n2. **Execute searches**: Call the search tool with your queries:\n   <tool_call>{"name": "search", "args": {"query_list": ["query1", "query2", ...]}}</tool_call>\n   \n   The tool will return numbered documents (Document 1, Document 2, Document 3, etc.) for each query.\n\n3. **Assess and iterate**: Review the results. Do you have enough information? If not, perform follow-up searches to fill gaps or explore different angles.\n\n4. **Consider multiple perspectives**: For complex or controversial topics (politics, ethics, debates), search for different viewpoints using queries like "arguments for X", "criticisms of X", "perspectives on X".\n\n5. **Answer ONLY based on retrieved documents**: Your answer MUST be grounded in the documents returned by the search tool. Do NOT make claims without document support.\n\n6. **Cite documents by number**: When referencing information, explicitly cite which document(s) you are using. Use formats like:\n   - "According to Document 1, ..."\n   - "Document 2 indicates that ..."\n   - "As stated in Document 3 and Document 5, ..."\n   - "Based on the information in Document 1, ..."\n\n7. **Present balanced views**: When documents present multiple perspectives, acknowledge them: "Document 1 argues... while Document 3 contends..." or "Documents 2 and 4 suggest... however, Document 5 points out...".\n\n8. **Format your answer**: Present your final answer after the "Answer:" prefix with proper document citations.\n\nExample workflow:\nQuestion: "Between 2020 and 2025, which year did New York City see the most population growth and how did San Francisco population change in that year?"\n\nThink: I need NYC and SF population data for 2020-2025.\n<tool_call>{"name": "search", "args": {"query_list": ["New York City population growth 2020-2025", "San Francisco population change 2020-2025"]}}</tool_call>\n\n[Tool returns: Document 1 with NYC data, Document 2 with SF data]\n\n(After results) Think: Document 1 shows NYC peak was 2024. Need more specific SF 2024 data.\n<tool_call>{"name": "search", "args": {"query_list": ["San Francisco population 2024"]}}</tool_call>\n\n[Tool returns: Document 3 with detailed SF 2024 data]\n\nAnswer: According to Document 1, New York City saw the most population growth in 2024 with an increase of [X]. Document 3 indicates that San Francisco\'s population changed by [Y] in 2024, showing [increase/decrease].\n', 'convo_prefix': 'standard', 'seed': 42, 'max_eval_size': 1024, 'max_trajectory_tokens': 8192, 'quality_threshold': 0.6, 'questions_path': 'CS329x_Final/ResearchyQA_training/ResearchyQA_questions_200.jsonl'}, 'model_name': 'Qwen/Qwen3-4B-Instruct-2507', 'max_tokens': 1024, 'compute_post_kl': False, 'evaluator_builders': [], 'lora_rank': 32, 'kl_penalty_coef': 0.0, 'kl_discount_factor': 0.0, 'loss_fn': 'importance_sampling', 'num_substeps': 1, 'wandb_project': 'researchyqa-llm-judge', 'wandb_name': 'researchyqa_multiperspective_cite_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-5_rank32_2025-12-07-21-22', 'log_path': '/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-07-21-22', 'base_url': None, 'enable_trace': False, 'remove_constant_reward_groups': False, 'eval_every': 0, 'save_every': 20, 'load_checkpoint_path': None, 'async_config': None, 'stream_minibatch_config': None, 'num_groups_to_log': 4}
2025-12-07 21:27:59,786 INFO    wandb-AsyncioManager-main:17752 [service_client.py:_forward_responses():80] Reached EOF.
2025-12-07 21:27:59,786 INFO    wandb-AsyncioManager-main:17752 [mailbox.py:close():137] Closing mailbox, abandoning 1 handles.
2025-12-07 21:28:00,314 ERROR   wandb-AsyncioManager-main:17752 [asyncio_manager.py:fn_wrap_exceptions():183] Uncaught exception in run_soon callback.
Traceback (most recent call last):
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py", line 181, in fn_wrap_exceptions
    await fn()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 38, in publish
    await self._send_server_request(request)
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 64, in _send_server_request
    await self._writer.drain()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 392, in drain
    await self._protocol._drain_helper()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 166, in _drain_helper
    raise ConnectionResetError('Connection lost')
ConnectionResetError: Connection lost
2025-12-07 21:28:00,318 ERROR   wandb-AsyncioManager-main:17752 [asyncio_manager.py:fn_wrap_exceptions():183] Uncaught exception in run_soon callback.
Traceback (most recent call last):
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py", line 181, in fn_wrap_exceptions
    await fn()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 38, in publish
    await self._send_server_request(request)
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 64, in _send_server_request
    await self._writer.drain()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 392, in drain
    await self._protocol._drain_helper()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 166, in _drain_helper
    raise ConnectionResetError('Connection lost')
ConnectionResetError: Connection lost
2025-12-07 21:28:00,319 ERROR   wandb-AsyncioManager-main:17752 [asyncio_manager.py:fn_wrap_exceptions():183] Uncaught exception in run_soon callback.
Traceback (most recent call last):
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py", line 181, in fn_wrap_exceptions
    await fn()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 38, in publish
    await self._send_server_request(request)
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 64, in _send_server_request
    await self._writer.drain()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 392, in drain
    await self._protocol._drain_helper()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 166, in _drain_helper
    raise ConnectionResetError('Connection lost')
ConnectionResetError: Connection lost
2025-12-07 21:28:00,324 ERROR   wandb-AsyncioManager-main:17752 [asyncio_manager.py:fn_wrap_exceptions():183] Uncaught exception in run_soon callback.
Traceback (most recent call last):
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py", line 181, in fn_wrap_exceptions
    await fn()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 38, in publish
    await self._send_server_request(request)
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 64, in _send_server_request
    await self._writer.drain()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 392, in drain
    await self._protocol._drain_helper()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 166, in _drain_helper
    raise ConnectionResetError('Connection lost')
ConnectionResetError: Connection lost
2025-12-07 21:28:00,325 ERROR   wandb-AsyncioManager-main:17752 [asyncio_manager.py:fn_wrap_exceptions():183] Uncaught exception in run_soon callback.
Traceback (most recent call last):
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py", line 181, in fn_wrap_exceptions
    await fn()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 38, in publish
    await self._send_server_request(request)
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 64, in _send_server_request
    await self._writer.drain()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 392, in drain
    await self._protocol._drain_helper()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 166, in _drain_helper
    raise ConnectionResetError('Connection lost')
ConnectionResetError: Connection lost
2025-12-07 21:28:00,326 ERROR   wandb-AsyncioManager-main:17752 [asyncio_manager.py:fn_wrap_exceptions():183] Uncaught exception in run_soon callback.
Traceback (most recent call last):
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/asyncio_manager.py", line 181, in fn_wrap_exceptions
    await fn()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 38, in publish
    await self._send_server_request(request)
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/site-packages/wandb/sdk/lib/service/service_client.py", line 64, in _send_server_request
    await self._writer.drain()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 392, in drain
    await self._protocol._drain_helper()
  File "/opt/miniconda3/envs/cs329x_hw2/lib/python3.11/asyncio/streams.py", line 166, in _drain_helper
    raise ConnectionResetError('Connection lost')
ConnectionResetError: Connection lost
