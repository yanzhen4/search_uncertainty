{
  "learning_rate": 4e-05,
  "dataset_builder": {
    "batch_size": 4,
    "group_size": 4,
    "model_name_for_tokenizer": "Qwen/Qwen3-4B-Instruct-2507",
    "renderer_name": "qwen3_instruct",
    "chroma_tool_config": {
      "chroma_host": "localhost",
      "chroma_port": 8000,
      "chroma_collection_name": "researchyqa_corpus",
      "retrieval_config": {
        "n_results": 3,
        "embedding_config": {
          "model_name": "gemini-embedding-001",
          "embedding_dim": 768,
          "task_type": "RETRIEVAL_QUERY"
        }
      },
      "max_retries": 10,
      "initial_retry_delay": 1
    },
    "judge_model_name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "judge_model_path": "tinker://2b33e94d-bdea-4c21-bdb7-2af143b79c8e/sampler_weights/final",
    "judge_rubric": "Evaluate the answer primarily based on the following two critical aspects:\n\n1. **Evidence-Based Reasoning with Source Citations**: CRITICAL - Does the answer explicitly reference or cite the retrieved sources for EVERY claim? The model MUST NOT make unsupported claims. High-quality answers should indicate which information comes from which searches, using phrases like \"According to the search results...\", \"The retrieved documents indicate...\", or \"Based on the information found...\". Any claim not supported by the retrieved context should be penalized. The reasoning should be transparently grounded in the evidence retrieved from the search tool.\n\n2. **Multiple Perspectives & Balanced Coverage**: CRITICAL - For questions that may have different viewpoints, are controversial, or involve debates, does the answer explicitly present multiple perspectives and acknowledge different viewpoints? High-quality answers should include phrases like \"Some argue..., while others contend...\", \"From one perspective..., from another...\", or \"Proponents believe..., whereas critics argue...\". This is especially important for topics involving politics, ethics, social issues, or scientific debates.\n\nIf the answer fails on either of these dimensions (e.g., makes unsupported claims, lacks citations, or ignores alternative viewpoints on a controversial topic), it should receive a low score regardless of its other qualities.",
    "system_prompt": "\nYou are an expert assistant who solves tasks using a Wikipedia search tool and provides balanced, nuanced answers.\nTool calling. Execute the tool by wrapping calls in <function_call>...</function_call>\n\nThe search tool you are given has the following schema:\n```\n{\n    \"name\": \"search\",\n    \"title\": \"Wikipedia search\",\n    \"description\": \"Searches Wikipedia for relevant information based on the given query.\",\n    \"inputSchema\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"query_list\": {\n                \"type\": \"array\",\n                \"items\": {\"type\": \"string\"},\n                \"description\": \"A list of fully-formed semantic queries. The tool will return search results for each query.\",\n            }\n        },\n        \"required\": [\"query_list\"],\n    },\n    \"outputSchema\": {\n        \"type\": \"string\",\n        \"description\": \"The search results in JSON format\",\n    },\n}\n```\n\nHere are instructions for how to solve a problem:\n1. Think step by step before calling the tool and after you receive the result of the tool call. Decide what queries to call the tool with.\n2. IMPORTANT: For questions that may be controversial or have multiple perspectives (e.g., about politics, ethics, social issues, scientific debates), actively search for different viewpoints by using queries that capture contrasting perspectives (e.g., \"arguments for X\", \"criticisms of X\", \"debate on X\").\n3. Call the tool with the queries you have decided on.\n4. Think step by step again after you receive the result of the tool call. If you have the information you need, you can stop here.\n5. Otherwise, come up with new queries that combine information from the previous results.\n6. IMPORTANT: When formulating your final answer, you MUST explicitly cite the retrieved sources and evidence for every claim to avoid making unsupported statements. Use phrases like \"According to the search results...\", \"The retrieved documents indicate...\", or \"Based on the information found...\". DO NOT make any claims that are not supported by the retrieved documents. Make it clear that your reasoning is grounded in the evidence you retrieved.\n7. When formulating your final answer, if the topic is controversial or has different viewpoints, explicitly present multiple perspectives using language like \"Some argue..., while others contend...\" or \"From one perspective..., from another...\" or \"Proponents believe..., whereas critics argue...\". This provides a more complete and balanced response.\n8. Include your final answer after the \"Answer:\" prefix. The answer should be comprehensive yet concise, with clear references to the retrieved evidence.\n\nHere is an example of solving a real question:\n\"Between 2020 and 2025, which year did New York City see the most population growth and how did San Francisco population change in that year?\"\n\n1. Think step by step: In order to answer this question, I need to know the population of New York City and San Francisco between 2020 and 2025. I will search for the population of New York City in each year\n2. Calling search tool: <function_call>{\"name\": \"search\", \"args\": {\"query_list\": [\"Population New York city between 2020 and 2025\"]}}</function_call> (Output omitted for brevity)\n3. Think step by step again: I have the population of New York City in each year, and I see that the population of New York City grew the most in 2024. I need to know the population of San Francisco in 2024. I will search for the population of San Francisco in each year.\n<function_call>{\"name\": \"search\", \"args\": {\"query_list\": [\"Population San Francisco between 2023 and 2024\"]}}</function_call> (Output omitted for brevity)\n4. Answer: The population of New York City grew the most in 2024, and the population of San Francisco changed by XXXX in 2024.\n",
    "convo_prefix": "standard",
    "seed": 42,
    "max_eval_size": 1024,
    "max_trajectory_tokens": 8192,
    "quality_threshold": 0.6,
    "questions_path": "CS329x_Final/ResearchyQA_training/ResearchyQA_questions_200.jsonl"
  },
  "model_name": "Qwen/Qwen3-4B-Instruct-2507",
  "max_tokens": 1024,
  "compute_post_kl": false,
  "evaluator_builders": [],
  "lora_rank": 32,
  "kl_penalty_coef": 0.0,
  "kl_discount_factor": 0.0,
  "loss_fn": "importance_sampling",
  "num_substeps": 1,
  "wandb_project": "researchyqa-llm-judge",
  "wandb_name": "researchyqa_multiperspective_cite_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-5_rank32_2025-12-07-09-37",
  "log_path": "/Users/yanzhenshen/Desktop/CS329x/tinker-cookbook/outputs/researchyqa_llm_judge/researchyqa_llmjudge_qwen-qwen3-4b-instruct-2507_bs4_gs4_judge-qwen3-30b-a3b-instruct-2507_thresh0.6_seed42_traj8k_lr4e-05_rank32_2025-12-07-09-37",
  "base_url": null,
  "enable_trace": false,
  "remove_constant_reward_groups": false,
  "eval_every": 0,
  "save_every": 20,
  "load_checkpoint_path": null,
  "async_config": null,
  "stream_minibatch_config": null,
  "num_groups_to_log": 4
}