{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-l6RtL7T-jG"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please run this on a GPU with specifications equivalent to or exceeding those of an L4 (High-RAM) configuration."
      ],
      "metadata": {
        "id": "babbEU0YdZ_O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpysgSZJ2A2C"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j9RdR01Cotv",
        "outputId": "f2879824-70bc-43ea-e8af-703001bdc9c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJdotaH2EFF"
      },
      "source": [
        "**Import Libraries**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7K3MAXD155q"
      },
      "source": [
        "Other libraries need us to install numpy 1.26.4. Click \"Restart Runtime\" if prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "osdkw8xgV8rO",
        "outputId": "378c9e78-5711-4ded-a3da-ffa9b50f2999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.3.5\n",
            "Uninstalling numpy-2.3.5:\n",
            "  Successfully uninstalled numpy-2.3.5\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "faiss-gpu-cu12 1.13.0 requires numpy<3,>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3fdf84356b674741b978b74dfb053254"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQd6FxOoWTfr",
        "outputId": "18f9d89e-cf01-48df-8df3-060c44342a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "print(numpy.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55n7gFTtdx9q",
        "outputId": "79909c05-5a14-495c-96ff-4c2852a5fcbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS329X_Project/search_agent_code/utils/verl\n",
            "Obtaining file:///content/drive/MyDrive/CS329X_Project/search_agent_code/utils/verl\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (1.12.0)\n",
            "Collecting codetiming (from verl==0.7.0.dev0)\n",
            "  Downloading codetiming-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (0.3.8)\n",
            "Collecting hydra-core (from verl==0.7.0.dev0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (2.2.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (0.18.0)\n",
            "Collecting pyarrow>=19.0.0 (from verl==0.7.0.dev0)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting pybind11 (from verl==0.7.0.dev0)\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting pylatexenc (from verl==0.7.0.dev0)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ray>=2.41.0 (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (0.11.0)\n",
            "Collecting tensordict!=0.9.0,<=0.10.0,>=0.8.0 (from verl==0.7.0.dev0)\n",
            "  Downloading tensordict-0.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (4.57.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (0.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (25.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from verl==0.7.0.dev0) (2.19.0)\n",
            "Collecting click!=8.3.*,>=7.0 (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (3.20.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (3.13.2)\n",
            "Collecting aiohttp_cors (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (1.76.0)\n",
            "Collecting opencensus (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (1.37.0)\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-proto in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (1.37.0)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (2.12.3)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (0.23.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default]>=2.41.0->verl==0.7.0.dev0) (7.5.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (8.7.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (from tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.11.4)\n",
            "Collecting pyvers<0.2.0,>=0.1.0 (from tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0)\n",
            "  Downloading pyvers-0.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->verl==0.7.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->verl==0.7.0.dev0) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate->verl==0.7.0.dev0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets->verl==0.7.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->verl==0.7.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->verl==0.7.0.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->verl==0.7.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core->verl==0.7.0.dev0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core->verl==0.7.0.dev0) (4.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->verl==0.7.0.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->verl==0.7.0.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->verl==0.7.0.dev0) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->verl==0.7.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->verl==0.7.0.dev0) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->verl==0.7.0.dev0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->verl==0.7.0.dev0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->verl==0.7.0.dev0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->verl==0.7.0.dev0) (3.1.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata->verl==0.7.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->verl==0.7.0.dev0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->verl==0.7.0.dev0) (0.22.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->verl==0.7.0.dev0) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->verl==0.7.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->verl==0.7.0.dev0) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb->verl==0.7.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.7->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->verl==0.7.0.dev0) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate->verl==0.7.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.58b0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]>=2.41.0->verl==0.7.0.dev0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (2025.11.12)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (3.5.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->verl==0.7.0.dev0) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray>=2.41.0->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.29.0)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (2.28.1)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default]>=2.41.0->verl==0.7.0.dev0)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default]>=2.41.0->verl==0.7.0.dev0) (2.0.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->verl==0.7.0.dev0) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (2.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->tensordict!=0.9.0,<=0.10.0,>=0.8.0->verl==0.7.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=2.41.0->verl==0.7.0.dev0) (0.6.1)\n",
            "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (449 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.0/450.0 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading codetiming-1.4.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvers-0.1.0-py3-none-any.whl (10 kB)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_prometheus-0.58b0-py3-none-any.whl (13 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Building wheels for collected packages: verl, pylatexenc\n",
            "  Building editable for verl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for verl: filename=verl-0.7.0.dev0-0.editable-py3-none-any.whl size=16338 sha256=1f13819bb1326408be4341e3426fb67b2ad4ce7dbacd45e31d18f345f31d1a2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dxazh834/wheels/14/37/d6/f149497299d1c666914999ea8033a1b31ffa86f08400bbec43\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=7dfa87dc35f44d433c022da5f062b0a8ed67aa21f246ca2e40c1ea4bfe739f05\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built verl pylatexenc\n",
            "Installing collected packages: pylatexenc, py-spy, opencensus-context, distlib, colorful, virtualenv, pyvers, pybind11, pyarrow, codetiming, click, hydra-core, aiohttp_cors, tensordict, ray, opencensus, opentelemetry-exporter-prometheus, verl\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "Successfully installed aiohttp_cors-0.8.1 click-8.2.1 codetiming-1.4.0 colorful-0.5.8 distlib-0.4.0 hydra-core-1.3.2 opencensus-0.11.4 opencensus-context-0.1.3 opentelemetry-exporter-prometheus-0.58b0 py-spy-0.4.1 pyarrow-22.0.0 pybind11-3.0.1 pylatexenc-2.10 pyvers-0.1.0 ray-2.52.1 tensordict-0.10.0 verl-0.7.0.dev0 virtualenv-20.35.4\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Load verl\n",
        "%cd \"/content/drive/MyDrive/CS329X_Project/search_agent_code/utils/verl/\"\n",
        "\n",
        "# Install verl in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "%cd \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aO8iKXgfQ5R4",
        "outputId": "16f110e4-c34e-4b11-b46e-b66d84d94560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.57.1\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-1.3.0.tar.gz (178.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.8/178.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.12/dist-packages (from pyserini) (3.0.12)\n",
            "Collecting pyjnius>=1.6.0 (from pyserini)\n",
            "  Downloading pyjnius-1.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.12/dist-packages (from pyserini) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pyserini) (1.16.3)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (2.9.0+cu126)\n",
            "Collecting onnxruntime>=1.8.1 (from pyserini)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (2.8.1)\n",
            "Requirement already satisfied: sentencepiece>=0.2 in /usr/local/lib/python3.12/dist-packages (from pyserini) (0.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (0.12.0)\n",
            "Requirement already satisfied: flask>3.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (3.1.2)\n",
            "Requirement already satisfied: pillow>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (11.3.0)\n",
            "Requirement already satisfied: fastapi>=0.70.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (0.118.3)\n",
            "Requirement already satisfied: uvicorn>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from pyserini) (0.38.0)\n",
            "Collecting fastmcp>=2.10.4 (from pyserini)\n",
            "  Downloading fastmcp-2.13.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from pyserini) (3.10.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.70.0->pyserini) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.70.0->pyserini) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.70.0->pyserini) (4.15.0)\n",
            "Requirement already satisfied: authlib>=1.6.5 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (1.6.5)\n",
            "Collecting cyclopts>=4.0.0 (from fastmcp>=2.10.4->pyserini)\n",
            "  Downloading cyclopts-4.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp>=2.10.4->pyserini)\n",
            "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (0.28.1)\n",
            "Collecting jsonschema-path>=0.3.4 (from fastmcp>=2.10.4->pyserini)\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: mcp!=1.21.1,<1.23,>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (1.22.0)\n",
            "Collecting openapi-pydantic>=0.5.1 (from fastmcp>=2.10.4->pyserini)\n",
            "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (4.5.0)\n",
            "Collecting py-key-value-aio<0.4.0,>=0.2.8 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading py_key_value_aio-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (1.11.0)\n",
            "Requirement already satisfied: python-dotenv>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (1.2.1)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (13.9.4)\n",
            "Requirement already satisfied: websockets>=15.0.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.10.4->pyserini) (15.0.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask>3.0->pyserini) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask>3.0->pyserini) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask>3.0->pyserini) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask>3.0->pyserini) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask>3.0->pyserini) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask>3.0->pyserini) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (1.2.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.8.1->pyserini)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.8.1->pyserini) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.8.1->pyserini) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.14.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->pyserini) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2025.11.12)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->pyserini) (3.5.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.13.0->pyserini) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyserini) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyserini) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyserini) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyserini) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->pyserini) (3.2.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib>=1.6.5->fastmcp>=2.10.4->pyserini) (43.0.3)\n",
            "Requirement already satisfied: docstring-parser<4.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=4.0.0->fastmcp>=2.10.4->pyserini) (0.17.0)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=4.0.0->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading rich_rst-1.3.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->fastmcp>=2.10.4->pyserini) (1.0.9)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path>=0.3.4->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting referencing<0.37.0 (from jsonschema-path>=0.3.4->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (3.0.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (0.4.2)\n",
            "Collecting py-key-value-shared==0.3.0 (from py-key-value-aio<0.4.0,>=0.2.8->py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading py_key_value_shared-0.3.0-py3-none-any.whl.metadata (706 bytes)\n",
            "Requirement already satisfied: beartype>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from py-key-value-aio<0.4.0,>=0.2.8->py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.10.4->pyserini) (0.22.6)\n",
            "Collecting diskcache>=5.0.0 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pathvalidate>=3.3.1 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: cachetools>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.10.4->pyserini) (6.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.70.0->pyserini) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.70.0->pyserini) (2.41.4)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp>=2.10.4->pyserini) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->fastmcp>=2.10.4->pyserini) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.8.1->pyserini)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp>=2.10.4->pyserini)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (2025.9.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp!=1.21.1,<1.23,>=1.19.0->fastmcp>=2.10.4->pyserini) (0.29.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->fastmcp>=2.10.4->pyserini) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib>=1.6.5->fastmcp>=2.10.4->pyserini) (2.0.0)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=4.0.0->fastmcp>=2.10.4->pyserini) (0.21.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib>=1.6.5->fastmcp>=2.10.4->pyserini) (2.23)\n",
            "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m151.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastmcp-2.13.3-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.6/385.6 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyjnius-1.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cyclopts-4.3.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_key_value_aio-0.3.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_key_value_shared-0.3.0-py3-none-any.whl (19 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rich_rst-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyserini\n",
            "  Building wheel for pyserini (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyserini: filename=pyserini-1.3.0-py3-none-any.whl size=178862781 sha256=ce8364f3cbdd49d0ffe8920fce7ba1fd56d16b6723e9945df9ef22e2555a2d7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/29/8d/06590a71e1ac6f59295c964c6cc28bb263c23577080c62a148\n",
            "Successfully built pyserini\n",
            "Installing collected packages: pyjnius, referencing, py-key-value-shared, pathvalidate, pathable, humanfriendly, exceptiongroup, dnspython, diskcache, py-key-value-aio, jsonschema-path, email-validator, coloredlogs, rich-rst, openapi-pydantic, onnxruntime, transformers, cyclopts, fastmcp, pyserini\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.37.0\n",
            "    Uninstalling referencing-0.37.0:\n",
            "      Successfully uninstalled referencing-0.37.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.2\n",
            "    Uninstalling transformers-4.57.2:\n",
            "      Successfully uninstalled transformers-4.57.2\n",
            "Successfully installed coloredlogs-15.0.1 cyclopts-4.3.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 exceptiongroup-1.3.1 fastmcp-2.13.3 humanfriendly-10.0 jsonschema-path-0.3.4 onnxruntime-1.23.2 openapi-pydantic-0.5.1 pathable-0.4.4 pathvalidate-3.3.1 py-key-value-aio-0.3.0 py-key-value-shared-0.3.0 pyjnius-1.7.0 pyserini-1.3.0 referencing-0.36.2 rich-rst-1.3.2 transformers-4.57.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp312-cp312-linux_x86_64.whl (799.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.4.0+cu121 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.4.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 triton-3.0.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu==1.8.0.post1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu==1.8.0.post1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Collecting vllm==0.6.3\n",
            "  Downloading vllm-0.6.3-cp38-abi3-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.2.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (4.67.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.45.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (4.57.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (5.29.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (3.13.2)\n",
            "Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (2.8.1)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.38.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (2.12.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (11.3.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.23.1)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.6.3)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.12.0)\n",
            "Collecting lm-format-enforcer==0.10.6 (from vllm==0.6.3)\n",
            "  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting outlines<0.1,>=0.0.43 (from vllm==0.6.3)\n",
            "  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (3.20.0)\n",
            "Collecting partial-json-parser (from vllm==0.6.3)\n",
            "  Downloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (26.2.1)\n",
            "Collecting msgspec (from vllm==0.6.3)\n",
            "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting gguf==0.10.0 (from vllm==0.6.3)\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (8.7.0)\n",
            "Collecting mistral-common>=1.4.4 (from mistral-common[opencv]>=1.4.4->vllm==0.6.3)\n",
            "  Downloading mistral_common-1.8.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (6.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.8.1)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (2.52.1)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (13.580.82)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (2.4.0+cu121)\n",
            "Collecting torchvision==0.19 (from vllm==0.6.3)\n",
            "  Downloading torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting xformers==0.0.27.post2 (from vllm==0.6.3)\n",
            "  Downloading xformers-0.0.27.post2-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=74.1.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (75.2.0)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.6.3) (0.118.3)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm==0.6.3)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.10.6->vllm==0.6.3) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0->vllm==0.6.3) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm==0.6.3) (12.6.85)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm==0.6.3) (0.48.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3) (4.25.1)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mistral-common[opencv]>=1.4.4->vllm==0.6.3) (4.12.0.88)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.40.0->vllm==0.6.3) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.40.0->vllm==0.6.3) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.40.0->vllm==0.6.3) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.40.0->vllm==0.6.3) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.40.0->vllm==0.6.3) (1.3.1)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (1.3.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (3.1.2)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (5.6.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (0.60.0)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (0.36.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3) (4.0.0)\n",
            "Collecting pycountry (from outlines<0.1,>=0.0.43->vllm==0.6.3)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pyairports (from outlines<0.1,>=0.0.43->vllm==0.6.3)\n",
            "  Downloading pyairports-0.0.1.tar.gz (3.1 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->vllm==0.6.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->vllm==0.6.3) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->vllm==0.6.3) (0.4.2)\n",
            "Requirement already satisfied: click!=8.3.*,>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.9->vllm==0.6.3) (8.2.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.9->vllm==0.6.3) (1.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.6.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.6.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.6.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.6.3) (2025.11.12)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.6.0->vllm==0.6.3) (2025.11.3)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.19.1->vllm==0.6.3) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0->vllm==0.6.3) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.6.3) (1.22.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->vllm==0.6.3) (3.23.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->vllm==0.6.3) (0.16.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm==0.6.3)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->vllm==0.6.3) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]->vllm==0.6.3)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.6.3)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]->vllm==0.6.3) (15.0.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm==0.6.3) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.19.1->vllm==0.6.3) (1.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3) (2025.9.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3) (0.29.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless>=4.0.0 (from mistral-common[opencv]>=1.4.4->vllm==0.6.3)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (22.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (0.70.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0->vllm==0.6.3) (3.0.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.6.3) (0.43.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0->vllm==0.6.3) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3) (2025.2)\n",
            "Downloading vllm-0.6.3-cp38-abi3-manylinux1_x86_64.whl (193.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.27.post2-cp312-cp312-manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.6-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post7-py3-none-any.whl (10 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyairports\n",
            "  Building wheel for pyairports (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyairports: filename=pyairports-0.0.1-py3-none-any.whl size=3524 sha256=313e52f0685992efb71e0c7b8cd8505e791bdde62bfb886255777b3632852a2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/38/6d/46c9744c0fc107fafb722708477240be475edcc6397154f362\n",
            "Successfully built pyairports\n",
            "Installing collected packages: pyairports, uvloop, pycountry, partial-json-parser, opencv-python-headless, msgspec, interegular, httptools, gguf, watchfiles, pydantic-extra-types, prometheus-fastapi-instrumentator, lm-format-enforcer, xformers, torchvision, outlines, mistral-common, vllm\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Successfully installed gguf-0.10.0 httptools-0.7.1 interegular-0.3.3 lm-format-enforcer-0.10.6 mistral-common-1.8.6 msgspec-0.20.0 opencv-python-headless-4.11.0.86 outlines-0.0.46 partial-json-parser-0.2.1.1.post7 prometheus-fastapi-instrumentator-7.1.0 pyairports-0.0.1 pycountry-24.6.1 pydantic-extra-types-2.10.6 torchvision-0.19.0 uvloop-0.22.1 vllm-0.6.3 watchfiles-1.1.1 xformers-0.0.27.post2\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.4.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=255985226 sha256=ee1fbb7dc9d4f6e973687e15e245727d39c2b5f5884c74fa30d21bd1841854af\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.8.3\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n",
            "Collecting faiss-gpu-cu12\n",
            "  Downloading faiss_gpu_cu12-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting numpy<3,>=2 (from faiss-gpu-cu12)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (25.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (12.1.3.1)\n",
            "Downloading faiss_gpu_cu12-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, faiss-gpu-cu12\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "outlines 0.0.46 requires numpy<2.0.0, but you have numpy 2.3.5 which is incompatible.\n",
            "vllm 0.6.3 requires numpy<2.0.0, but you have numpy 2.3.5 which is incompatible.\n",
            "verl 0.7.0.dev0 requires numpy<2.0.0, but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-gpu-cu12-1.13.0 numpy-2.3.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "0a5f03d3fee846168181dfba9d0593b7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. Core libraries\n",
        "!pip install transformers==4.57.1 datasets pyserini\n",
        "# 2. Torch with CUDA 12.1\n",
        "!pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "# 3. GPU FAISS (RL rollout support)\n",
        "!pip install faiss-gpu==1.8.0.post1\n",
        "# 4. API + backend dependencies\n",
        "!pip install uvicorn fastapi\n",
        "# 5. vLLM for inference backend\n",
        "!pip install vllm==0.6.3\n",
        "# 6. FlashAttention 2 (optimized attention)\n",
        "!pip install flash-attn --no-build-isolation\n",
        "# 7. Logging utilities\n",
        "!pip install wandb\n",
        "\n",
        "# For Retrieval\n",
        "!pip install pyngrok\n",
        "!pip install faiss-gpu-cu12\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1raHHhluXgkp"
      },
      "source": [
        "# 2. Build index for your corpus (only needed for first time)\n",
        "\n",
        "\n",
        "**Skip this step if you have already indexed your corpus.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AunW-GwRbXf-"
      },
      "source": [
        "2.0 View your corpus (optional)\n",
        "\n",
        "Note: For each document in your corpus, please make sure that the documents are saved under \"contents\", like the below example. Otherwise, the code in Part 4 won't work.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{'id': '39', 'contents': '\"Tax policy and economic inequality in the United States\"\\nwages from 1979–2009. The real wages of the top fifth rose by 99% and then 55% during the same periods, respectively. Average real hourly wages have also increased by a significantly larger rate for the top 20% than they have for the bottom 20%. Real family income for the bottom 20% increased by 7.4% from 1979 to 2009 while it increased by 49% for the top 20% and increased by 22.7% for the second top fifth of American families. As of 2007, the United Nations estimated the ratio of average income for the top 10% to the bottom 10% of'}\n",
        "{'id': '67', 'contents': '\"Ambrosini SAI.207\"\\nAmbrosini SAI.207 The Ambrosini SAI.207 was a light fighter interceptor built entirely from wood and developed in Italy during World War II. Powered by a single 750 hp Isotta Fraschini Delta, the SAI.207 enjoyed limited success during evaluation of the 12 pre-production aircraft. The SAI.207 was developed from the Ambrosini SAI.7 racing and sporting monoplane after the light fighter concept had been proven with the Ambrosini SAI.107 prototype. Steffanuti designed the aircraft to have a lightweight structure and light armament to allow lower-powered engines to be used, without unduly reducing performance. The first of three prototypes was completed and flown'}\n",
        "{'id': '215', 'contents': '\"Digital cross connect system\"\\nOC3, OC12, OC48, and OC192. The DCS must be able to groom the traffic, economically and quickly, at the most efficient and desired levels. This is performed at the lowest level possible - DS1 level (or VT1.5) is preferred. A SONET 3/1 DCS will transmux and carry DS3 signals as STS-1 signals and groom TDM DS1/T1s using VT1.5 signals. The Central Office is where signals are generally switched and groomed to route DS1s needing to be mapped to other Optical or Electrical signals to get to different equipment or sent along to other Central Offices. If an Electrical DS3 is'}\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QEX3E45rtx-",
        "outputId": "249ce711-31cc-4788-c7d2-1ab7e92c3ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '0_0#p0000', 'contents': \"Alabama is No. 1 in the final AP Top 25 men's college basketball poll of the season Houston is No. 2 and Big Ten champion Purdue was third.\"}\n",
            "{'id': '0_1#p0000', 'contents': 'The football poll is released Sundays at 2 pm Eastern time during the season, unless ranked teams have not finished their games. HistoryEdit. The AP college\\xa0...'}\n",
            "{'id': '0_2#p0000', 'contents': 'Get the latest College Basketball rankings for the 2022-23 season. Find out where your favorite team is ranked in the AP Top 25, Coaches Poll, Top 25 And 1,\\xa0...'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "#file_path = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/wikipedia_corpus/mini-wiki-18.jsonl\"\n",
        "#file_path = \"/content/drive/MyDrive/CS329X_Project/datasets/ResearchyQA/ResearchQA_corpus.jsonl\"\n",
        "file_path = \"/content/drive/MyDrive/CS329X_Project/datasets/QACC/ConflictQA_corpus.jsonl\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        print(json.loads(line))\n",
        "        if i >= 2:  # show only first 3 entries\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3TLTxRIYe96"
      },
      "source": [
        "2.1 Run these functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5HtzrwSpntG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "216fd3d8-fc66-47e0-e4eb-abc81a81d2ef"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-588591062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# from LongRAG.retriever.utils import load_model, load_corpus, pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderDecoderConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m from .configuration_auto import (\n\u001b[1;32m     42\u001b[0m     \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0;31m from .candidate_generator import (\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mAssistantVocabTranslatorCache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mAssistedCandidateGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/candidate_generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_sklearn_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_arraylike_not_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_numpy_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_preserve_dia_indices_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_support_alternative_backends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_basic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/_basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_specfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_comb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_comb_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from ._multiufuncs import (assoc_legendre_p_all,\n\u001b[0m\u001b[1;32m     23\u001b[0m                            legendre_p_all)\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m sph_legendre_p = MultiUFunc(\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0msph_legendre_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     r\"\"\"sph_legendre_p(n, m, theta, *, diff_n=0)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/special/_multiufuncs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ufunc_or_ufuncs, doc, force_complex_output, **default_kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mufunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufuncs_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     raise ValueError(\"All ufuncs must have type `numpy.ufunc`.\"\n\u001b[0m\u001b[1;32m     42\u001b[0m                                      f\" Received {ufunc_or_ufuncs}\")\n\u001b[1;32m     43\u001b[0m                 \u001b[0mseen_input_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"->\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import faiss\n",
        "import json\n",
        "import warnings\n",
        "import numpy as np\n",
        "from typing import cast, List, Dict\n",
        "import shutil\n",
        "import subprocess\n",
        "import argparse\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "# from LongRAG.retriever.utils import load_model, load_corpus, pooling\n",
        "import datasets\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "\n",
        "\n",
        "def load_model(\n",
        "        model_path: str,\n",
        "        use_fp16: bool = False\n",
        "    ):\n",
        "    model_config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
        "    model = AutoModel.from_pretrained(model_path, trust_remote_code=True)\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "    if use_fp16:\n",
        "        model = model.half()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True, trust_remote_code=True)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def pooling(\n",
        "        pooler_output,\n",
        "        last_hidden_state,\n",
        "        attention_mask = None,\n",
        "        pooling_method = \"mean\"\n",
        "    ):\n",
        "    if pooling_method == \"mean\":\n",
        "        last_hidden = last_hidden_state.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "    elif pooling_method == \"cls\":\n",
        "        return last_hidden_state[:, 0]\n",
        "    elif pooling_method == \"pooler\":\n",
        "        return pooler_output\n",
        "    else:\n",
        "        raise NotImplementedError(\"Pooling method not implemented!\")\n",
        "\n",
        "\n",
        "def load_corpus(corpus_path: str):\n",
        "    corpus = datasets.load_dataset(\n",
        "            'json',\n",
        "            data_files=corpus_path,\n",
        "            split=\"train\",\n",
        "            num_proc=4)\n",
        "    return corpus\n",
        "\n",
        "\n",
        "class Index_Builder:\n",
        "    r\"\"\"A tool class used to build an index used in retrieval.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            retrieval_method,\n",
        "            model_path,\n",
        "            corpus_path,\n",
        "            save_dir,\n",
        "            max_length,\n",
        "            batch_size,\n",
        "            use_fp16,\n",
        "            pooling_method,\n",
        "            faiss_type=None,\n",
        "            embedding_path=None,\n",
        "            save_embedding=False,\n",
        "            faiss_gpu=False\n",
        "        ):\n",
        "\n",
        "        self.retrieval_method = retrieval_method.lower()\n",
        "        self.model_path = model_path\n",
        "        self.corpus_path = corpus_path\n",
        "        self.save_dir = save_dir\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = batch_size\n",
        "        self.use_fp16 = use_fp16\n",
        "        self.pooling_method = pooling_method\n",
        "        self.faiss_type = faiss_type if faiss_type is not None else 'Flat'\n",
        "        self.embedding_path = embedding_path\n",
        "        self.save_embedding = save_embedding\n",
        "        self.faiss_gpu = faiss_gpu\n",
        "\n",
        "        self.gpu_num = torch.cuda.device_count()\n",
        "        # prepare save dir\n",
        "        print(self.save_dir)\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.makedirs(self.save_dir)\n",
        "        else:\n",
        "            if not self._check_dir(self.save_dir):\n",
        "                warnings.warn(\"Some files already exists in save dir and may be overwritten.\", UserWarning)\n",
        "\n",
        "        self.index_save_path = os.path.join(self.save_dir, f\"{self.retrieval_method}_{self.faiss_type}.index\")\n",
        "\n",
        "        self.embedding_save_path = os.path.join(self.save_dir, f\"emb_{self.retrieval_method}.memmap\")\n",
        "\n",
        "        self.corpus = load_corpus(self.corpus_path)\n",
        "\n",
        "        print(\"Finish loading...\")\n",
        "    @staticmethod\n",
        "    def _check_dir(dir_path):\n",
        "        r\"\"\"Check if the dir path exists and if there is content.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if os.path.isdir(dir_path):\n",
        "            if len(os.listdir(dir_path)) > 0:\n",
        "                return False\n",
        "        else:\n",
        "            os.makedirs(dir_path, exist_ok=True)\n",
        "        return True\n",
        "\n",
        "    def build_index(self):\n",
        "        r\"\"\"Constructing different indexes based on selective retrieval method.\n",
        "\n",
        "        \"\"\"\n",
        "        if self.retrieval_method == \"bm25\":\n",
        "            self.build_bm25_index()\n",
        "        else:\n",
        "            self.build_dense_index()\n",
        "\n",
        "    def build_bm25_index(self):\n",
        "        \"\"\"Building BM25 index based on Pyserini library.\n",
        "\n",
        "        Reference: https://github.com/castorini/pyserini/blob/master/docs/usage-index.md#building-a-bm25-index-direct-java-implementation\n",
        "        \"\"\"\n",
        "\n",
        "        # to use pyserini pipeline, we first need to place jsonl file in the folder\n",
        "        self.save_dir = os.path.join(self.save_dir, \"bm25\")\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        temp_dir = self.save_dir + \"/temp\"\n",
        "        temp_file_path = temp_dir + \"/temp.jsonl\"\n",
        "        os.makedirs(temp_dir)\n",
        "\n",
        "        # if self.have_contents:\n",
        "        #     shutil.copyfile(self.corpus_path, temp_file_path)\n",
        "        # else:\n",
        "        #     with open(temp_file_path, \"w\") as f:\n",
        "        #         for item in self.corpus:\n",
        "        #             f.write(json.dumps(item) + \"\\n\")\n",
        "        shutil.copyfile(self.corpus_path, temp_file_path)\n",
        "\n",
        "        print(\"Start building bm25 index...\")\n",
        "        pyserini_args = [\"--collection\", \"JsonCollection\",\n",
        "                         \"--input\", temp_dir,\n",
        "                         \"--index\", self.save_dir,\n",
        "                         \"--generator\", \"DefaultLuceneDocumentGenerator\",\n",
        "                         \"--threads\", \"1\"]\n",
        "\n",
        "        subprocess.run([\"python\", \"-m\", \"pyserini.index.lucene\"] + pyserini_args)\n",
        "\n",
        "        shutil.rmtree(temp_dir)\n",
        "\n",
        "        print(\"Finish!\")\n",
        "\n",
        "    def _load_embedding(self, embedding_path, corpus_size, hidden_size):\n",
        "        all_embeddings = np.memmap(\n",
        "                embedding_path,\n",
        "                mode=\"r\",\n",
        "                dtype=np.float32\n",
        "            ).reshape(corpus_size, hidden_size)\n",
        "        return all_embeddings\n",
        "\n",
        "    def _save_embedding(self, all_embeddings):\n",
        "        memmap = np.memmap(\n",
        "            self.embedding_save_path,\n",
        "            shape=all_embeddings.shape,\n",
        "            mode=\"w+\",\n",
        "            dtype=all_embeddings.dtype\n",
        "        )\n",
        "        length = all_embeddings.shape[0]\n",
        "        # add in batch\n",
        "        save_batch_size = 10000\n",
        "        if length > save_batch_size:\n",
        "            for i in tqdm(range(0, length, save_batch_size), leave=False, desc=\"Saving Embeddings\"):\n",
        "                j = min(i + save_batch_size, length)\n",
        "                memmap[i: j] = all_embeddings[i: j]\n",
        "        else:\n",
        "            memmap[:] = all_embeddings\n",
        "\n",
        "    def encode_all(self):\n",
        "        if self.gpu_num > 1:\n",
        "            print(\"Use multi gpu!\")\n",
        "            self.encoder = torch.nn.DataParallel(self.encoder)\n",
        "            self.batch_size = self.batch_size * self.gpu_num\n",
        "\n",
        "        all_embeddings = []\n",
        "\n",
        "        for start_idx in tqdm(range(0, len(self.corpus), self.batch_size), desc='Inference Embeddings:'):\n",
        "\n",
        "            # batch_data_title = self.corpus[start_idx:start_idx+self.batch_size]['title']\n",
        "            # batch_data_text = self.corpus[start_idx:start_idx+self.batch_size]['text']\n",
        "            # batch_data = ['\"' + title + '\"\\n' + text for title, text in zip(batch_data_title, batch_data_text)]\n",
        "            batch_data = self.corpus[start_idx:start_idx+self.batch_size]['contents']\n",
        "\n",
        "            if self.retrieval_method == \"e5\":\n",
        "                batch_data = [f\"passage: {doc}\" for doc in batch_data]\n",
        "\n",
        "            inputs = self.tokenizer(\n",
        "                        batch_data,\n",
        "                        padding=True,\n",
        "                        truncation=True,\n",
        "                        return_tensors='pt',\n",
        "                        max_length=self.max_length,\n",
        "            ).to('cuda')\n",
        "\n",
        "            inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "            #TODO: support encoder-only T5 model\n",
        "            if \"T5\" in type(self.encoder).__name__:\n",
        "                # T5-based retrieval model\n",
        "                decoder_input_ids = torch.zeros(\n",
        "                    (inputs['input_ids'].shape[0], 1), dtype=torch.long\n",
        "                ).to(inputs['input_ids'].device)\n",
        "                output = self.encoder(\n",
        "                    **inputs, decoder_input_ids=decoder_input_ids, return_dict=True\n",
        "                )\n",
        "                embeddings = output.last_hidden_state[:, 0, :]\n",
        "\n",
        "            else:\n",
        "                output = self.encoder(**inputs, return_dict=True)\n",
        "                embeddings = pooling(output.pooler_output,\n",
        "                                    output.last_hidden_state,\n",
        "                                    inputs['attention_mask'],\n",
        "                                    self.pooling_method)\n",
        "                if  \"dpr\" not in self.retrieval_method:\n",
        "                    embeddings = torch.nn.functional.normalize(embeddings, dim=-1)\n",
        "\n",
        "            embeddings = cast(torch.Tensor, embeddings)\n",
        "            embeddings = embeddings.detach().cpu().numpy()\n",
        "            all_embeddings.append(embeddings)\n",
        "\n",
        "        all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "        all_embeddings = all_embeddings.astype(np.float32)\n",
        "\n",
        "        return all_embeddings\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def build_dense_index(self):\n",
        "        \"\"\"Obtain the representation of documents based on the embedding model(BERT-based) and\n",
        "        construct a faiss index.\n",
        "        \"\"\"\n",
        "\n",
        "        if os.path.exists(self.index_save_path):\n",
        "            print(\"The index file already exists and will be overwritten.\")\n",
        "\n",
        "        self.encoder, self.tokenizer = load_model(model_path = self.model_path,\n",
        "                                                  use_fp16 = self.use_fp16)\n",
        "        if self.embedding_path is not None:\n",
        "            hidden_size = self.encoder.config.hidden_size\n",
        "            corpus_size = len(self.corpus)\n",
        "            all_embeddings = self._load_embedding(self.embedding_path, corpus_size, hidden_size)\n",
        "        else:\n",
        "            all_embeddings = self.encode_all()\n",
        "            if self.save_embedding:\n",
        "                self._save_embedding(all_embeddings)\n",
        "            del self.corpus\n",
        "\n",
        "        # build index\n",
        "        print(\"Creating index\")\n",
        "        dim = all_embeddings.shape[-1]\n",
        "        faiss_index = faiss.index_factory(dim, self.faiss_type, faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "        if self.faiss_gpu:\n",
        "            co = faiss.GpuMultipleClonerOptions()\n",
        "            co.useFloat16 = True\n",
        "            co.shard = True\n",
        "            faiss_index = faiss.index_cpu_to_all_gpus(faiss_index, co)\n",
        "            if not faiss_index.is_trained:\n",
        "                faiss_index.train(all_embeddings)\n",
        "            faiss_index.add(all_embeddings)\n",
        "            faiss_index = faiss.index_gpu_to_cpu(faiss_index)\n",
        "        else:\n",
        "            if not faiss_index.is_trained:\n",
        "                faiss_index.train(all_embeddings)\n",
        "            faiss_index.add(all_embeddings)\n",
        "\n",
        "        faiss.write_index(faiss_index, self.index_save_path)\n",
        "        print(\"Finish!\")\n",
        "\n",
        "\n",
        "MODEL2POOLING = {\n",
        "    \"e5\": \"mean\",\n",
        "    \"bge\": \"cls\",\n",
        "    \"contriever\": \"mean\",\n",
        "    'jina': 'mean'\n",
        "}\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description = \"Creating index.\")\n",
        "\n",
        "    # Basic parameters\n",
        "    parser.add_argument('--retrieval_method', type=str)\n",
        "    parser.add_argument('--model_path', type=str, default=None)\n",
        "    parser.add_argument('--corpus_path', type=str)\n",
        "    parser.add_argument('--save_dir', default= 'indexes/',type=str)\n",
        "\n",
        "    # Parameters for building dense index\n",
        "    parser.add_argument('--max_length', type=int, default=180)\n",
        "    parser.add_argument('--batch_size', type=int, default=512)\n",
        "    parser.add_argument('--use_fp16', default=False, action='store_true')\n",
        "    parser.add_argument('--pooling_method', type=str, default=None)\n",
        "    parser.add_argument('--faiss_type',default=None,type=str)\n",
        "    parser.add_argument('--embedding_path', default=None, type=str)\n",
        "    parser.add_argument('--save_embedding', action='store_true', default=False)\n",
        "    parser.add_argument('--faiss_gpu', default=False, action='store_true')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.pooling_method is None:\n",
        "        pooling_method = 'mean'\n",
        "        for k,v in MODEL2POOLING.items():\n",
        "            if k in args.retrieval_method.lower():\n",
        "                pooling_method = v\n",
        "                break\n",
        "    else:\n",
        "        if args.pooling_method not in ['mean','cls','pooler']:\n",
        "            raise NotImplementedError\n",
        "        else:\n",
        "            pooling_method = args.pooling_method\n",
        "\n",
        "\n",
        "    index_builder = Index_Builder(\n",
        "                        retrieval_method = args.retrieval_method,\n",
        "                        model_path = args.model_path,\n",
        "                        corpus_path = args.corpus_path,\n",
        "                        save_dir = args.save_dir,\n",
        "                        max_length = args.max_length,\n",
        "                        batch_size = args.batch_size,\n",
        "                        use_fp16 = args.use_fp16,\n",
        "                        pooling_method = pooling_method,\n",
        "                        faiss_type = args.faiss_type,\n",
        "                        embedding_path = args.embedding_path,\n",
        "                        save_embedding = args.save_embedding,\n",
        "                        faiss_gpu = args.faiss_gpu\n",
        "                    )\n",
        "    index_builder.build_index()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgx8KhiRYv1a"
      },
      "source": [
        "2.2 Build index\n",
        "\n",
        "Set up your variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4ul-XsY8ff",
        "outputId": "a5f22736-0ec1-4cc7-e29f-932a1b751ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus Path:  /content/drive/MyDrive/CS329X_Project/datasets/QACC/ConflictQA_corpus.jsonl\n",
            "Save Index Path:  /content/drive/MyDrive/CS329X_Project/datasets/QACC/index\n"
          ]
        }
      ],
      "source": [
        "# Set up variables\n",
        "import os\n",
        "corpus_folder = \"/content/drive/MyDrive/CS329X_Project/datasets/QACC\" # Folder of corpus\n",
        "corpus_file_name = \"ConflictQA_corpus.jsonl\" # Filename\n",
        "\n",
        "\n",
        "batch_size = 64 # you may need to set lower\n",
        "\n",
        "# Sanity check\n",
        "print(\"Corpus Path: \", os.path.join(corpus_folder, corpus_file_name))\n",
        "print(\"Save Index Path: \",  os.path.join(corpus_folder, \"index\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt0ujXOPY9BG"
      },
      "source": [
        "Run this code block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "8660deed496c47e5821e9cd144305f57",
            "be5bad62020c4b90b75281c9c9c371fc",
            "b82f129c1a334ac0892da96ef933444c",
            "ff5d484ead2a4e1c8ffb16688cea9a7e",
            "95812e572488406d81cdd68135276dfe",
            "34c774ab738544fa9bd0478c119c09be",
            "c7d54fcf616848c9ac14f0be47173e4b",
            "46a5d6d11ee646f0a1c2c394200b0fae",
            "52d178b313914beb9197b40508852907",
            "738fcf7c4e284da3b5ed15a61a68779d",
            "86f670f427d744a0b4025d77b954ce44",
            "0be4525aaa06411dbd023134175cfc69",
            "bc55da3fca6c4187a0953dd6069518c3",
            "f145e8a8816f4501b17a30f409f14093",
            "454a2ee4042c45bfa5cdb618a4341431",
            "a8b1d829c2b945e691ef6fdf2da0232d",
            "69f33bcbcb994472883848fbbee38222",
            "1a38998bbce3454f874e98b22451fdb5",
            "537a9c9d8f804539a6af523056e675e2",
            "c55a0cbabbdb4435b817f6f4dcd60378",
            "b988783880a145109303f20df3d96fca",
            "1de6ba139e234df5a1a973515d472caf",
            "a2c32915bf944ea6a3e96d9d130eb737",
            "d2136642b1cf414f820c291c30c61a82",
            "65f4bd71b7934aaf9471275fc7885cdb",
            "66b8446b54a2474899e742e3b5f7d02a",
            "e7dbae1a1ff94d30b6e9d83866e7af4f",
            "2a8bfb655e174817943099aa25db6f29",
            "24161fe75a7a4a24aaf1a47a9546cdfc",
            "fa8cca3be9434bd6acf6b9f5aff43cdb",
            "aa26fbc501d94f8aa97628a384fc90ed",
            "060d5dd7caaf432786c4ae49a1ffa9dd",
            "ab2771a615c6410f8dcaf59fb8692691",
            "93df9e0895944c57aeaffa3fb2b61d8b",
            "c676df9c24b841eaa83eec8d784b51da",
            "2d6d8b85dece4426b104383a24b75796",
            "0ce1092eeca24e99ab32118317fa54b3",
            "b9d6b40e6b1c4000a5123375c0cfe169",
            "d0c47d1aa6c446afa9c897e2e06e8cf7",
            "89ec1416d1674074a9ea63bbfb4cf3cc",
            "986e50d8a4d44e89aa4466a918774845",
            "c0c437959ebb43ffa6c2ee61844d3262",
            "46b3cd93ee33490e9758fc0ccf5bfb88",
            "533fb484453b4d378ef5cd90773cb93f",
            "bedf4f5c3ce0487dbd61819c924241a6",
            "b13661c38a9c49138805b77e99647cb4",
            "6791973c269848a48049a794007e8726",
            "ef8a545e4a6544209565d229afcb2d9d",
            "9a0074fe9dd843f98627329d80103d61",
            "870aee9f4c9e4b13bf31064034bbb704",
            "b13754541c854f4d8187bbdc61dca290",
            "6827513b8f574b3085098c7e17798f74",
            "d27f1187ea624a178f89bd7d6fa82192",
            "2c4a7eee48574c2c998db314ae99d493",
            "73e41db060e14462a2a3224b84f9b758",
            "5d063054d71e40e49900ab705f57f2a3",
            "86cd087d5b8f448da3660f172517d169",
            "00f11cdb2bc84e4f9eb82431ac4992bd",
            "de2a0b9da26940d1a9898a0db8cfc6d0",
            "a7105427c82942be8a68206b65bd18f2",
            "817a36082cee4b0cbba5cd66a4578ffa",
            "a11002b97a504a4baf05ea6b768e7405",
            "095254d538354f34b0814c7351e65fd1",
            "a47708b6c9fc435fb24e285dd82e9200",
            "19eb3d8a259d4c2d9dc710d6483d4bed",
            "6371ae310b3f43c680581d122666a8bc",
            "1dea30fce4b449589dbcef1df2b3743f",
            "5341eeb40e9f482ea36f77485ddf51a0",
            "19e2969215f645b198a9af3b08be0549",
            "80d75000ab1c43bda2a58239ad8a72f4",
            "037a12007c334a6ebbfb5a1d385f7eeb",
            "1035105d74604950929cfb4fb2b46188",
            "cd6d8482f9344b6aaeba70a1422d35f0",
            "12bf5a430064405b88af85238e585876",
            "9549df74dfc54c2a985b7bf45d614658",
            "9ecd176a498f4ced8832f5a0f925eed4",
            "6198003c51b049bf8a09adc4e33a1f46"
          ]
        },
        "id": "4cZMZbCMp1_S",
        "outputId": "b128d297-c8c4-44bd-c52b-47bead4f2629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS329X_Project/datasets/QACC/index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8660deed496c47e5821e9cd144305f57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish loading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be4525aaa06411dbd023134175cfc69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2c32915bf944ea6a3e96d9d130eb737"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93df9e0895944c57aeaffa3fb2b61d8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bedf4f5c3ce0487dbd61819c924241a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d063054d71e40e49900ab705f57f2a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dea30fce4b449589dbcef1df2b3743f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference Embeddings:: 100%|██████████| 232/232 [00:05<00:00, 43.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating index\n",
            "Finish!\n"
          ]
        }
      ],
      "source": [
        "# Run Retriever\n",
        "if __name__ == \"__main__\": #cba\n",
        "\n",
        "    # ----------------------------\n",
        "    # Set your configuration here\n",
        "    # ----------------------------\n",
        "    retrieval_method = \"e5\"               # e.g., \"e5\", \"bge\"\n",
        "    model_path = \"intfloat/e5-base-v2\"    # or local path\n",
        "    corpus_path = os.path.join(corpus_folder, corpus_file_name)\n",
        "    save_dir = os.path.join(corpus_folder, \"index\") # index_save_path = os.path.join(corpus_folder, \"index\") #\"/content/drive/MyDrive/CS329X_Project/search_agent_code/wikipedia_corpus/index\"\n",
        "    max_length = 256\n",
        "    batch_size = batch_size\n",
        "    use_fp16 = True\n",
        "    pooling_method = \"mean\"               # \"mean\", \"cls\", \"pooler\"\n",
        "    faiss_type = \"Flat\"\n",
        "    embedding_path = None                 # optional, if precomputed embeddings exist\n",
        "    save_embedding = False\n",
        "    faiss_gpu = True\n",
        "\n",
        "\n",
        "    # ----------------------------\n",
        "    # Build index\n",
        "    # ----------------------------\n",
        "    index_builder = Index_Builder(\n",
        "        retrieval_method=retrieval_method,\n",
        "        model_path=model_path,\n",
        "        corpus_path=corpus_path,\n",
        "        save_dir=save_dir,\n",
        "        max_length=max_length,\n",
        "        batch_size=batch_size,\n",
        "        use_fp16=use_fp16,\n",
        "        pooling_method=pooling_method,\n",
        "        faiss_type=faiss_type,\n",
        "        embedding_path=embedding_path,\n",
        "        save_embedding=save_embedding,\n",
        "        faiss_gpu=faiss_gpu\n",
        "    )\n",
        "\n",
        "    index_builder.build_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkgMLVNNdZDj"
      },
      "source": [
        "# 3. Run retrieval server"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAiPkmRqT7dN"
      },
      "source": [
        "3.1 Just run this block of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gI_fOcQiz3d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import warnings\n",
        "from typing import List, Dict, Optional\n",
        "import argparse\n",
        "\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "import datasets\n",
        "\n",
        "import uvicorn\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "def load_corpus(corpus_path: str):\n",
        "    corpus = datasets.load_dataset(\n",
        "        'json',\n",
        "        data_files=corpus_path,\n",
        "        split=\"train\",\n",
        "        num_proc=4\n",
        "    )\n",
        "    return corpus\n",
        "\n",
        "def read_jsonl(file_path):\n",
        "    data = []\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "def load_docs(corpus, doc_idxs):\n",
        "    results = [corpus[int(idx)] for idx in doc_idxs]\n",
        "    return results\n",
        "\n",
        "def load_model(model_path: str, use_fp16: bool = False):\n",
        "    model_config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
        "    model = AutoModel.from_pretrained(model_path, trust_remote_code=True)\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "    if use_fp16:\n",
        "        model = model.half()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True, trust_remote_code=True)\n",
        "    return model, tokenizer\n",
        "\n",
        "def pooling(\n",
        "    pooler_output,\n",
        "    last_hidden_state,\n",
        "    attention_mask = None,\n",
        "    pooling_method = \"mean\"\n",
        "):\n",
        "    if pooling_method == \"mean\":\n",
        "        last_hidden = last_hidden_state.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "    elif pooling_method == \"cls\":\n",
        "        return last_hidden_state[:, 0]\n",
        "    elif pooling_method == \"pooler\":\n",
        "        return pooler_output\n",
        "    else:\n",
        "        raise NotImplementedError(\"Pooling method not implemented!\")\n",
        "\n",
        "class Encoder:\n",
        "    def __init__(self, model_name, model_path, pooling_method, max_length, use_fp16):\n",
        "        self.model_name = model_name\n",
        "        self.model_path = model_path\n",
        "        self.pooling_method = pooling_method\n",
        "        self.max_length = max_length\n",
        "        self.use_fp16 = use_fp16\n",
        "\n",
        "        self.model, self.tokenizer = load_model(model_path=model_path, use_fp16=use_fp16)\n",
        "        self.model.eval()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode(self, query_list: List[str], is_query=True) -> np.ndarray:\n",
        "        # processing query for different encoders\n",
        "        if isinstance(query_list, str):\n",
        "            query_list = [query_list]\n",
        "\n",
        "        if \"e5\" in self.model_name.lower():\n",
        "            if is_query:\n",
        "                query_list = [f\"query: {query}\" for query in query_list]\n",
        "            else:\n",
        "                query_list = [f\"passage: {query}\" for query in query_list]\n",
        "\n",
        "        if \"bge\" in self.model_name.lower():\n",
        "            if is_query:\n",
        "                query_list = [f\"Represent this sentence for searching relevant passages: {query}\" for query in query_list]\n",
        "\n",
        "        inputs = self.tokenizer(query_list,\n",
        "                                max_length=self.max_length,\n",
        "                                padding=True,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\"\n",
        "                                )\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "        if \"T5\" in type(self.model).__name__:\n",
        "            # T5-based retrieval model\n",
        "            decoder_input_ids = torch.zeros(\n",
        "                (inputs['input_ids'].shape[0], 1), dtype=torch.long\n",
        "            ).to(inputs['input_ids'].device)\n",
        "            output = self.model(\n",
        "                **inputs, decoder_input_ids=decoder_input_ids, return_dict=True\n",
        "            )\n",
        "            query_emb = output.last_hidden_state[:, 0, :]\n",
        "        else:\n",
        "            output = self.model(**inputs, return_dict=True)\n",
        "            query_emb = pooling(output.pooler_output,\n",
        "                                output.last_hidden_state,\n",
        "                                inputs['attention_mask'],\n",
        "                                self.pooling_method)\n",
        "            if \"dpr\" not in self.model_name.lower():\n",
        "                query_emb = torch.nn.functional.normalize(query_emb, dim=-1)\n",
        "\n",
        "        query_emb = query_emb.detach().cpu().numpy()\n",
        "        query_emb = query_emb.astype(np.float32, order=\"C\")\n",
        "\n",
        "        del inputs, output\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return query_emb\n",
        "\n",
        "class BaseRetriever:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.retrieval_method = config.retrieval_method\n",
        "        self.topk = config.retrieval_topk\n",
        "\n",
        "        self.index_path = config.index_path\n",
        "        self.corpus_path = config.corpus_path\n",
        "\n",
        "    def _search(self, query: str, num: int, return_score: bool):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _batch_search(self, query_list: List[str], num: int, return_score: bool):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def search(self, query: str, num: int = None, return_score: bool = False):\n",
        "        return self._search(query, num, return_score)\n",
        "\n",
        "    def batch_search(self, query_list: List[str], num: int = None, return_score: bool = False):\n",
        "        return self._batch_search(query_list, num, return_score)\n",
        "\n",
        "class BM25Retriever(BaseRetriever):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        from pyserini.search.lucene import LuceneSearcher\n",
        "        self.searcher = LuceneSearcher(self.index_path)\n",
        "        self.contain_doc = self._check_contain_doc()\n",
        "        if not self.contain_doc:\n",
        "            self.corpus = load_corpus(self.corpus_path)\n",
        "        self.max_process_num = 8\n",
        "\n",
        "    def _check_contain_doc(self):\n",
        "        return self.searcher.doc(0).raw() is not None\n",
        "\n",
        "    def _search(self, query: str, num: int = None, return_score: bool = False):\n",
        "        if num is None:\n",
        "            num = self.topk\n",
        "        hits = self.searcher.search(query, num)\n",
        "        if len(hits) < 1:\n",
        "            if return_score:\n",
        "                return [], []\n",
        "            else:\n",
        "                return []\n",
        "        scores = [hit.score for hit in hits]\n",
        "        if len(hits) < num:\n",
        "            warnings.warn('Not enough documents retrieved!')\n",
        "        else:\n",
        "            hits = hits[:num]\n",
        "\n",
        "        if self.contain_doc:\n",
        "            all_contents = [\n",
        "                json.loads(self.searcher.doc(hit.docid).raw())['contents']\n",
        "                for hit in hits\n",
        "            ]\n",
        "            results = [\n",
        "                {\n",
        "                    'title': content.split(\"\\n\")[0].strip(\"\\\"\"),\n",
        "                    'text': \"\\n\".join(content.split(\"\\n\")[1:]),\n",
        "                    'contents': content\n",
        "                }\n",
        "                for content in all_contents\n",
        "            ]\n",
        "        else:\n",
        "            results = load_docs(self.corpus, [hit.docid for hit in hits])\n",
        "\n",
        "        if return_score:\n",
        "            return results, scores\n",
        "        else:\n",
        "            return results\n",
        "\n",
        "    def _batch_search(self, query_list: List[str], num: int = None, return_score: bool = False):\n",
        "        results = []\n",
        "        scores = []\n",
        "        for query in query_list:\n",
        "            item_result, item_score = self._search(query, num, True)\n",
        "            results.append(item_result)\n",
        "            scores.append(item_score)\n",
        "        if return_score:\n",
        "            return results, scores\n",
        "        else:\n",
        "            return results\n",
        "\n",
        "class DenseRetriever(BaseRetriever):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.index = faiss.read_index(self.index_path)\n",
        "        if config.faiss_gpu:\n",
        "            co = faiss.GpuMultipleClonerOptions()\n",
        "            co.useFloat16 = True\n",
        "            co.shard = True\n",
        "            self.index = faiss.index_cpu_to_all_gpus(self.index, co=co)\n",
        "\n",
        "        self.corpus = load_corpus(self.corpus_path)\n",
        "        self.encoder = Encoder(\n",
        "            model_name = self.retrieval_method,\n",
        "            model_path = config.retrieval_model_path,\n",
        "            pooling_method = config.retrieval_pooling_method,\n",
        "            max_length = config.retrieval_query_max_length,\n",
        "            use_fp16 = config.retrieval_use_fp16\n",
        "        )\n",
        "        self.topk = config.retrieval_topk\n",
        "        self.batch_size = config.retrieval_batch_size\n",
        "\n",
        "    def _search(self, query: str, num: int = None, return_score: bool = False):\n",
        "        if num is None:\n",
        "            num = self.topk\n",
        "        query_emb = self.encoder.encode(query)\n",
        "        scores, idxs = self.index.search(query_emb, k=num)\n",
        "        idxs = idxs[0]\n",
        "        scores = scores[0]\n",
        "        results = load_docs(self.corpus, idxs)\n",
        "        if return_score:\n",
        "            return results, scores.tolist()\n",
        "        else:\n",
        "            return results\n",
        "\n",
        "    def _batch_search(self, query_list: List[str], num: int = None, return_score: bool = False):\n",
        "        if isinstance(query_list, str):\n",
        "            query_list = [query_list]\n",
        "        if num is None:\n",
        "            num = self.topk\n",
        "\n",
        "        results = []\n",
        "        scores = []\n",
        "        for start_idx in tqdm(range(0, len(query_list), self.batch_size), desc='Retrieval process: '):\n",
        "            query_batch = query_list[start_idx:start_idx + self.batch_size]\n",
        "            batch_emb = self.encoder.encode(query_batch)\n",
        "            batch_scores, batch_idxs = self.index.search(batch_emb, k=num)\n",
        "            batch_scores = batch_scores.tolist()\n",
        "            batch_idxs = batch_idxs.tolist()\n",
        "\n",
        "            # load_docs is not vectorized, but is a python list approach\n",
        "            flat_idxs = sum(batch_idxs, [])\n",
        "            batch_results = load_docs(self.corpus, flat_idxs)\n",
        "            # chunk them back\n",
        "            batch_results = [batch_results[i*num : (i+1)*num] for i in range(len(batch_idxs))]\n",
        "\n",
        "            results.extend(batch_results)\n",
        "            scores.extend(batch_scores)\n",
        "\n",
        "            del batch_emb, batch_scores, batch_idxs, query_batch, flat_idxs, batch_results\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if return_score:\n",
        "            return results, scores\n",
        "        else:\n",
        "            return results\n",
        "\n",
        "def get_retriever(config):\n",
        "    if config.retrieval_method == \"bm25\":\n",
        "        return BM25Retriever(config)\n",
        "    else:\n",
        "        return DenseRetriever(config)\n",
        "\n",
        "\n",
        "#####################################\n",
        "# FastAPI server below\n",
        "#####################################\n",
        "\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    Minimal config class (simulating your argparse)\n",
        "    Replace this with your real arguments or load them dynamically.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        retrieval_method: str = \"bm25\",\n",
        "        retrieval_topk: int = 10,\n",
        "        index_path: str = \"./index/bm25\",\n",
        "        corpus_path: str = \"./data/corpus.jsonl\",\n",
        "        dataset_path: str = \"./data\",\n",
        "        data_split: str = \"train\",\n",
        "        faiss_gpu: bool = True,\n",
        "        retrieval_model_path: str = \"./model\",\n",
        "        retrieval_pooling_method: str = \"mean\",\n",
        "        retrieval_query_max_length: int = 256,\n",
        "        retrieval_use_fp16: bool = False,\n",
        "        retrieval_batch_size: int = 128\n",
        "    ):\n",
        "        self.retrieval_method = retrieval_method\n",
        "        self.retrieval_topk = retrieval_topk\n",
        "        self.index_path = index_path\n",
        "        self.corpus_path = corpus_path\n",
        "        self.dataset_path = dataset_path\n",
        "        self.data_split = data_split\n",
        "        self.faiss_gpu = faiss_gpu\n",
        "        self.retrieval_model_path = retrieval_model_path\n",
        "        self.retrieval_pooling_method = retrieval_pooling_method\n",
        "        self.retrieval_query_max_length = retrieval_query_max_length\n",
        "        self.retrieval_use_fp16 = retrieval_use_fp16\n",
        "        self.retrieval_batch_size = retrieval_batch_size\n",
        "\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    queries: List[str]\n",
        "    topk: Optional[int] = None\n",
        "    return_scores: bool = False\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/retrieve\")\n",
        "def retrieve_endpoint(request: QueryRequest):\n",
        "    \"\"\"\n",
        "    Endpoint that accepts queries and performs retrieval.\n",
        "    Input format:\n",
        "    {\n",
        "      \"queries\": [\"What is Python?\", \"Tell me about neural networks.\"],\n",
        "      \"topk\": 3,\n",
        "      \"return_scores\": true\n",
        "    }\n",
        "    \"\"\"\n",
        "    if not request.topk:\n",
        "        request.topk = config.retrieval_topk  # fallback to default\n",
        "\n",
        "    # Perform batch retrieval\n",
        "    results, scores = retriever.batch_search(\n",
        "        query_list=request.queries,\n",
        "        num=request.topk,\n",
        "        return_score=request.return_scores\n",
        "    )\n",
        "\n",
        "    # Format response\n",
        "    resp = []\n",
        "    for i, single_result in enumerate(results):\n",
        "        if request.return_scores:\n",
        "            # If scores are returned, combine them with results\n",
        "            combined = []\n",
        "            for doc, score in zip(single_result, scores[i]):\n",
        "                combined.append({\"document\": doc, \"score\": score})\n",
        "            resp.append(combined)\n",
        "        else:\n",
        "            resp.append(single_result)\n",
        "    return {\"result\": resp}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br8wKvIKbwPZ"
      },
      "source": [
        "3.2 Set Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset configurations, for your reference:\n",
        "\n",
        "DebateQA\n",
        "- Corpus Folder: \"/datasets/DebateQA\"\n",
        "- Corpus File Name: \"DebateQA_corpus.jsonl\"\n",
        "\n",
        "Researchy\n",
        "- Corpus Folder: \"/datasets/ResearchyQA\"\n",
        "- Corpus File Name: \"ResearchyQA_corpus.jsonl\"\n",
        "\n",
        "QACC\n",
        "- Corpus Folder: \"/datasets/QACC\"\n",
        "- Corpus File Name: \"ConflictQA_corpus.jsonl\"\n",
        "\n",
        "AmbigQA\n",
        "- Corpus Folder: \"/datasets/AmbigQA\"\n",
        "- Corpus File Name: \"AmbigQA_corpus.jsonl\""
      ],
      "metadata": {
        "id": "2MjV5iW6d8Me"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n271zzyDb11e",
        "outputId": "f937e033-40ad-46e2-80f9-4d2a32e0fd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus Path:  /content/drive/MyDrive/CS329X_Project/datasets/QACC/ConflictQA_corpus.jsonl\n",
            "Index Path:  /content/drive/MyDrive/CS329X_Project/datasets/QACC/index/e5_Flat.index\n"
          ]
        }
      ],
      "source": [
        "# # Set up variables\n",
        "# corpus_folder = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/wikipedia_corpus\"\n",
        "# corpus_file_name = \"mini-wiki-18.jsonl\"\n",
        "corpus_folder = \"/content/drive/MyDrive/CS329X_Project/datasets/QACC\"#DebateQA\"\n",
        "corpus_file_name = \"ConflictQA_corpus.jsonl\"\n",
        "index_dir = \"index/e5_Flat.index\" # DO NOT CHANGE\n",
        "topk = 5 # number of documents to retrieve per search.\n",
        "\n",
        "# Sanity check\n",
        "print(\"Corpus Path: \", os.path.join(corpus_folder, corpus_file_name))\n",
        "print(\"Index Path: \",  os.path.join(corpus_folder, index_dir))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrsOWOSjbyRi"
      },
      "source": [
        "3.3 Run retrieval server. Just run the code.\n",
        "\n",
        "If you want to stop server, uncomment the \"Stop Server\" block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5qNcNTWFNAD",
        "outputId": "eb90b387-c18c-4dfe-dde9-90734d17d7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [3584]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     parser = argparse.ArgumentParser(description=\"Launch the local faiss retriever.\")\n",
        "#     parser.add_argument(\"--index_path\", type=str, default=\"/home/peterjin/mnt/index/wiki-18/e5_Flat.index\", help=\"Corpus indexing file.\")\n",
        "#     parser.add_argument(\"--corpus_path\", type=str, default=\"/home/peterjin/mnt/data/retrieval-corpus/wiki-18.jsonl\", help=\"Local corpus file.\")\n",
        "#     parser.add_argument(\"--topk\", type=int, default=3, help=\"Number of retrieved passages for one query.\")\n",
        "#     parser.add_argument(\"--retriever_name\", type=str, default=\"e5\", help=\"Name of the retriever model.\")\n",
        "#     parser.add_argument(\"--retriever_model\", type=str, default=\"intfloat/e5-base-v2\", help=\"Path of the retriever model.\")\n",
        "#     parser.add_argument('--faiss_gpu', action='store_true', help='Use GPU for computation')\n",
        "\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "# 1) Build a config (could also parse from arguments).\n",
        "#    In real usage, you'd parse your CLI arguments or environment variables.\n",
        "config = Config(\n",
        "    retrieval_method = \"e5\",  # or \"dense\"\n",
        "    index_path=os.path.join(corpus_folder, index_dir),\n",
        "    corpus_path=os.path.join(corpus_folder, corpus_file_name),\n",
        "    retrieval_topk=topk,\n",
        "    faiss_gpu=True,\n",
        "    retrieval_model_path=\"intfloat/e5-base-v2\",\n",
        "    retrieval_pooling_method=\"mean\",\n",
        "    retrieval_query_max_length=256,\n",
        "    retrieval_use_fp16=True,\n",
        "    retrieval_batch_size=512,\n",
        ")\n",
        "\n",
        "# 2) Instantiate a global retriever so it is loaded once and reused.\n",
        "retriever = get_retriever(config)\n",
        "\n",
        "# 3) Launch the server. By default, it listens on http://127.0.0.1:8000\n",
        "#uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# # Stop Server\n",
        "# stop_event = threading.Event()\n",
        "# stop_event.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QafCcPmnVJ4J"
      },
      "source": [
        "# Save New Search Agents to Local Storage (usually not needed)\n",
        "\n",
        "This is the code to save search agents from Hugging Face in our shared folder (this makes loading our model faster). I saved Search-R1 in our shared folder already, so you  can just ignore.\n",
        "\n",
        "If you want to load other search agents, just uncomment the code block below and change the variables: save_dir, model_name, model_id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the search agent models we used from Hugging Face:\n",
        "\n",
        "- Search-R1: \"PeterJinGo/SearchR1-nq_hotpotqa_train-qwen2.5-7b-em-ppo\"\n",
        "- DeSA: \"Blancokdb/DeSA-Qwen2.5-7B-Instruct-Stage2\"\n",
        "- S3: \"pat-jj/s3-8-3-3-20steps\"\n"
      ],
      "metadata": {
        "id": "Qh_GeDzIeX1T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2lZ8AWwZSZ4"
      },
      "outputs": [],
      "source": [
        "# Set up Variables\n",
        "save_dir = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/models\" # DO NOT CHANGE\n",
        "model_name = \"desa/3b\" # for search_r1, we have search_r1/3b and search_r1/7b\n",
        "model_id = \"Blancokdb/DeSA-Qwen2.5-7B-Instruct-Stage2\" # use name from hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "yr1s7MqgDssP",
        "outputId": "3d761e8e-1194-467a-8e19-5b38f9f49063"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_id' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2365241249.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, torch_dtype=torch.bfloat16, device_map=\"auto\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_id' is not defined"
          ]
        }
      ],
      "source": [
        "# Load and Save Model to Drive\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "\n",
        "model_dir = os.path.join(save_dir, model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id, torch_dtype=torch.bfloat16)#, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"cuda\")\n",
        "\n",
        "model.save_pretrained(model_dir) # \"/content/drive/MyDrive/CS329X_Project/search_agent_code/search_r1/3b\"\n",
        "tokenizer.save_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMT3JRVqqsaC",
        "outputId": "9dca703b-4c75-491c-ae5a-45185609641d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "added_tokens.json                 model-00002-of-00002.safetensors\n",
            "chat_template.jinja               model.safetensors.index.json\n",
            "config.json                       special_tokens_map.json\n",
            "generation_config.json            tokenizer_config.json\n",
            "merges.txt                        tokenizer.json\n",
            "model-00001-of-00002.safetensors  vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls \"/content/drive/MyDrive/CS329X_Project/search_agent_code/models/desa/3b\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHh7fGVjXCFX"
      },
      "source": [
        "# 4. Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nqoYVL0ZXuh"
      },
      "outputs": [],
      "source": [
        "# Define Variables\n",
        "save_dir = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/models\" # DO NOT CHANGE\n",
        "model_name = \"s3\" # for search_r1, we have search_r1/3b and search_r1/7b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(model_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ_acSvr5DB9",
        "outputId": "fe5d451d-1561-4deb-a057-178ed92ca304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['config.json', 'generation_config.json', 'model-00001-of-00004.safetensors', 'model-00002-of-00004.safetensors', 'model-00003-of-00004.safetensors', 'model-00004-of-00004.safetensors', 'model.safetensors.index.json', 'chat_template.jinja', 'tokenizer_config.json', 'special_tokens_map.json', 'added_tokens.json', 'vocab.json', 'merges.txt', 'tokenizer.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "422080f5471545f38f53e758b003ea57",
            "2e6251b8b4474d4d9f3d40c3c0ae1716",
            "f8362ffc7a6644f2be326ef3a08c4a64",
            "72f2bb290dc84293924173bed45641c6",
            "f0dd0a1d68cb41959916dfa54667ec32",
            "8df454d16f374a59a656404f096e2099",
            "d64f01efd9ba4be7b0314fcedf64a82d",
            "89d6cc728e30431f885c648fa6cc7ebe",
            "b643596b9be4467287da3125c6c6fccf",
            "8bd5b70980364bb19b084b360177828f",
            "2dd06ee52a554783ae0ce572e4fbe1eb"
          ]
        },
        "id": "UpNuugQoDvRX",
        "outputId": "2855bc50-cd86-4fc4-ec70-e5b42fb5c5f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "422080f5471545f38f53e758b003ea57"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load Model from Drive\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "import os\n",
        "# Run this code below\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Set device to CUDA\n",
        "\n",
        "# Load the model and tokenizer from your saved directory\n",
        "model_dir = os.path.join(save_dir, model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir, dtype = torch.bfloat16, device_map=\"cuda\")#,trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir, dtype = torch.bfloat16, device_map=\"cuda\")#,trust_remote_code=True)#, dtype = torch.bfloat16, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMP_jq-h7LBt"
      },
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2uGjTFbcpQl"
      },
      "source": [
        "# 5. Test run your Search Agent (just for debugging)\n",
        "\n",
        "Your search agent should be loaded now. Test on a single query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MYH8CC9dx5P"
      },
      "outputs": [],
      "source": [
        "question = \"Who did Real Madrid win La Decima against in the final?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAQnAg9sQyAg",
        "outputId": "dd88adb0-3e07-4abe-e170-7673894e4b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "################# [Start Reasoning + Searching] ##################\n",
            "\n",
            "\n",
            "<|im_start|>system\n",
            "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "Answer the given question. You must conduct reasoning inside <think> and </think> first every time you get new information. After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. You can search as many times as your want. If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations. For example, <answer> Beijing </answer>. Question: Who did Real Madrid win La Decima against in the final?\n",
            "<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:56440 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "<think> I need to check who Real Madrid won against in the final to get La Decima. </think>\n",
            "<search> Real Madrid La Decima final winner </search>\n",
            "<information>Doc 1(Title: \"European Cup and UEFA Champions League history\") the treble. Real Madrid won their long-awaited \"\"La Decima\"\" (translates into Spanish as \"\"the tenth\"\"), their record-breaking tenth European Cup/UEFA Champions League title, in the 2013–14 season after winning 4–1 in extra time in the final against city rivals and La Liga champions Atlético Madrid. It was the first same-city final and the second all-Spanish final. Diego Simeone coached Atlético in an incredible season after clinching the Spanish league title a week before the final and his side lead 1–0 through Diego Godín until a Sergio Ramos header deep into injury time took it to extra time. The next year,\n",
            "Doc 2(Title: \"Football in Madrid\") League finals. Historically, Atletico has won 10 national league titles and 10 national cup titles. The final matches for the UEFA Euro 1964 and the 1982 FIFA World Cup, were held at Bernabéu, thus making Madrid the first city in Europe to host both a UEFA European Championship and a FIFA World Cup final. Some of Spain's top footballers are Madrilenians (born in Madrid), including Real Madrid former captains Emilio Butragueño (and co-teammate of La Quinta del Buitre, \"\"The Vulture's Cohort\"\"), Raúl or Iker Casillas and Atlético Madrid player Fernando Torres. In 2018, Madrid produced two clubs, UEFA Champions League\n",
            "Doc 3(Title: \"Zinedine Zidane\") the 2016 UEFA Champions League final by beating Manchester City 1–0 on aggregate. In La Liga, Real Madrid finished runners up, just one point behind Barcelona. In the Champions League final on 28 May, Real Madrid defeated fellow Madrid club Atlético Madrid in a penalty shootout to grab the 11th European Cup (\"\"La Undécima\"\") in club history. Zidane became the seventh man to win the European Cup (now UEFA Champions League) as both a player and a manager, the second man (after Miguel Muñoz) to win the trophy with Real Madrid as both a player and a manager, and the\n",
            "Doc 4(Title: \"Santiago Bernabéu Yeste\") while the World Cup was being played in Argentina. In his honour FIFA decreed three days of mourning during the tournament. In 2002, he was posthumously awarded the FIFA Order of Merit. Notes Santiago Bernabéu Yeste Santiago Bernabéu de Yeste (; 8 June 1895 – 2 June 1978) was a footballer who played for Real Madrid as a forward, and is one of the most important men in Real Madrid's history. He is generally considered the one to whom much of the credit can be given for transforming Real Madrid C.F. into the most successful football club in Spain and\n",
            "Doc 5(Title: \"Marco Asensio\") Calvià, as a defender. Asensio's goal celebration in the 2017 Champions League final was dedicated to his family: \"\"I told them that if I scored then I'd run to where they were. I knew where they were and this is what I did.\"\" (Spain score listed first, score column indicates score after each Asensio goal) Real Madrid Spain U19 Marco Asensio Marco Asensio Willemsen (; born 21 January 1996) is a Spanish professional footballer who plays as a winger and attacking midfielder for Real Madrid and the Spain national team. After starting out at Mallorca, he signed with Real Madrid\n",
            "</information>\n",
            "\n",
            "\n",
            "From the information provided, it's clear that Real Madrid won La Decima in the 2013–14 season against Atlético Madrid.\n",
            "\n",
            "<answer> Atlético Madrid </answer>\n",
            "\n",
            "The final score was 4-1 in favor of Real Madrid, taking it to extra time.\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "\n",
        "# Model ID and device setup\n",
        "# model_id = \"PeterJinGo/SearchR1-nq_hotpotqa_train-qwen2.5-7b-em-ppo\"\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "question = question.strip()\n",
        "if question[-1] != '?':\n",
        "    question += '?'\n",
        "curr_eos = [151645, 151643] # for Qwen2.5 series models\n",
        "curr_search_template = '\\n\\n{output_text}<information>{search_results}</information>\\n\\n'\n",
        "\n",
        "# Prepare the message\n",
        "prompt = f\"\"\"Answer the given question. \\\n",
        "You must conduct reasoning inside <think> and </think> first every time you get new information. \\\n",
        "After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. \\\n",
        "You can search as many times as your want. \\\n",
        "If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations. For example, <answer> Beijing </answer>. Question: {question}\\n\"\"\"\n",
        "\n",
        "# # Initialize the tokenizer and model\n",
        "# tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
        "# model = transformers.AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "\n",
        "# Define the custom stopping criterion\n",
        "class StopOnSequence(transformers.StoppingCriteria):\n",
        "    def __init__(self, target_sequences, tokenizer):\n",
        "        # Encode the string so we have the exact token-IDs pattern\n",
        "        self.target_ids = [tokenizer.encode(target_sequence, add_special_tokens=False) for target_sequence in target_sequences]\n",
        "        self.target_lengths = [len(target_id) for target_id in self.target_ids]\n",
        "        self._tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, input_ids, scores, **kwargs):\n",
        "        # Make sure the target IDs are on the same device\n",
        "        targets = [torch.as_tensor(target_id, device=input_ids.device) for target_id in self.target_ids]\n",
        "\n",
        "        if input_ids.shape[1] < min(self.target_lengths):\n",
        "            return False\n",
        "\n",
        "        # Compare the tail of input_ids with our target_ids\n",
        "        for i, target in enumerate(targets):\n",
        "            if torch.equal(input_ids[0, -self.target_lengths[i]:], target):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "def get_query(text):\n",
        "    import re\n",
        "    pattern = re.compile(r\"<search>(.*?)</search>\", re.DOTALL)\n",
        "    matches = pattern.findall(text)\n",
        "    if matches:\n",
        "        return matches[-1]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def search(query: str):\n",
        "    payload = {\n",
        "            \"queries\": [query],\n",
        "            \"topk\": 5,\n",
        "            \"return_scores\": True\n",
        "        }\n",
        "    results = requests.post(\"http://127.0.0.1:8000/retrieve\", json=payload).json()['result']\n",
        "\n",
        "    def _passages2string(retrieval_result):\n",
        "        format_reference = ''\n",
        "        for idx, doc_item in enumerate(retrieval_result):\n",
        "\n",
        "            content = doc_item['document']['contents']\n",
        "            # print(content)\n",
        "            # raise Exception(\"error\")\n",
        "            #exit(0)#['set']\n",
        "            title = content.split(\"\\n\")[0]\n",
        "            text = \"\\n\".join(content.split(\"\\n\")[1:])\n",
        "            format_reference += f\"Doc {idx+1}(Title: {title}) {text}\\n\"\n",
        "        return format_reference\n",
        "\n",
        "    return _passages2string(results[0])\n",
        "\n",
        "\n",
        "# Initialize the stopping criteria\n",
        "target_sequences = [\"</search>\", \" </search>\", \"</search>\\n\", \" </search>\\n\", \"</search>\\n\\n\", \" </search>\\n\\n\"]\n",
        "stopping_criteria = transformers.StoppingCriteriaList([StopOnSequence(target_sequences, tokenizer)])\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "if tokenizer.chat_template:\n",
        "    prompt = tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], add_generation_prompt=True, tokenize=False)\n",
        "\n",
        "print('\\n\\n################# [Start Reasoning + Searching] ##################\\n\\n')\n",
        "print(prompt)\n",
        "# Encode the chat-formatted prompt and move it to the correct device\n",
        "while True:\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "    attention_mask = torch.ones_like(input_ids)\n",
        "\n",
        "    # Generate text with the stopping criteria\n",
        "    outputs = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=1024,\n",
        "        stopping_criteria=stopping_criteria,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    if outputs[0][-1].item() in curr_eos:\n",
        "        generated_tokens = outputs[0][input_ids.shape[1]:]\n",
        "        output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "        print(output_text)\n",
        "        break\n",
        "\n",
        "    generated_tokens = outputs[0][input_ids.shape[1]:]\n",
        "    output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    tmp_query = get_query(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "    if tmp_query:\n",
        "        # print(f'searching \"{tmp_query}\"...')\n",
        "        search_results = search(tmp_query)\n",
        "    else:\n",
        "        search_results = ''\n",
        "\n",
        "    search_text = curr_search_template.format(output_text=output_text, search_results=search_results)\n",
        "    prompt += search_text\n",
        "    cnt += 1\n",
        "    print(search_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rNZSjlOeB5y"
      },
      "source": [
        "# 6. Evaluate Search Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfpi7YP3VJyJ"
      },
      "source": [
        "6.1 Load datasets\n",
        "\n",
        "Feel free to change the loaded dataset to your own one. I think this code expects a \"Dataset\" object (from Hugging Face) right now. We might need to do that too for your code.\n",
        "\n",
        "Note: Please make sure that questions are stored under the \"question\" key. (e.g., {'question': 'question contents'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV7MqoVhDAk3"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjkRlDti_LgU"
      },
      "outputs": [],
      "source": [
        "# Define the custom stopping criterion\n",
        "class StopOnSequence(transformers.StoppingCriteria):\n",
        "    def __init__(self, target_sequences, tokenizer):\n",
        "        # Encode the string so we have the exact token-IDs pattern\n",
        "        self.target_ids = [tokenizer.encode(target_sequence, add_special_tokens=False) for target_sequence in target_sequences]\n",
        "        self.target_lengths = [len(target_id) for target_id in self.target_ids]\n",
        "        self._tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, input_ids, scores, **kwargs):\n",
        "        # Make sure the target IDs are on the same device\n",
        "        targets = [torch.as_tensor(target_id, device=input_ids.device) for target_id in self.target_ids]\n",
        "\n",
        "        if input_ids.shape[1] < min(self.target_lengths):\n",
        "            return False\n",
        "\n",
        "        # Compare the tail of input_ids with our target_ids\n",
        "        for i, target in enumerate(targets):\n",
        "            if torch.equal(input_ids[0, -self.target_lengths[i]:], target):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "def get_query(text):\n",
        "    import re\n",
        "    pattern = re.compile(r\"<search>(.*?)</search>\", re.DOTALL)\n",
        "    matches = pattern.findall(text)\n",
        "    if matches:\n",
        "        return matches[-1]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def search(query: str):\n",
        "    payload = {\n",
        "            \"queries\": [query],\n",
        "            \"topk\": 5,\n",
        "            \"return_scores\": True\n",
        "        }\n",
        "    results = requests.post(\"http://127.0.0.1:8000/retrieve\", json=payload).json()['result']\n",
        "\n",
        "    def _passages2string(retrieval_result):\n",
        "        format_reference = ''\n",
        "        for idx, doc_item in enumerate(retrieval_result):\n",
        "\n",
        "            content = doc_item['document']['contents']\n",
        "            # print(content)\n",
        "            # raise Exception(\"error\")\n",
        "            #exit(0)#['set']\n",
        "            title = content.split(\"\\n\")[0]\n",
        "            text = \"\\n\".join(content.split(\"\\n\")[1:])\n",
        "            format_reference += f\"Doc {idx+1}(Title: {title}) {text}\\n\"\n",
        "        return format_reference\n",
        "\n",
        "    return _passages2string(results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d4754cf65636476bb2f0475e391fbf6c",
            "7d10cefb3df3441e84002eebdee6d59b",
            "9c424e06fbde4352ab979c10bc182c96",
            "cfedc9cd4b0b48afaf1358f729f3118f",
            "c9ab2c4172fc4a99ad442368fe49fdd0",
            "0111cd9426d4469f905bc3fd7d1a6afa",
            "d30cea283ad74809b8bafde7660a071c",
            "8444ff87de21454ea9881ce80d3de421",
            "8461a26991004e23be431d5c79df902f",
            "50471c8d3552400aae99763499b6a503",
            "b56b8ac28d64456cb517d1aae8d6a4a5"
          ]
        },
        "id": "AkLAOB-OVKZY",
        "outputId": "b79cdeb2-58c4-4dbf-d324-ed674f3bd66c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4754cf65636476bb2f0475e391fbf6c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# e.g., Load TriviaQA\n",
        "\n",
        "# 1. Load your eval dataset.\n",
        "#dataset = load_dataset(\"trivia_qa\", \"rc\")['validation'] # you can load your own eval dataset\n",
        "# dataset = load_dataset(\"akariasai/PopQA\", split=\"test\")\n",
        "# dataset = load_dataset(\"hotpotqa/hotpot_qa\",'fullwiki')['validation']\n",
        "#dataset = load_dataset('json', data_files='/content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_eval_100.jsonl')['train']\n",
        "dataset = load_dataset('json', data_files='/content/drive/MyDrive/CS329X_Project/datasets/AmbigQA/AmbigQA_eval_500.jsonl')['train']\n",
        "# Keep the ['train']\n",
        "\n",
        "# 2. Choose evaluation portion (if needed)\n",
        "# 3. Sample 20 data samples\n",
        "# eval_subset = dataset.select(range(20))\n",
        "eval_subset = dataset.select(range(404))#.select(range(2))#.select(range(5))#[0]  # small subset for testing\n",
        "\n",
        "# # Save as HuggingFace dataset format\n",
        "\n",
        "# eval_subset = dataset.shuffle(seed=42).select(range(500))\n",
        "\n",
        "# # Save as JSON lines\n",
        "# json_path = '/content/drive/MyDrive/CS329X_Project/datasets/AmbigQA/AmbigQA_eval_500.jsonl'\n",
        "# eval_subset.to_json(json_path)\n",
        "\n",
        "\n",
        "# # # Later load it back\n",
        "# # from datasets import load_from_disk\n",
        "# # reloaded_dataset = load_from_disk(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmDj0565aPR0",
        "outputId": "bfebd71a-4175-455e-be52-575468a5e65c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'role': ['user'],\n",
              " 'question': ['When did the first large winter carnival take place in quebec city?']}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# View the data:\n",
        "eval_subset[:1]#[:1]#.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECWFpL8sehEh"
      },
      "source": [
        "6.2 Run this cell to load functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwaPEMfmUf3c"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "curr_eos = [151645, 151643] # for Qwen2.5 series models\n",
        "curr_search_template = '\\n\\n{output_text}<information>{search_results}</information>\\n\\n'\n",
        "\n",
        "\n",
        "# Initialize the stopping criteria\n",
        "target_sequences = [\"</search>\", \" </search>\", \"</search>\\n\", \" </search>\\n\", \"</search>\\n\\n\", \" </search>\\n\\n\"]\n",
        "stopping_criteria = transformers.StoppingCriteriaList([StopOnSequence(target_sequences, tokenizer)])\n",
        "\n",
        "def answer_query(question, prompt): #, max_retries = 5):\n",
        "    question = question.strip()\n",
        "    if question[-1] != '?':\n",
        "        question += '?'\n",
        "    cnt = 0\n",
        "\n",
        "#     # Prepare the message\n",
        "#     prompt = f\"\"\"Answer the given question. \\\n",
        "# You must conduct reasoning inside <think> and </think> first every time you get new information. \\\n",
        "# After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. \\\n",
        "# You can search as many times as your want. \\\n",
        "# If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations. For example, <answer> Beijing </answer>. Question: {question}\\n\"\"\"\n",
        "# #    # Other Prompt\n",
        "# #     prompt = f\"\"\"Answer the given question. \\\n",
        "# # You may conduct reasoning inside <think> and </think> to plan searches and organize your thoughts. \\\n",
        "# # If you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. \\\n",
        "# # You can search as many times as you want. \\\n",
        "# # When writing your final answer, include all explanation, causal reasoning using words like 'because', alternative perspectives or caveats, and any references to facts you found in <information>, all inside <answer>…</answer>. \\\n",
        "# # Do not put step-by-step reasoning or search planning from <think> into <answer>; <answer> should be a clear synthesis of your reasoning and the information you gathered. \\\n",
        "# For example: <answer> Coffee contains caffeine, which can increase alertness and concentration because caffeine blocks adenosine receptors in the brain. According to the sources retrieved, this effect helps people focus and temporarily reduces fatigue. Some people, however, are sensitive to caffeine and may experience jitters, anxiety, or insomnia. </answer> \\\n",
        "# Question: {question}\\n\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if tokenizer.chat_template:\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            [{\"role\": \"user\", \"content\": prompt}],\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False\n",
        "        )\n",
        "\n",
        "    #print('\\n\\n################# [Start Reasoning + Searching] ##################\\n\\n')\n",
        "    #print(\"Prompt: \", prompt)\n",
        "\n",
        "    reasoning_chain = \"\"\n",
        "    #search_attempts = 0  # Track number of search attempts\n",
        "\n",
        "    # Encode the chat-formatted prompt and move it to the correct device\n",
        "    while True:\n",
        "        #print(device)\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "        attention_mask = torch.ones_like(input_ids, dtype=torch.float32).to(device)\n",
        "        #print(attention_mask.dtype)\n",
        "\n",
        "        #raise Exception\n",
        "        # # Tokenize and move everything to GPU\n",
        "        # inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "        # # Convert floating-point inputs to match model dtype (e.g., fp16)\n",
        "        # for k, v in inputs.items():\n",
        "        #     if torch.is_floating_point(v):\n",
        "        #         inputs[k] = v.to(model.dtype)\n",
        "        # input_ids = inputs[\"input_ids\"]\n",
        "        # # print(input_ids.shape)\n",
        "        # # raise Exception\n",
        "        # attention_mask = inputs.get(\"attention_mask\", torch.ones_like(input_ids, dtype=model.dtype))\n",
        "\n",
        "        # Generate text with the stopping criteria\n",
        "        outputs = model.generate(\n",
        "            input_ids, #input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_new_tokens=1024,\n",
        "            stopping_criteria=stopping_criteria,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "\n",
        "        if outputs[0][-1].item() in curr_eos:\n",
        "            generated_tokens = outputs[0][input_ids.shape[1]:]\n",
        "            output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "            reasoning_chain += output_text\n",
        "            #print(\"Output Text: \",output_text)\n",
        "            break\n",
        "\n",
        "        generated_tokens = outputs[0][input_ids.shape[1]:]\n",
        "        output_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "        tmp_query = get_query(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "        if tmp_query:\n",
        "            # # print(f'searching \"{tmp_query}\"...')\n",
        "            # search_attempts += 1\n",
        "            # if search_attempts > max_retries:\n",
        "            #     reasoning_chain += f\"\\n[Max retries reached without successful search]\\n\"\n",
        "            #     output_text = None  # indicate failure\n",
        "            #     break\n",
        "            search_results = search(tmp_query)\n",
        "        else:\n",
        "            search_results = ''\n",
        "\n",
        "        search_text = curr_search_template.format(\n",
        "            output_text=output_text,\n",
        "            search_results=search_results\n",
        "        )\n",
        "        prompt += search_text\n",
        "        cnt += 1\n",
        "        reasoning_chain += search_text + \"\\n\" # i forgot to add this first time.\n",
        "        #print(\"Search Text: \", search_text)\n",
        "\n",
        "    return {\"output_text\" : output_text, \"reasoning_chain\": reasoning_chain}\n",
        "\n",
        "# def answer_queries_parallel(questions, max_workers=4):\n",
        "#     results = [None] * len(questions)\n",
        "#     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "#         future_to_idx = {executor.submit(answer_query, q): i for i, q in enumerate(questions)}\n",
        "#         # Wrap as_completed with tqdm to show progress\n",
        "#         for future in tqdm(as_completed(future_to_idx), total=len(future_to_idx), desc=\"Answering Questions\"):\n",
        "#             idx = future_to_idx[future]\n",
        "#             results[idx] = future.result()\n",
        "#     return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFEbdlLdH_J-"
      },
      "source": [
        "Parallel version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9fyQEHZH8ho"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def answer_queries_parallel(questions, max_workers=4, max_retries=3):\n",
        "    results = [None] * len(questions)\n",
        "\n",
        "    def safe_answer_query(q, idx):\n",
        "        \"\"\"Wrapper that retries failed queries up to max_retries times.\"\"\"\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                return answer_query(q)\n",
        "            except Exception as e:\n",
        "                print(f\"[Warning] Query {idx} failed on attempt {attempt+1}/{max_retries}: {e}\")\n",
        "                # brief pause to avoid spamming GPU if memory-related\n",
        "                time.sleep(1)\n",
        "        # after max_retries, return a fallback value\n",
        "        return {\"output_text\": None, \"reasoning_chain\": f\"[Error] Failed after {max_retries} retries.\"}\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_idx = {executor.submit(safe_answer_query, q, i): i for i, q in enumerate(questions)}\n",
        "\n",
        "        for future in tqdm(as_completed(future_to_idx), total=len(future_to_idx), desc=\"Answering Questions\"):\n",
        "            idx = future_to_idx[future]\n",
        "            try:\n",
        "                results[idx] = future.result()\n",
        "            except Exception as e:\n",
        "                # catches any unexpected executor-level exceptions\n",
        "                print(f\"[Fatal] Query {idx} crashed outside retry loop: {e}\")\n",
        "                results[idx] = {\"output_text\": None, \"reasoning_chain\": f\"[Fatal error: {e}]\"}\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLYHMRAKe7PT"
      },
      "source": [
        "6.3 Set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69sl0SsJfDDD",
        "outputId": "2d2fa107-e87f-407a-c816-cc4f666dd25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save results into this directory:  /content/drive/MyDrive/CS329X_Project/search_agent_code/results/QACC/s3\n"
          ]
        }
      ],
      "source": [
        "# Where to save LLM output.\n",
        "results_folder = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/results\" # DO NOT CHANGE\n",
        "dataset_name = \"QACC\"\n",
        "model_name = \"s3\" # use other prompts.\n",
        "num_workers = 2 # for parallelization. 4 is probably the limit for Google's T4 GPU. If you want to go higher, use A100 from Colab Pro.\n",
        "have_groundtruth = False # if there is no groundtruth, set this to False\n",
        "\n",
        "# Sanity check:\n",
        "print(\"Save results into this directory: \", os.path.join(results_folder, dataset_name, model_name))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP_07ds3e-nN"
      },
      "source": [
        "6.4 Let search agent answer all the queries. You can choose non-parallel version / parallel version:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53IbL_SmIKdZ"
      },
      "source": [
        "Non-parallel version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSh_yPvMfwPV",
        "outputId": "dd944be2-34e5-4e5e-cbd0-0f101e05ab3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Answering Questions:   0%|          | 0/404 [00:00<?, ?it/s]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 22.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58420 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   0%|          | 1/404 [00:08<1:00:20,  8.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 91.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42620 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   0%|          | 2/404 [00:14<45:37,  6.81s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42630 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58152 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58168 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   1%|          | 3/404 [00:31<1:16:39, 11.47s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37932 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37934 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42312 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   1%|          | 4/404 [00:46<1:25:33, 12.83s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42324 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   1%|▏         | 6/404 [01:02<1:08:36, 10.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35952 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60818 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   2%|▏         | 7/404 [01:14<1:10:34, 10.67s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60824 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39148 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39160 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   2%|▏         | 9/404 [01:33<1:03:11,  9.60s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36374 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58242 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   2%|▏         | 10/404 [01:49<1:14:35, 11.36s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43398 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   3%|▎         | 11/404 [01:59<1:12:49, 11.12s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49946 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   3%|▎         | 12/404 [02:09<1:09:01, 10.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 91.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50480 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   3%|▎         | 13/404 [02:14<59:14,  9.09s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 91.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50492 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55320 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55328 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   3%|▎         | 14/404 [02:33<1:18:29, 12.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 90.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55790 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▎         | 15/404 [02:41<1:09:30, 10.72s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49392 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▍         | 16/404 [02:46<58:41,  9.08s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44666 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44678 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58876 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58888 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▍         | 17/404 [03:09<1:26:07, 13.35s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49550 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▍         | 18/404 [03:17<1:15:20, 11.71s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38058 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   5%|▍         | 19/404 [03:26<1:09:44, 10.87s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45560 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   5%|▍         | 20/404 [03:35<1:04:51, 10.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45576 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52180 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   5%|▌         | 21/404 [03:51<1:17:03, 12.07s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48450 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   6%|▌         | 23/404 [04:05<57:47,  9.10s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44976 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   6%|▌         | 24/404 [04:11<51:46,  8.17s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52276 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   6%|▌         | 25/404 [04:16<46:21,  7.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52292 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 27/404 [04:27<40:00,  6.37s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50948 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50950 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 28/404 [04:46<1:02:30,  9.97s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43726 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43740 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43744 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 29/404 [05:05<1:18:40, 12.59s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46148 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42582 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42584 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42592 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 30/404 [05:18<1:19:19, 12.73s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57086 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57100 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   8%|▊         | 31/404 [05:34<1:25:48, 13.80s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 90.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58042 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45602 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   8%|▊         | 33/404 [05:48<1:02:06, 10.05s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37314 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   8%|▊         | 34/404 [05:53<52:34,  8.53s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37328 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37334 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   9%|▊         | 35/404 [06:02<53:36,  8.72s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44392 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45778 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45792 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45796 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45806 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 57.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46640 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   9%|▉         | 36/404 [06:25<1:19:42, 12.99s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59258 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   9%|▉         | 37/404 [06:35<1:13:33, 12.03s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59262 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39198 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39202 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  10%|▉         | 39/404 [06:58<1:08:10, 11.21s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 91.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44186 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44188 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33670 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33688 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46860 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  10%|▉         | 40/404 [07:32<1:49:06, 17.99s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  10%|█         | 41/404 [07:40<1:30:14, 14.92s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47190 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  10%|█         | 42/404 [07:55<1:29:51, 14.89s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60532 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60542 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  11%|█         | 43/404 [08:13<1:36:05, 15.97s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45350 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52250 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  11%|█         | 45/404 [08:37<1:18:56, 13.19s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60920 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  11%|█▏        | 46/404 [08:51<1:19:39, 13.35s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43010 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  12%|█▏        | 47/404 [09:01<1:13:57, 12.43s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:32814 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  12%|█▏        | 48/404 [09:12<1:11:32, 12.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56818 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  12%|█▏        | 49/404 [09:26<1:14:06, 12.53s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60840 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  12%|█▏        | 50/404 [09:52<1:38:01, 16.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51744 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  13%|█▎        | 51/404 [10:00<1:22:58, 14.10s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42048 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42056 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42068 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38086 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38098 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  13%|█▎        | 52/404 [10:16<1:25:34, 14.59s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43288 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  13%|█▎        | 53/404 [10:31<1:25:40, 14.65s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51978 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  13%|█▎        | 54/404 [10:38<1:12:05, 12.36s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34802 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34810 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41394 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  14%|█▎        | 55/404 [10:57<1:23:24, 14.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54020 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54032 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40280 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  14%|█▍        | 56/404 [11:15<1:30:47, 15.65s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40282 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37334 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37350 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  14%|█▍        | 57/404 [11:35<1:37:25, 16.85s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39218 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  14%|█▍        | 58/404 [11:41<1:18:08, 13.55s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41826 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41842 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47426 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  15%|█▍        | 59/404 [12:06<1:38:25, 17.12s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46722 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  15%|█▍        | 60/404 [12:17<1:27:27, 15.26s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33666 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  15%|█▌        | 61/404 [12:24<1:13:22, 12.84s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  15%|█▌        | 62/404 [12:37<1:12:34, 12.73s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54878 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  16%|█▌        | 63/404 [12:46<1:07:00, 11.79s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36038 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36050 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36054 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  16%|█▌        | 65/404 [13:10<1:04:42, 11.45s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50716 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  17%|█▋        | 68/404 [13:28<42:39,  7.62s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51074 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  17%|█▋        | 69/404 [13:35<40:18,  7.22s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51086 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  17%|█▋        | 70/404 [13:45<46:08,  8.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43324 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60350 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  18%|█▊        | 71/404 [14:00<56:56, 10.26s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60572 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  18%|█▊        | 73/404 [14:12<43:03,  7.81s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33080 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  18%|█▊        | 74/404 [14:22<47:38,  8.66s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38376 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43770 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43776 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43788 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  19%|█▊        | 75/404 [14:41<1:02:59, 11.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48436 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43388 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43396 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  19%|█▉        | 76/404 [14:58<1:11:50, 13.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55390 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55396 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  19%|█▉        | 77/404 [15:10<1:10:54, 13.01s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59366 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  19%|█▉        | 78/404 [15:18<1:01:52, 11.39s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56934 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  20%|█▉        | 79/404 [15:26<56:52, 10.50s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40322 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40324 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40336 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  20%|█▉        | 80/404 [15:40<1:01:37, 11.41s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42942 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42944 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59112 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  20%|██        | 81/404 [15:53<1:05:04, 12.09s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59118 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44156 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44158 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  20%|██        | 82/404 [16:13<1:16:34, 14.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46332 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43534 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  21%|██        | 83/404 [16:32<1:24:29, 15.79s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41142 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  21%|██        | 85/404 [16:49<1:04:23, 12.11s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52940 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51322 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  21%|██▏       | 86/404 [17:05<1:09:59, 13.21s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51330 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49016 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49024 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36300 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  22%|██▏       | 87/404 [17:23<1:17:32, 14.68s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36304 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  22%|██▏       | 89/404 [17:40<1:01:21, 11.69s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45720 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  23%|██▎       | 91/404 [17:54<47:14,  9.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48668 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  23%|██▎       | 92/404 [18:09<57:12, 11.00s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46902 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46908 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46918 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44242 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44248 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 53.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44260 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  24%|██▎       | 95/404 [18:40<47:14,  9.17s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52656 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  24%|██▍       | 96/404 [18:47<43:19,  8.44s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52738 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  24%|██▍       | 97/404 [18:55<43:05,  8.42s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52746 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  24%|██▍       | 98/404 [19:03<41:31,  8.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54076 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60088 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60092 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60108 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 54.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47386 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▍       | 99/404 [19:27<1:05:59, 12.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42112 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▌       | 101/404 [19:39<47:35,  9.42s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48408 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46274 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▌       | 102/404 [19:55<57:28, 11.42s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46290 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35428 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35436 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▌       | 103/404 [20:10<1:02:39, 12.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47986 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48000 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  26%|██▌       | 104/404 [20:24<1:05:02, 13.01s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48900 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  26%|██▌       | 105/404 [20:32<56:17, 11.30s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40384 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40396 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  26%|██▋       | 107/404 [20:47<45:18,  9.15s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58624 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  27%|██▋       | 109/404 [21:03<42:43,  8.69s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35588 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33900 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33912 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33920 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52512 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  27%|██▋       | 110/404 [21:25<1:02:31, 12.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52522 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37444 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37450 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 57.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37466 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  27%|██▋       | 111/404 [21:43<1:09:07, 14.15s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50060 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50064 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  28%|██▊       | 112/404 [21:51<1:01:02, 12.54s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37876 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  28%|██▊       | 113/404 [21:59<54:05, 11.15s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37170 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  28%|██▊       | 114/404 [22:08<50:15, 10.40s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42964 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35854 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 57.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35856 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35868 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  29%|██▊       | 116/404 [22:36<54:15, 11.30s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50632 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  29%|██▉       | 117/404 [22:46<52:33, 10.99s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35314 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35326 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35328 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  29%|██▉       | 118/404 [23:00<56:22, 11.83s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46404 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  29%|██▉       | 119/404 [23:07<48:32, 10.22s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42122 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42136 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  30%|██▉       | 120/404 [23:20<52:41, 11.13s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56168 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  30%|██▉       | 121/404 [23:26<45:28,  9.64s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47002 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47012 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  30%|███       | 122/404 [23:39<49:51, 10.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57056 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  30%|███       | 123/404 [23:50<50:03, 10.69s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39812 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58492 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  31%|███       | 124/404 [24:03<53:41, 11.50s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38748 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  31%|███▏      | 127/404 [24:29<39:45,  8.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34804 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  32%|███▏      | 129/404 [24:42<34:06,  7.44s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40016 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40026 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35288 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35300 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  32%|███▏      | 130/404 [25:00<48:02, 10.52s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36208 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  32%|███▏      | 131/404 [25:08<44:45,  9.84s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33018 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33022 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33038 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  33%|███▎      | 132/404 [25:22<49:41, 10.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39564 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39572 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51390 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51400 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  33%|███▎      | 133/404 [25:40<58:33, 12.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48534 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  33%|███▎      | 134/404 [25:46<49:10, 10.93s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48546 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35218 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35222 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  33%|███▎      | 135/404 [25:59<52:24, 11.69s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48686 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  34%|███▍      | 137/404 [26:13<40:39,  9.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36602 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  34%|███▍      | 138/404 [26:20<37:49,  8.53s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51760 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  34%|███▍      | 139/404 [26:29<38:21,  8.68s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45000 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45002 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41446 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  35%|███▍      | 140/404 [26:52<57:22, 13.04s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53834 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  35%|███▍      | 141/404 [27:00<50:27, 11.51s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59196 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  35%|███▌      | 142/404 [27:11<49:28, 11.33s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33594 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47866 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  35%|███▌      | 143/404 [27:25<53:03, 12.20s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33134 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  36%|███▌      | 144/404 [27:41<56:47, 13.11s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56010 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  36%|███▌      | 145/404 [27:49<50:37, 11.73s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58326 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  36%|███▋      | 147/404 [28:06<43:09, 10.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42224 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  37%|███▋      | 148/404 [28:17<43:54, 10.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50910 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50916 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50922 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35412 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  37%|███▋      | 149/404 [28:34<52:11, 12.28s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35416 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54124 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54136 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  37%|███▋      | 150/404 [28:56<1:03:55, 15.10s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52484 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  37%|███▋      | 151/404 [29:08<1:00:19, 14.30s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36448 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  38%|███▊      | 152/404 [29:15<50:19, 11.98s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36462 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59150 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59158 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  38%|███▊      | 154/404 [29:35<44:22, 10.65s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34834 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  38%|███▊      | 155/404 [29:42<40:34,  9.78s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34840 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34846 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  39%|███▉      | 157/404 [29:59<36:58,  8.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46932 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  39%|███▉      | 158/404 [30:04<31:53,  7.78s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46942 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  39%|███▉      | 159/404 [30:11<30:47,  7.54s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60334 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  40%|███▉      | 160/404 [30:21<33:03,  8.13s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46918 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  40%|███▉      | 161/404 [30:40<46:31, 11.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57702 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  40%|████      | 162/404 [30:51<45:46, 11.35s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47792 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47802 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51572 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51578 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  40%|████      | 163/404 [31:08<52:27, 13.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54724 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54740 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54742 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  41%|████      | 164/404 [31:20<50:32, 12.64s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52878 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  41%|████▏     | 167/404 [31:35<29:15,  7.41s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45614 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  42%|████▏     | 168/404 [31:42<28:24,  7.22s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45620 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  42%|████▏     | 169/404 [31:52<31:30,  8.04s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59732 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46830 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46844 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46846 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  43%|████▎     | 173/404 [32:26<27:13,  7.07s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60768 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  43%|████▎     | 174/404 [32:36<30:30,  7.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37948 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37964 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37972 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▎     | 176/404 [32:58<34:03,  8.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40134 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40136 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40144 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▍     | 177/404 [33:14<41:42, 11.02s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47144 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▍     | 178/404 [33:23<38:40, 10.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39134 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45474 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45482 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▍     | 179/404 [33:42<48:16, 12.88s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37716 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37730 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  45%|████▍     | 180/404 [33:56<49:55, 13.37s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44774 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44786 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  45%|████▍     | 181/404 [34:10<50:49, 13.68s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51190 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  45%|████▌     | 182/404 [34:25<51:04, 13.80s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51194 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46286 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  45%|████▌     | 183/404 [34:40<52:41, 14.30s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41396 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41406 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34942 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▌     | 184/404 [34:55<53:15, 14.53s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59492 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59504 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59510 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▌     | 185/404 [35:12<55:23, 15.17s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57758 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57766 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52222 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52226 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▌     | 186/404 [35:30<58:21, 16.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51586 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▋     | 187/404 [35:36<47:12, 13.05s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44878 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44886 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  47%|████▋     | 188/404 [35:49<46:42, 12.97s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40538 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40544 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40550 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56182 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56198 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  47%|████▋     | 189/404 [36:11<56:39, 15.81s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37506 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37516 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51912 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  47%|████▋     | 190/404 [36:27<56:45, 15.92s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 90.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40560 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  47%|████▋     | 191/404 [36:36<48:29, 13.66s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40566 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49440 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49454 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  48%|████▊     | 192/404 [36:46<45:04, 12.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38066 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38080 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38094 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38106 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35152 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35168 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  48%|████▊     | 193/404 [37:08<53:53, 15.33s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53316 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  48%|████▊     | 194/404 [37:18<48:09, 13.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60204 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  48%|████▊     | 195/404 [37:26<41:59, 12.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59516 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59532 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53878 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  49%|████▊     | 196/404 [37:46<50:08, 14.47s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59504 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59518 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59520 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59534 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  49%|████▉     | 197/404 [38:03<52:34, 15.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45384 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36148 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36154 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36170 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53552 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  49%|████▉     | 198/404 [38:28<1:02:38, 18.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33434 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  50%|████▉     | 201/404 [38:52<37:02, 10.95s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39654 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39670 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34436 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  50%|█████     | 204/404 [39:20<31:55,  9.58s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44432 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  51%|█████     | 205/404 [39:27<29:10,  8.80s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58260 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  51%|█████     | 206/404 [39:33<26:25,  8.01s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45046 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45060 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  51%|█████     | 207/404 [39:45<30:10,  9.19s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45064 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  51%|█████▏    | 208/404 [39:53<28:58,  8.87s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51538 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51550 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57236 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57248 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57256 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  52%|█████▏    | 209/404 [40:10<37:12, 11.45s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35670 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  52%|█████▏    | 210/404 [40:16<30:58,  9.58s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35676 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57770 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  52%|█████▏    | 211/404 [40:33<38:16, 11.90s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59788 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  52%|█████▏    | 212/404 [40:41<34:43, 10.85s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44362 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45852 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  53%|█████▎    | 213/404 [41:03<44:53, 14.10s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41240 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  53%|█████▎    | 214/404 [41:15<42:59, 13.58s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39034 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39050 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39052 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  53%|█████▎    | 215/404 [41:31<44:47, 14.22s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50336 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  53%|█████▎    | 216/404 [41:39<38:59, 12.45s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54270 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  54%|█████▎    | 217/404 [41:58<44:19, 14.22s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60654 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60664 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60666 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  54%|█████▍    | 218/404 [42:17<48:41, 15.71s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40782 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  54%|█████▍    | 219/404 [42:28<43:52, 14.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43660 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43670 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57350 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  54%|█████▍    | 220/404 [42:49<49:43, 16.21s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50620 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50634 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  55%|█████▍    | 221/404 [43:04<48:21, 15.86s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50996 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55750 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55766 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55774 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  55%|█████▍    | 222/404 [43:25<53:25, 17.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60814 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  55%|█████▌    | 224/404 [43:44<39:48, 13.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40366 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41298 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  56%|█████▌    | 225/404 [44:04<45:46, 15.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51086 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50912 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50926 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  56%|█████▌    | 226/404 [44:19<44:55, 15.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45016 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45022 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  56%|█████▌    | 227/404 [44:33<44:05, 14.95s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35482 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  56%|█████▋    | 228/404 [44:41<37:24, 12.75s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56308 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56310 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51020 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51028 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51034 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  57%|█████▋    | 229/404 [45:06<48:07, 16.50s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54748 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  57%|█████▋    | 230/404 [45:16<42:17, 14.58s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56776 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  57%|█████▋    | 231/404 [45:26<37:51, 13.13s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56784 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56108 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  57%|█████▋    | 232/404 [45:38<36:45, 12.83s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56038 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 233/404 [45:45<31:35, 11.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59736 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 234/404 [45:56<31:06, 10.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48174 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 235/404 [46:10<33:29, 11.89s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44520 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44530 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 236/404 [46:23<34:12, 12.22s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51104 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  59%|█████▊    | 237/404 [46:33<32:30, 11.68s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38144 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  59%|█████▉    | 238/404 [46:39<27:31,  9.95s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  59%|█████▉    | 239/404 [46:47<25:25,  9.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45070 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45080 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45084 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40556 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  59%|█████▉    | 240/404 [47:06<33:43, 12.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35326 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35328 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35338 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 57.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44916 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  60%|█████▉    | 241/404 [47:23<37:22, 13.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44932 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54848 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56876 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  60%|█████▉    | 242/404 [47:51<48:32, 17.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37756 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  60%|██████    | 243/404 [47:59<40:16, 15.01s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34042 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  60%|██████    | 244/404 [48:13<39:23, 14.77s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39290 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36342 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36352 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████    | 245/404 [48:29<39:27, 14.89s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57706 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████    | 246/404 [48:39<35:53, 13.63s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33156 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33170 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████    | 247/404 [48:55<37:21, 14.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46514 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████▏   | 248/404 [49:05<33:20, 12.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55022 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55034 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  62%|██████▏   | 250/404 [49:24<27:37, 10.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46126 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  62%|██████▏   | 252/404 [49:43<24:52,  9.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43534 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43546 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35744 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  63%|██████▎   | 253/404 [49:55<26:40, 10.60s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53702 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53704 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53718 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  63%|██████▎   | 254/404 [50:10<29:44, 11.89s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41102 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  63%|██████▎   | 255/404 [50:20<28:13, 11.37s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45932 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45948 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:32938 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  63%|██████▎   | 256/404 [50:33<29:34, 11.99s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:32954 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45446 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  64%|██████▎   | 257/404 [50:46<29:30, 12.04s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57814 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  64%|██████▍   | 258/404 [50:52<25:20, 10.41s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57816 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  64%|██████▍   | 259/404 [50:59<22:40,  9.38s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51810 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  64%|██████▍   | 260/404 [51:08<22:10,  9.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47640 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47642 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47652 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  65%|██████▍   | 261/404 [51:23<26:16, 11.02s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37050 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  65%|██████▍   | 262/404 [51:31<23:59, 10.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39946 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  65%|██████▌   | 263/404 [51:39<22:18,  9.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48952 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48960 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  65%|██████▌   | 264/404 [51:54<25:51, 11.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36920 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37348 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 54.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37364 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  66%|██████▌   | 265/404 [52:10<28:43, 12.40s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49646 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49654 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36430 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  66%|██████▌   | 266/404 [52:25<30:29, 13.26s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55840 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  66%|██████▌   | 267/404 [52:33<26:53, 11.77s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55856 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48154 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48168 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48176 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45226 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  66%|██████▋   | 268/404 [52:53<32:17, 14.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45230 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41824 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 269/404 [53:08<32:09, 14.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48388 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48394 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48396 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 270/404 [53:20<30:54, 13.84s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37572 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37578 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 271/404 [53:31<28:37, 12.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54162 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 272/404 [53:41<26:12, 11.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42714 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42724 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  68%|██████▊   | 273/404 [53:57<28:54, 13.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44410 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44416 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  69%|██████▊   | 277/404 [54:22<14:58,  7.07s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49510 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  69%|██████▉   | 278/404 [54:31<16:18,  7.77s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41710 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41726 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44988 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44996 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  69%|██████▉   | 279/404 [54:49<22:15, 10.68s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59044 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59052 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45134 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  69%|██████▉   | 280/404 [55:11<28:56, 14.00s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60820 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45468 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45478 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  70%|██████▉   | 281/404 [55:28<31:02, 15.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45312 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  70%|██████▉   | 282/404 [55:37<27:05, 13.32s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33852 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  70%|███████   | 283/404 [55:44<22:38, 11.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33862 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50616 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50622 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  70%|███████   | 284/404 [55:59<24:50, 12.42s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59848 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  71%|███████   | 285/404 [56:07<22:18, 11.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35280 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35290 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 57.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35294 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  71%|███████▏  | 288/404 [56:29<15:58,  8.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56112 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56116 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46984 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46996 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  72%|███████▏  | 289/404 [56:55<25:59, 13.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39528 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39540 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39548 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39554 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 55.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41510 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  72%|███████▏  | 290/404 [57:20<32:15, 16.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54968 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54980 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54992 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  72%|███████▏  | 291/404 [57:35<31:02, 16.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55516 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  72%|███████▏  | 292/404 [57:41<24:36, 13.18s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50046 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  73%|███████▎  | 293/404 [57:48<20:53, 11.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48178 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  73%|███████▎  | 294/404 [58:02<22:10, 12.10s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36322 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54800 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54804 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54814 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55300 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  73%|███████▎  | 295/404 [58:26<28:26, 15.65s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48366 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48368 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48382 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51468 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  73%|███████▎  | 296/404 [58:48<31:46, 17.65s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47130 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47140 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47150 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  74%|███████▎  | 297/404 [59:00<28:12, 15.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38028 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38042 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  74%|███████▍  | 298/404 [59:16<28:15, 15.99s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43076 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  74%|███████▍  | 299/404 [59:23<23:07, 13.21s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43082 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  74%|███████▍  | 300/404 [59:28<18:46, 10.84s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51106 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  75%|███████▍  | 301/404 [59:36<17:06,  9.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45710 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45714 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45718 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  75%|███████▍  | 302/404 [59:51<19:31, 11.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38206 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38218 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38232 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  75%|███████▌  | 304/404 [1:00:10<16:45, 10.05s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:32826 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  75%|███████▌  | 305/404 [1:00:18<15:24,  9.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48024 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48030 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48040 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55662 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  76%|███████▌  | 306/404 [1:00:34<18:39, 11.43s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49944 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49948 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49958 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  76%|███████▌  | 307/404 [1:00:49<20:08, 12.46s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34804 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34810 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34816 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60298 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  76%|███████▌  | 308/404 [1:01:36<36:22, 22.74s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49984 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  76%|███████▋  | 309/404 [1:01:45<29:41, 18.75s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39294 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  77%|███████▋  | 310/404 [1:01:52<23:49, 15.21s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39304 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36078 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36090 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36104 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35802 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  77%|███████▋  | 312/404 [1:02:18<20:13, 13.19s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33158 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33166 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35298 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  77%|███████▋  | 313/404 [1:02:33<20:51, 13.75s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35306 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  78%|███████▊  | 314/404 [1:02:43<19:02, 12.69s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56068 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  78%|███████▊  | 315/404 [1:02:53<17:38, 11.89s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52908 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52924 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59340 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  78%|███████▊  | 316/404 [1:03:05<17:26, 11.90s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59354 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50350 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50362 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50370 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  78%|███████▊  | 317/404 [1:03:17<17:29, 12.07s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60366 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60382 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  79%|███████▊  | 318/404 [1:03:28<16:41, 11.65s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45824 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  79%|███████▉  | 319/404 [1:03:37<15:14, 10.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51258 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51268 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  79%|███████▉  | 320/404 [1:03:49<15:39, 11.19s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37700 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  79%|███████▉  | 321/404 [1:03:56<13:48,  9.99s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36958 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36974 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  80%|███████▉  | 322/404 [1:04:09<14:47, 10.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49474 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49476 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49478 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  80%|███████▉  | 323/404 [1:04:20<14:40, 10.87s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59334 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59342 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  80%|████████  | 324/404 [1:04:33<15:13, 11.42s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55300 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  80%|████████  | 325/404 [1:04:48<16:32, 12.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35818 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  81%|████████  | 326/404 [1:04:55<14:10, 10.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59908 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  81%|████████  | 327/404 [1:05:07<14:20, 11.17s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33866 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  81%|████████  | 328/404 [1:05:18<14:22, 11.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35280 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  81%|████████▏ | 329/404 [1:05:31<14:40, 11.74s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35080 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49012 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 330/404 [1:05:47<16:09, 13.10s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36566 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36578 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 331/404 [1:06:01<16:11, 13.30s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33650 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37674 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 332/404 [1:06:14<15:59, 13.33s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37684 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54578 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 333/404 [1:06:31<16:50, 14.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46604 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  83%|████████▎ | 334/404 [1:06:44<16:19, 14.00s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42416 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:32910 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  83%|████████▎ | 335/404 [1:07:00<16:49, 14.64s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58770 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38832 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  83%|████████▎ | 336/404 [1:07:15<16:27, 14.52s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  83%|████████▎ | 337/404 [1:07:23<14:02, 12.57s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57962 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  84%|████████▎ | 338/404 [1:07:30<12:14, 11.13s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51448 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51454 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45634 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45644 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  84%|████████▍ | 339/404 [1:07:49<14:23, 13.28s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41816 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  84%|████████▍ | 340/404 [1:07:56<12:13, 11.46s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35820 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35824 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 53.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35832 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49222 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  84%|████████▍ | 341/404 [1:08:18<15:17, 14.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51150 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51158 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  85%|████████▍ | 343/404 [1:08:43<13:42, 13.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57870 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  85%|████████▌ | 344/404 [1:08:49<11:13, 11.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57650 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  85%|████████▌ | 345/404 [1:09:00<10:49, 11.00s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60014 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  86%|████████▌ | 346/404 [1:09:08<09:52, 10.21s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40120 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  86%|████████▌ | 347/404 [1:09:25<11:41, 12.30s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48446 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  86%|████████▌ | 348/404 [1:09:36<11:03, 11.85s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39484 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  86%|████████▋ | 349/404 [1:09:44<09:42, 10.59s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39490 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49466 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  87%|████████▋ | 350/404 [1:10:04<12:08, 13.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51444 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43958 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  87%|████████▋ | 351/404 [1:10:22<13:05, 14.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38194 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38200 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  87%|████████▋ | 352/404 [1:10:36<12:36, 14.55s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38500 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38516 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38524 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59848 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59850 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  87%|████████▋ | 353/404 [1:11:00<14:45, 17.35s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38682 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53674 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  88%|████████▊ | 354/404 [1:11:18<14:35, 17.51s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47984 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47988 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  88%|████████▊ | 355/404 [1:11:27<12:22, 15.14s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 94.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51304 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  88%|████████▊ | 356/404 [1:11:33<09:53, 12.37s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51308 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  88%|████████▊ | 357/404 [1:11:38<07:55, 10.12s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36680 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36692 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  89%|████████▊ | 358/404 [1:11:49<07:56, 10.36s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57098 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57108 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  89%|████████▉ | 359/404 [1:12:04<08:46, 11.70s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58592 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35874 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35876 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  89%|████████▉ | 361/404 [1:12:23<07:16, 10.15s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52940 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  90%|████████▉ | 362/404 [1:12:33<07:02, 10.05s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46588 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  90%|████████▉ | 363/404 [1:12:43<06:49,  9.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44336 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  90%|█████████ | 365/404 [1:13:00<06:03,  9.31s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51040 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  91%|█████████ | 366/404 [1:13:09<06:00,  9.48s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53552 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  91%|█████████ | 367/404 [1:13:14<04:56,  8.01s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46650 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  91%|█████████ | 368/404 [1:13:24<05:08,  8.57s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46658 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55536 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  91%|█████████▏| 369/404 [1:13:36<05:38,  9.66s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57960 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39246 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39248 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  92%|█████████▏| 370/404 [1:14:01<08:04, 14.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33272 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33282 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36952 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36956 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36958 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51636 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  92%|█████████▏| 371/404 [1:14:25<09:24, 17.11s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51652 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  92%|█████████▏| 372/404 [1:14:31<07:22, 13.84s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46116 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  92%|█████████▏| 373/404 [1:14:42<06:45, 13.07s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35836 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35842 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47036 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34202 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  93%|█████████▎| 374/404 [1:15:05<07:54, 15.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45776 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45782 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  93%|█████████▎| 375/404 [1:15:19<07:26, 15.41s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45456 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45462 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  93%|█████████▎| 376/404 [1:15:39<07:49, 16.77s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54930 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54942 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40084 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  93%|█████████▎| 377/404 [1:16:01<08:12, 18.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41044 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  94%|█████████▎| 378/404 [1:16:10<06:41, 15.46s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51808 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51818 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49396 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  94%|█████████▍| 379/404 [1:16:28<06:45, 16.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52780 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  94%|█████████▍| 381/404 [1:16:41<04:14, 11.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46734 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▍| 382/404 [1:16:53<04:13, 11.52s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 90.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53610 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43106 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43120 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▍| 383/404 [1:17:06<04:11, 11.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52572 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▌| 384/404 [1:17:16<03:42, 11.11s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52582 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54380 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▌| 385/404 [1:17:28<03:38, 11.48s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38976 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38992 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39000 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 57.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55258 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  96%|█████████▌| 387/404 [1:17:47<02:51, 10.10s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45252 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45268 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  96%|█████████▌| 388/404 [1:18:03<03:07, 11.70s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54578 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51848 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51862 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  96%|█████████▋| 389/404 [1:18:21<03:25, 13.71s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44684 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44686 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37180 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 390/404 [1:18:40<03:33, 15.23s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49946 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48892 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 391/404 [1:18:56<03:22, 15.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48904 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 392/404 [1:19:02<02:29, 12.47s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38782 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 393/404 [1:19:10<02:03, 11.20s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57474 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57484 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  98%|█████████▊| 394/404 [1:19:22<01:53, 11.38s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45620 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  98%|█████████▊| 395/404 [1:19:29<01:30, 10.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38288 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38290 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  98%|█████████▊| 396/404 [1:19:39<01:21, 10.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59260 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59264 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58604 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  98%|█████████▊| 397/404 [1:19:56<01:25, 12.20s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53716 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  99%|█████████▉| 399/404 [1:20:13<00:51, 10.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47158 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47164 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60832 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  99%|█████████▉| 400/404 [1:20:25<00:43, 10.88s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60836 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36400 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  99%|█████████▉| 401/404 [1:20:43<00:38, 12.81s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49276 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions: 100%|█████████▉| 402/404 [1:20:50<00:22, 11.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46686 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions: 100%|█████████▉| 403/404 [1:20:56<00:09,  9.67s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50788 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions: 100%|██████████| 404/404 [1:21:17<00:00, 12.07s/it]\n",
            "Answering Questions:   0%|          | 0/404 [00:00<?, ?it/s]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43532 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35954 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   0%|          | 2/404 [00:26<1:21:01, 12.09s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43758 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43770 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   1%|▏         | 6/404 [01:11<1:08:51, 10.38s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55212 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   2%|▏         | 9/404 [01:40<1:04:06,  9.74s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58888 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   2%|▏         | 10/404 [01:56<1:15:43, 11.53s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45522 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   3%|▎         | 12/404 [02:14<1:05:08,  9.97s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55966 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   3%|▎         | 13/404 [02:25<1:07:26, 10.35s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57638 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▎         | 15/404 [02:47<1:10:09, 10.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57654 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▍         | 16/404 [02:56<1:05:12, 10.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38068 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   4%|▍         | 18/404 [03:11<56:59,  8.86s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44430 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   5%|▍         | 19/404 [03:24<1:02:59,  9.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57218 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 27/404 [04:43<1:08:32, 10.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52622 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 28/404 [04:55<1:10:31, 11.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52604 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50714 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   7%|▋         | 30/404 [05:14<1:01:47,  9.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33512 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:   8%|▊         | 33/404 [05:41<52:55,  8.56s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55724 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  10%|▉         | 39/404 [06:28<47:27,  7.80s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58514 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58526 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43284 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  10%|█         | 42/404 [07:15<1:15:20, 12.49s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56164 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  11%|█         | 45/404 [07:43<1:03:11, 10.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47640 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  12%|█▏        | 48/404 [08:16<1:02:23, 10.52s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38368 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  13%|█▎        | 54/404 [09:08<46:54,  8.04s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60004 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  14%|█▍        | 56/404 [09:32<56:35,  9.76s/it]  \n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33388 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  14%|█▍        | 58/404 [09:49<50:50,  8.82s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38138 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  16%|█▌        | 63/404 [10:25<34:57,  6.15s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34652 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  16%|█▌        | 64/404 [10:39<49:10,  8.68s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46236 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  17%|█▋        | 69/404 [11:18<38:34,  6.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60496 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  17%|█▋        | 70/404 [11:30<47:20,  8.51s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37264 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  18%|█▊        | 72/404 [11:48<45:46,  8.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48628 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  18%|█▊        | 73/404 [11:56<46:43,  8.47s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46966 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  19%|█▉        | 76/404 [12:22<41:31,  7.60s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33660 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  19%|█▉        | 77/404 [12:32<45:03,  8.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54282 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54288 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  20%|█▉        | 79/404 [12:50<45:17,  8.36s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35354 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  21%|██        | 85/404 [13:42<49:09,  9.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53408 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53420 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  22%|██▏       | 87/404 [14:05<52:01,  9.85s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48140 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57696 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  22%|██▏       | 88/404 [14:17<55:53, 10.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57704 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  22%|██▏       | 89/404 [14:29<58:10, 11.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48416 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  22%|██▏       | 90/404 [14:40<57:08, 10.92s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46584 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  24%|██▎       | 95/404 [15:35<51:44, 10.05s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52716 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  24%|██▍       | 96/404 [15:52<1:02:23, 12.15s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57660 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▍       | 100/404 [16:22<39:07,  7.72s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 89.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50392 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▌       | 101/404 [16:37<49:15,  9.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55450 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 65.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53806 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▌       | 102/404 [16:50<54:54, 10.91s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58260 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  25%|██▌       | 103/404 [17:02<55:28, 11.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55826 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  26%|██▌       | 104/404 [17:20<1:06:50, 13.37s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60380 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  27%|██▋       | 109/404 [17:53<36:01,  7.33s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34812 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34822 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46584 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  28%|██▊       | 113/404 [18:36<45:03,  9.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38510 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  28%|██▊       | 114/404 [18:49<50:50, 10.52s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43830 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35004 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35006 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  29%|██▉       | 117/404 [19:20<45:19,  9.48s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 72.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48928 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48942 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48944 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  30%|██▉       | 121/404 [20:13<55:46, 11.83s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34000 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  30%|███       | 122/404 [20:22<51:13, 10.90s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45376 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  31%|███       | 124/404 [20:38<42:23,  9.09s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55408 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  32%|███▏      | 129/404 [21:23<36:29,  7.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50478 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 54.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50484 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  32%|███▏      | 131/404 [21:45<40:44,  8.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58194 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  33%|███▎      | 134/404 [22:05<33:06,  7.36s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51100 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  34%|███▍      | 138/404 [22:42<37:35,  8.48s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46866 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  35%|███▌      | 142/404 [23:20<43:31,  9.97s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44460 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  36%|███▋      | 147/404 [24:20<54:30, 12.73s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57478 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  37%|███▋      | 151/404 [24:56<40:23,  9.58s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44792 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  38%|███▊      | 152/404 [25:06<40:29,  9.64s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48526 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  38%|███▊      | 154/404 [25:25<39:06,  9.39s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59466 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  40%|███▉      | 161/404 [26:35<41:29, 10.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44824 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44828 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44830 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  40%|████      | 162/404 [26:54<52:07, 12.92s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51642 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  41%|████      | 166/404 [27:34<40:48, 10.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 59.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50674 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  41%|████▏     | 167/404 [27:42<37:44,  9.55s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41228 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  42%|████▏     | 169/404 [28:04<40:44, 10.40s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 80.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52246 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  42%|████▏     | 170/404 [28:24<50:53, 13.05s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35026 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▎     | 176/404 [29:14<32:09,  8.46s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47352 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▍     | 178/404 [29:30<30:23,  8.07s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40824 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  44%|████▍     | 179/404 [29:46<39:10, 10.44s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43186 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  45%|████▍     | 180/404 [30:03<46:20, 12.41s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37630 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▌     | 185/404 [30:50<30:27,  8.34s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43636 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▌     | 186/404 [31:04<36:45, 10.12s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40534 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  46%|████▋     | 187/404 [31:13<35:24,  9.79s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53890 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56702 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  47%|████▋     | 190/404 [31:43<32:10,  9.02s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52232 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  48%|████▊     | 192/404 [32:00<30:25,  8.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51426 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  48%|████▊     | 193/404 [32:08<29:24,  8.36s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49322 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  49%|████▉     | 198/404 [33:09<34:28, 10.04s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51142 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  50%|█████     | 204/404 [34:20<41:31, 12.46s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39192 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39196 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  51%|█████     | 205/404 [34:33<42:01, 12.67s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 87.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38902 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  52%|█████▏    | 211/404 [35:17<22:37,  7.03s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35060 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43450 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  53%|█████▎    | 213/404 [35:44<31:53, 10.02s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57560 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  53%|█████▎    | 214/404 [35:57<34:12, 10.80s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48034 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  54%|█████▍    | 218/404 [36:26<23:14,  7.50s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45790 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  54%|█████▍    | 219/404 [36:37<26:48,  8.70s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37470 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 55.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36884 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36900 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36916 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  55%|█████▍    | 221/404 [37:10<36:59, 12.13s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49518 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  55%|█████▌    | 224/404 [37:48<37:55, 12.64s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59150 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  56%|█████▌    | 225/404 [38:02<39:03, 13.09s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57692 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57706 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  56%|█████▋    | 228/404 [38:33<30:36, 10.44s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58364 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  57%|█████▋    | 229/404 [38:44<31:18, 10.73s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41848 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 234/404 [39:34<31:20, 11.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33050 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 235/404 [39:54<38:45, 13.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33458 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  58%|█████▊    | 236/404 [40:07<37:41, 13.46s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52124 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  60%|█████▉    | 241/404 [40:44<20:59,  7.72s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56398 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  60%|██████    | 243/404 [41:05<23:05,  8.60s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52808 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████    | 245/404 [41:21<22:26,  8.47s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44488 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44492 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 58.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54718 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████    | 246/404 [41:48<36:51, 14.00s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52858 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  61%|██████    | 247/404 [42:09<41:30, 15.86s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45138 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  62%|██████▏   | 250/404 [42:35<28:05, 10.94s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52102 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  62%|██████▏   | 252/404 [43:05<33:20, 13.16s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53854 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53862 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  64%|██████▎   | 257/404 [43:48<21:20,  8.71s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36290 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  65%|██████▍   | 262/404 [44:22<16:23,  6.93s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 84.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38852 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  66%|██████▌   | 267/404 [45:13<21:55,  9.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39866 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 269/404 [45:30<19:34,  8.70s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33170 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 270/404 [45:38<19:30,  8.74s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:50732 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  67%|██████▋   | 271/404 [45:50<21:18,  9.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43100 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  68%|██████▊   | 273/404 [46:03<17:15,  7.90s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 69.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46550 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  69%|██████▉   | 280/404 [46:56<14:05,  6.81s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43436 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  70%|██████▉   | 281/404 [47:07<16:56,  8.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 83.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40356 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  70%|███████   | 284/404 [47:27<14:10,  7.08s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52390 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  71%|███████   | 285/404 [47:39<16:49,  8.48s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40064 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 73.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40068 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40084 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 75.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40094 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40102 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  71%|███████▏  | 288/404 [48:12<18:11,  9.41s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43426 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43436 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 63.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43446 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:43454 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  72%|███████▏  | 289/404 [48:31<23:28, 12.25s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55478 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  73%|███████▎  | 295/404 [49:30<19:41, 10.84s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49140 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49156 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  74%|███████▎  | 297/404 [49:54<19:50, 11.13s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56192 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  74%|███████▍  | 300/404 [50:16<14:22,  8.29s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33220 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  75%|███████▍  | 302/404 [50:30<12:32,  7.37s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53860 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  75%|███████▌  | 305/404 [51:01<14:26,  8.76s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47694 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  76%|███████▌  | 307/404 [51:25<16:36, 10.27s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42850 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 61.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34322 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  76%|███████▋  | 309/404 [51:55<18:24, 11.62s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 70.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33500 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  78%|███████▊  | 314/404 [52:53<18:14, 12.16s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44246 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  79%|███████▉  | 319/404 [53:34<12:19,  8.70s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54318 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  79%|███████▉  | 321/404 [53:48<10:31,  7.61s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49546 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47214 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 62.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:47224 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  80%|███████▉  | 323/404 [54:10<12:14,  9.06s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49596 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 56.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49604 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  81%|████████  | 326/404 [54:50<14:30, 11.16s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42366 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 330/404 [55:39<14:14, 11.55s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:51934 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 331/404 [55:55<15:35, 12.81s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 78.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44736 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 332/404 [56:05<14:21, 11.97s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41606 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  82%|████████▏ | 333/404 [56:20<15:25, 13.03s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35948 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  83%|████████▎ | 335/404 [56:33<11:00,  9.58s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:49732 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  83%|████████▎ | 336/404 [56:42<10:46,  9.51s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 86.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48804 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  84%|████████▍ | 340/404 [57:12<08:23,  7.87s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:42708 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  85%|████████▍ | 343/404 [57:39<09:07,  8.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44190 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  85%|████████▌ | 345/404 [58:11<12:22, 12.59s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55906 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 68.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55912 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  87%|████████▋ | 351/404 [59:17<08:09,  9.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55762 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 64.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56962 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 60.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56964 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  87%|████████▋ | 352/404 [59:38<10:59, 12.69s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57544 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  88%|████████▊ | 354/404 [59:57<08:59, 10.79s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55676 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  91%|█████████ | 366/404 [1:01:44<06:29, 10.24s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:40568 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  93%|█████████▎| 377/404 [1:03:10<03:51,  8.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53764 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▍| 382/404 [1:03:54<03:24,  9.30s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 82.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58426 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 67.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58442 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 54.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:41380 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▌| 384/404 [1:04:23<03:54, 11.74s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53144 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  95%|█████████▌| 385/404 [1:04:35<03:44, 11.80s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 85.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58820 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 71.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58822 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  96%|█████████▌| 387/404 [1:04:55<02:59, 10.56s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 88.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 390/404 [1:05:32<02:33, 10.98s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 77.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55996 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 391/404 [1:05:45<02:30, 11.57s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59946 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  97%|█████████▋| 393/404 [1:05:58<01:38,  8.96s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 79.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59082 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 66.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:36196 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  99%|█████████▊| 398/404 [1:06:43<00:53,  8.90s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:52248 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions:  99%|█████████▉| 400/404 [1:07:03<00:35,  8.89s/it]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 81.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58750 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions: 100%|██████████| 404/404 [1:07:41<00:00, 10.05s/it]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch  # if using PyTorch\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "save_dir = os.path.join(results_folder, dataset_name, model_name)\n",
        "\n",
        "start_idx = 0\n",
        "# Collect all questions\n",
        "questions = [instance['question'] for instance in eval_subset]\n",
        "#groundtruth_answers = [instance['answer'] for instance in eval_subset]\n",
        "\n",
        "# Run the parallelized function\n",
        "#answers = answer_queries_parallel(questions, max_workers=num_workers)  # adjust max_workers based on your GPU/CPU\n",
        "\n",
        "# for question in questions:\n",
        "#     answers.append(answer_query(question))\n",
        "max_attempts = 3\n",
        "\n",
        "# Prepare the message\n",
        "prompts = [\"\"\"Answer the given question. \\\n",
        "You must conduct reasoning inside <think> and </think> first every time you get new information. \\\n",
        "After reasoning, if you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. \\\n",
        "You can search as many times as your want. \\\n",
        "If you find no further external knowledge needed, you can directly provide the answer inside <answer> and </answer>, without detailed illustrations. For example, <answer> Beijing </answer>. Question: {}\\n\"\"\",\n",
        "\"\"\"Answer the given question. \\\n",
        "# You may conduct reasoning inside <think> and </think> to plan searches and organize your thoughts. \\\n",
        "# If you find you lack some knowledge, you can call a search engine by <search> query </search> and it will return the top searched results between <information> and </information>. \\\n",
        "# You can search as many times as you want. \\\n",
        "# When writing your final answer, include all explanation, causal reasoning using words like 'because', alternative perspectives or caveats, and any references to facts you found in <information>, all inside <answer>…</answer>. \\\n",
        "# Do not put step-by-step reasoning or search planning from <think> into <answer>; <answer> should be a clear synthesis of your reasoning and the information you gathered. \\\n",
        "# For example: <answer> Coffee contains caffeine, which can increase alertness and concentration because caffeine blocks adenosine receptors in the brain. According to the sources retrieved, this effect helps people focus and temporarily reduces fatigue. Some people, however, are sensitive to caffeine and may experience jitters, anxiety, or insomnia. </answer> \\\n",
        "# Question: {}\\n\"\"\"]\n",
        "for i, prompt in enumerate(prompts):\n",
        "  answers =[]\n",
        "\n",
        "  for idx in tqdm(range(start_idx, len(questions)), desc=\"Answering Questions\"):\n",
        "      # if idx not in [33,68]:\n",
        "      #     continue\n",
        "      question = questions[idx]\n",
        "      attempt = 0\n",
        "      result = None\n",
        "\n",
        "      while attempt < max_attempts:\n",
        "          try:\n",
        "              with torch.no_grad():\n",
        "                  result = answer_query(question, prompt.format(question))  # your existing function\n",
        "              break  # success, exit retry loop\n",
        "          except Exception as e:\n",
        "              print(f\"Error on question {idx} (attempt {attempt+1}/{max_attempts}): {e}\")\n",
        "              torch.cuda.empty_cache()\n",
        "              gc.collect()\n",
        "              attempt += 1\n",
        "\n",
        "      if result is None:\n",
        "          print(f\"Failed to process question {idx} after {max_attempts} attempts. Storing None.\")\n",
        "          result = {\"output_text\" : None, \"reasoning_chain\": None}\n",
        "\n",
        "      answers.append(result)\n",
        "\n",
        "      # Clear GPU memory after each question\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "\n",
        "\n",
        "  # Add back later\n",
        "  # Build the evaluation dictionary\n",
        "  eval_dict = []\n",
        "  for idx, instance in enumerate(eval_subset):\n",
        "      if have_groundtruth == True:\n",
        "        eval_dict.append({\n",
        "            'question': instance['question'],\n",
        "            'groundtruth_answer': instance['answer'],\n",
        "            'agent_answer': answers[idx]['output_text'],  # map parallel output back to the instance\n",
        "            'reasoning_chain': answers[idx]['reasoning_chain']\n",
        "        })\n",
        "      else:\n",
        "        eval_dict.append({\n",
        "            'question': instance['question'],\n",
        "            #'groundtruth_answer': instance['answer'],\n",
        "            'agent_answer': answers[idx]['output_text'],  # map parallel output back to the instance\n",
        "            'reasoning_chain': answers[idx]['reasoning_chain']\n",
        "        })\n",
        "\n",
        "  # # Assume answer_query can take a batch of questions\n",
        "  # # If it can't, you can modify it to do so\n",
        "  # batch_size = 32  # adjust depending on GPU memory\n",
        "  # for i in tqdm(range(0, len(questions), batch_size)):\n",
        "  #     batch_questions = questions[i:i+batch_size]\n",
        "  #     batch_answers = answer_query(batch_questions)  # returns a list of answers\n",
        "  #     batch_gt = groundtruth_answers[i:i+batch_size]\n",
        "  #     for q, ans, gt in zip(batch_questions, batch_answers, batch_gt):\n",
        "  #         #print(instance)\n",
        "  #         eval_dict.append({\n",
        "  #             'question': q,\n",
        "  #             'groundtruth_answer': gt,\n",
        "  #             'agent_answer': ans\n",
        "  #         })\n",
        "\n",
        "  # Save results\n",
        "  if i == 0:\n",
        "    with open(f\"{save_dir}/results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(eval_dict, f, ensure_ascii=False, indent=2)\n",
        "  else:\n",
        "    with open(f\"{save_dir}/other_prompts/results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(eval_dict, f, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMQd7KpuLKNf",
        "outputId": "19beaff6-5f21-48f0-8271-d69ec29f64f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': \"When is ap men's basketball poll released?\",\n",
              "  'agent_answer': \"<think>I found out that the AP men's basketball poll is released every Monday. Now I can provide the answer.</think>\\n\\n<answer> every Monday </answer>\",\n",
              "  'reasoning_chain': \"\\n\\n<think>I need to find out when the AP men's basketball poll is released. I'll search for it.</think>\\n\\n<search> AP men's basketball poll released </search>\\n\\n<information>Doc 1(Title: Alabama is No. 1 in the final AP Top 25 men's college basketball poll of the season Houston is No. 2 and Big Ten champion Purdue was third.) \\nDoc 2(Title: Feb 27, 2023 ... AP Top 25 Men's Basketball Rankings · 1. Houston (49), 27-2 · 2. Alabama (5), 25-4 · 3. Kansas (8), 24-5 · 4. UCLA, 25-4 · 5. Purdue, 24-5 · 6.) \\nDoc 3(Title: Mar 5, 2023 ... March Madness correspondent Andy Katz went live on Bleacher Report to break down the men's basketball AP poll released on March 6, the last\\xa0...) \\nDoc 4(Title: Mar 14, 2023 ... The AP poll is released every Monday. Unlike college football, the poll results have virtually no effect on the sport. College basketball teams\\xa0...) \\nDoc 5(Title: Visit ESPN to view the 2022-23 Men's College Basketball Rankings for Final Rankings. ... No poll released during this time frame. Coaches Poll\\xa0...) \\n</information>\\n\\n\\n<think>I found out that the AP men's basketball poll is released every Monday. Now I can provide the answer.</think>\\n\\n<answer> every Monday </answer>\"},\n",
              " {'question': 'How many 40 point games does michael jordan have in the playoffs?',\n",
              "  'agent_answer': '<think>I found out that Michael Jordan had 38 games with 40+ points in the playoffs. Now I can provide the answer.</think>\\n\\n<answer> 38 </answer>',\n",
              "  'reasoning_chain': \"\\n\\n<think>I need to find out how many 40-point games Michael Jordan has in the playoffs. I'll search for it.</think>\\n\\n<search> how many 40-point games does Michael Jordan have in the playoffs </search>\\n\\n<information>Doc 1(Title: Michael Jordan had his most games with 40+ points in a single NBA playoff run in 1988-89, with 7 games. most career 40 point playoff games michael jordan\\xa0...) \\nDoc 2(Title: Aug 12, 2021 ... What makes Jordan's achievement even greater is the fact that he has averaged 40 points per game in an NBA playoff series five times in his\\xa0...) \\nDoc 3(Title: 7 days ago ... Michael Jordan's last 40-point playoff game came against the Utah Jazz in Game 6 of the NBA Finals. How many 40 point playoff games did Michael\\xa0...) \\nDoc 4(Title: Michael Jordan had the most games in the playoffs with 40+ points, with 38 games.) \\nDoc 5(Title: Michael Jordan had 173 games played with 40+ points.) \\n</information>\\n\\n\\n<think>I found out that Michael Jordan had 38 games with 40+ points in the playoffs. Now I can provide the answer.</think>\\n\\n<answer> 38 </answer>\"},\n",
              " {'question': 'Who is the only bowler to have taken a hattrick in both meaning of a test match?',\n",
              "  'agent_answer': '<think>I found out that Jimmy Matthews is the only bowler who has taken a hatrick in both meanings of a test match. Now I can provide the answer.</think>\\n\\n<answer> Jimmy Matthews </answer>',\n",
              "  'reasoning_chain': \"\\n\\n<think>I need to find the only bowler who has taken a hatrick in both meanings of a test match. I'll search for it.</think>\\n\\n<search> who is the only bowler to have taken a hatrick in both meanings of a test match </search>\\n\\n<information>Doc 1(Title: It has been more than 141 years of Test Cricket and there's only one bowler who has taken a hat-trick in the same test match. He was Jimmy Mathews from\\xa0...) \\nDoc 2(Title: Ques : Who is the only bowler to have taken a hat-trick in both innings of a Test match? A: Hush Truble. B: Jimmy Matthews. C: Wasim Akram. D: Stuart Board.) \\nDoc 3(Title: Australian Merv Hughes is the only bowler to take a hat-rick where the wickets ... Matthews only bowler took a hat-trick in both innings of the same Test.) \\nDoc 4(Title: Feb 27, 2013 ... Only wickets attributed to the bowler count towards a hat-trick; ... over two different innings and becoming the only player in Test cricket\\xa0...) \\nDoc 5(Title: Feb 27, 2013 ... Only wickets attributed to the bowler count towards a hat-trick; ... over two different innings and becoming the only player in Test cricket\\xa0...) \\n</information>\\n\\n\\n<think>I found out that Jimmy Matthews is the only bowler who has taken a hatrick in both meanings of a test match. Now I can provide the answer.</think>\\n\\n<answer> Jimmy Matthews </answer>\"},\n",
              " {'question': \"Who plays timothy mcgee's wife on ncis?\",\n",
              "  'agent_answer': '<think>I found out that Margo Harshman plays Delilah Fielding in NCIS.</think>\\n\\n<answer> Margo Harshman </answer>',\n",
              "  'reasoning_chain': \"\\n\\n<think>I need to find out who plays Timothy McGee's wife in NCIS. I'll search for it.</think>\\n\\n<search> who plays Timothy McGee's wife on NCIS </search>\\n\\n<information>Doc 1(Title: Delilah Fielding McGee is a Department of Defense employee and the girlfriend/wife of NCIS Special Agent Timothy McGee. She is also the mother of Morgan and\\xa0...) \\nDoc 2(Title: Jan 20, 2021 ... She is married to NCIS Special Agent Timothy McGee. The on couple also has two kids, Morgan and John McGee II. Earlier, Delilah was more often\\xa0...) \\nDoc 3(Title: Dec 5, 2022 ... Margo Harshman husband: Is NCIS Agent Timothy McGee's wife Delilah married in real life? Margo Harshman is reprising her role as Delilah\\xa0...) \\nDoc 4(Title: Dec 6, 2022 ... Actress returns as Timothy McGee's wife Delilah Fielding in new episode ... Margo Harshman's Delilah Fielding returned to NCIS season 20. The\\xa0...) \\nDoc 5(Title: Jan 19, 2021 ... NCIS character Timothy McGee (Sean Murray) has been married to Delilah since 2017. Who is the actor who plays Delilah?) \\n</information>\\n\\n\\n\\n\\n<think>I found out that Delilah Fielding is Timothy McGee's wife in NCIS. Now I need to find out who plays Delilah Fielding.</think>\\n\\n<search> who plays Delilah Fielding in NCIS </search>\\n\\n<information>Doc 1(Title: Dec 6, 2022 ... Actress returns as Timothy McGee's wife Delilah Fielding in new episode ... Margo Harshman's Delilah Fielding returned to NCIS season 20. The\\xa0...) \\nDoc 2(Title: Delilah Fielding McGee is a Department of Defense employee and the girlfriend/wife of NCIS Special Agent Timothy McGee. She is also the mother of Morgan and\\xa0...) \\nDoc 3(Title: She is best known for her roles as Tawny Dean on Even Stevens, Alex Jensen on The Big Bang Theory, and Delilah Fielding-McGee on NCIS.) \\nDoc 4(Title: Dec 5, 2022 ... Margo Harshman husband: Is NCIS Agent Timothy McGee's wife Delilah married in real life? Margo Harshman is reprising her role as Delilah\\xa0...) \\nDoc 5(Title: Jan 19, 2021 ... NCIS character Timothy McGee (Sean Murray) has been married to Delilah since 2017. Who is the actor who plays Delilah?) \\n</information>\\n\\n\\n<think>I found out that Margo Harshman plays Delilah Fielding in NCIS.</think>\\n\\n<answer> Margo Harshman </answer>\"},\n",
              " {'question': 'Who played aang in the last airbender movie?',\n",
              "  'agent_answer': '<think>I found out that Noah Ringer played Aang in the Last Airbender movie. Now I can provide the answer.</think>\\n\\n<answer> Noah Ringer </answer>',\n",
              "  'reasoning_chain': \"\\n\\n<think>I need to find out who played Aang in the Last Airbender movie. I'll search for it.</think>\\n\\n<search> who played Aang in the Last Airbender movie </search>\\n\\n<information>Doc 1(Title: May 25, 2010 ... Fans of the TV series Avatar: The Last Airbender are slamming the movie ... to cast the movie, unknown Noah Ringer was picked to play Aang.) \\nDoc 2(Title: Noah Andrew Ringer is an American actor who starred as Aang in the film The Last Airbender. He was discovered in an open casting call for Airbender in Texas\\xa0...) \\nDoc 3(Title: Based on the first season of the Nickelodeon animated television series Avatar: The Last Airbender, the film stars Noah Ringer as Aang, with Dev Patel playing\\xa0...) \\nDoc 4(Title: Based on the first season of the Nickelodeon animated television series Avatar: The Last Airbender, the film stars Noah Ringer as Aang, with Dev Patel playing\\xa0...) \\nDoc 5(Title: Jun 19, 2023 ... Who's in the cast of Avatar: The Last Airbender? Gordon Cormier will star as Aang, the fearless, easygoing 12-year-old who is keeper of the\\xa0...) \\n</information>\\n\\n\\n<think>I found out that Noah Ringer played Aang in the Last Airbender movie. Now I can provide the answer.</think>\\n\\n<answer> Noah Ringer </answer>\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(f\"{save_dir}/results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(eval_dict, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "NghT5-3dLIIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch\n",
        "\n",
        "# Step 1: Move model to CPU (break CUDA references)\n",
        "try:\n",
        "    model.to('cpu')\n",
        "except Exception as e:\n",
        "    print(\"Model not on GPU or already deleted:\", e)\n",
        "\n",
        "# Step 2: Delete the model and related objects\n",
        "for var in ['model', 'tokenizer', 'optimizer', 'scheduler']:\n",
        "    if var in locals():\n",
        "        del locals()[var]\n",
        "\n",
        "# Step 3: Clear PyTorch cache and collect garbage\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQhNUtZlwRoB",
        "outputId": "7e8911e6-a420-4f91-c512-c3272fb0b1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not on GPU or already deleted: name 'model' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMZVzJGHwBWw",
        "outputId": "79eac97e-eb60-4483-bc93-f92654503b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov  7 09:58:20 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   69C    P0             33W /   72W |   15545MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCVpa8T-IMbz"
      },
      "source": [
        "Parallel version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKm9AgEEIgQH"
      },
      "outputs": [],
      "source": [
        "# set variables:\n",
        "max_workers = 2  # tune based on GPU memory\n",
        "max_retries = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "TiqAM0g9iJdy",
        "outputId": "1e9fcf72-76af-4b19-d654-3afcbb097b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnswering Questions:   0%|          | 0/1617 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Error] Question 1 failed attempt 1/4: probability tensor contains either `inf`, `nan` or element < 0\n",
            "[Error] Question 0 failed attempt 1/4: probability tensor contains either `inf`, `nan` or element < 0\n",
            "[Error] Question 0 failed attempt 2/4: probability tensor contains either `inf`, `nan` or element < 0\n",
            "[Error] Question 1 failed attempt 2/4: probability tensor contains either `inf`, `nan` or element < 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnswering Questions:   0%|          | 0/1617 [00:05<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Error] Question 0 failed attempt 3/4: probability tensor contains either `inf`, `nan` or element < 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Error] Question 1 failed attempt 3/4: probability tensor contains either `inf`, `nan` or element < 0\n",
            "[Error] Question 0 failed attempt 4/4: probability tensor contains either `inf`, `nan` or element < 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3570676809.py\u001b[0m in \u001b[0;36manswer_queries_parallel\u001b[0;34m(questions, max_workers, max_retries)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Answering Questions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3570676809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_queries_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# ---- BUILD EVAL DICTIONARY ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3570676809.py\u001b[0m in \u001b[0;36manswer_queries_parallel\u001b[0;34m(questions, max_workers, max_retries)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         future_to_idx = {\n\u001b[1;32m     38\u001b[0m             \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_answer_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "save_dir = os.path.join(results_folder, dataset_name)\n",
        "\n",
        "# Collect all questions\n",
        "questions = [instance['question'] for instance in eval_subset]\n",
        "\n",
        "\n",
        "def safe_answer_query(q, idx, max_retries=3):\n",
        "    \"\"\"Wrapper that retries answer_query with GPU cleanup between attempts.\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                result = answer_query(q)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"[Error] Question {idx} failed attempt {attempt+1}/{max_retries}: {e}\")\n",
        "            # Clean up GPU memory and retry\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            time.sleep(1)\n",
        "    # If all attempts fail, return placeholder\n",
        "    return {\"output_text\": None, \"reasoning_chain\": None}\n",
        "\n",
        "\n",
        "def answer_queries_parallel(questions, max_workers=4, max_retries=3):\n",
        "    \"\"\"Parallel execution with retry and GPU memory cleanup per failure.\"\"\"\n",
        "    results = [None] * len(questions)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_idx = {\n",
        "            executor.submit(safe_answer_query, q, i, max_retries): i\n",
        "            for i, q in enumerate(questions)\n",
        "        }\n",
        "\n",
        "        for future in tqdm(as_completed(future_to_idx), total=len(future_to_idx), desc=\"Answering Questions\"):\n",
        "            idx = future_to_idx[future]\n",
        "            try:\n",
        "                results[idx] = future.result()\n",
        "            except Exception as e:\n",
        "                print(f\"[Fatal] Query {idx} crashed completely: {e}\")\n",
        "                results[idx] = {\"output_text\": None, \"reasoning_chain\": None}\n",
        "            finally:\n",
        "                # Clean memory between completions\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "answers = answer_queries_parallel(questions, max_workers=max_workers, max_retries=max_retries)\n",
        "\n",
        "# ---- BUILD EVAL DICTIONARY ----\n",
        "eval_dict = []\n",
        "for idx, instance in enumerate(eval_subset):\n",
        "    entry = {\n",
        "        'question': instance['question'],\n",
        "        'agent_answer': answers[idx]['output_text'],\n",
        "        'reasoning_chain': answers[idx]['reasoning_chain']\n",
        "    }\n",
        "    if have_groundtruth:\n",
        "        entry['groundtruth_answer'] = instance['answer']\n",
        "    eval_dict.append(entry)\n",
        "\n",
        "# ---- SAVE RESULTS ----\n",
        "with open(f\"{save_dir}/results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(eval_dict, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"✅ Saved results to {save_dir}/results.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5THkI6zRfod"
      },
      "outputs": [],
      "source": [
        "    # torch.cuda.empty_cache()\n",
        "    # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuCbJRtjNUh-"
      },
      "outputs": [],
      "source": [
        "# eval_dict = []\n",
        "# for idx, instance in enumerate(eval_subset):\n",
        "#     # print(instance)\n",
        "#     if idx < 68:\n",
        "#         continue\n",
        "#     if idx >= 100:\n",
        "#         break\n",
        "#     if have_groundtruth == True:\n",
        "#       eval_dict.append({\n",
        "#           'question': instance['question'],\n",
        "#           'groundtruth_answer': instance['answer'],\n",
        "#           'agent_answer': answers[idx - 68]  # map parallel output back to the instance\n",
        "#       })\n",
        "#     else:\n",
        "#       eval_dict.append({\n",
        "#           'question': instance['question'],\n",
        "#           #'groundtruth_answer': instance['answer'],\n",
        "#           'agent_answer': answers[idx - 68]  # map parallel output back to the instance\n",
        "#       })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeMfAi6Qga34"
      },
      "source": [
        "6.5 Load evaluation results from folder (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IyD0PSamQKI"
      },
      "outputs": [],
      "source": [
        "# save_dir = os.path.join(results_folder, dataset_name, model_name)\n",
        "\n",
        "\n",
        "with open(f\"{save_dir}/results.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    eval_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg26T0bQDLcC"
      },
      "source": [
        "6.6 Check if the model failed to give any outputs. If something is printed, then the model failed to give an answer for some input. If nothing is printed, then the model successfuly gave an answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO9tFZnKDLPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fa8622-8edf-411d-b8bf-e7480cbb1b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n"
          ]
        }
      ],
      "source": [
        "for idx, instance in enumerate(eval_dict):\n",
        "\n",
        "    if instance['agent_answer'] is None:\n",
        "        print(idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqY6hsHbDQt9"
      },
      "source": [
        "6.7 (Optional) If the model gave None for some answers, we try to search again. Skip if nothing is printed. Just run this.\n",
        "\n",
        "Note that this code does not guarantee that the LLM will give answers - we just try more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPbWRmO2DXun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5d5550-5297-449c-f96b-e575b5311217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Answering Questions:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 74.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54984 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 37.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54632 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 34.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59462 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 31.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:54088 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 28.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39878 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 27.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60860 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error on question 0 (attempt 1/10): CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 22.16 GiB of which 449.38 MiB is free. Process 39529 has 21.72 GiB memory in use. Of the allocated memory 18.35 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 26.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60028 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 39.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60030 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 34.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46500 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 26.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39412 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 29.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56976 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error on question 0 (attempt 2/10): CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacity of 22.16 GiB of which 435.38 MiB is free. Process 39529 has 21.73 GiB memory in use. Of the allocated memory 18.07 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 26.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56242 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 38.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:56254 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 29.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:33148 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 35.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:55594 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 28.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:32998 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 30.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:38372 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error on question 0 (attempt 3/10): CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacity of 22.16 GiB of which 177.38 MiB is free. Process 39529 has 21.98 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 25.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46092 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 38.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:46094 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 35.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57232 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 32.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58368 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 29.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:60098 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 24.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:48462 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error on question 0 (attempt 4/10): CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacity of 22.16 GiB of which 69.38 MiB is free. Process 39529 has 22.09 GiB memory in use. Of the allocated memory 18.73 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 27.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:44506 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 38.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:34598 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 35.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:53728 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 33.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59786 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 28.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:57048 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 27.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:35442 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error on question 0 (attempt 5/10): CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 22.16 GiB of which 63.38 MiB is free. Process 39529 has 22.09 GiB memory in use. Of the allocated memory 18.73 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 25.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37502 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 39.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45876 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 33.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:45892 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 31.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:58216 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 29.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59234 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 27.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:37996 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error on question 0 (attempt 6/10): CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 22.16 GiB of which 63.38 MiB is free. Process 39529 has 22.09 GiB memory in use. Of the allocated memory 18.73 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Retrieval process: 100%|██████████| 1/1 [00:00<00:00, 25.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:59860 - \"POST /retrieve HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Answering Questions: 100%|██████████| 1/1 [07:30<00:00, 450.16s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "missed_indices = []\n",
        "for idx, instance in enumerate(eval_dict):\n",
        "    if instance['agent_answer'] is None:\n",
        "        missed_indices.append(idx)\n",
        "\n",
        "# Collect all questions\n",
        "questions = [instance['question'] for instance in eval_subset]\n",
        "#groundtruth_answers = [instance['answer'] for instance in eval_subset]\n",
        "\n",
        "# Run the parallelized function\n",
        "#answers = answer_queries_parallel(questions, max_workers=num_workers)  # adjust max_workers based on your GPU/CPU\n",
        "missed_answers =[]\n",
        "# for question in questions:\n",
        "#     answers.append(answer_query(question))\n",
        "max_attempts = 10 # higher max_attempts\n",
        "for idx in tqdm(range(0, len(missed_indices)), desc=\"Answering Questions\"):\n",
        "\n",
        "    question = questions[missed_indices[idx]]\n",
        "    attempt = 0\n",
        "    result = None\n",
        "\n",
        "    while attempt < max_attempts:\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                result = answer_query(question, prompts[0].format(question))  # your existing function\n",
        "            break  # success, exit retry loop\n",
        "        except Exception as e:\n",
        "            print(f\"Error on question {idx} (attempt {attempt+1}/{max_attempts}): {e}\")\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            attempt += 1\n",
        "\n",
        "    if result is None:\n",
        "        print(f\"Failed to process question {idx} after {max_attempts} attempts. Storing None.\")\n",
        "        result = {\"output_text\" : None, \"reasoning_chain\": None}\n",
        "\n",
        "    missed_answers.append(result)\n",
        "\n",
        "    # Clear GPU memory after each question\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "# Add back to eval_dict\n",
        "\n",
        "for idx, ans in zip(missed_indices, missed_answers):\n",
        "    eval_dict[idx]['agent_answer'] = ans['output_text']\n",
        "    eval_dict[idx]['reasoning_chain'] = ans['reasoning_chain']\n",
        "\n",
        "\n",
        "# # Assume answer_query can take a batch of questions\n",
        "# # If it can't, you can modify it to do so\n",
        "# batch_size = 32  # adjust depending on GPU memory\n",
        "# for i in tqdm(range(0, len(questions), batch_size)):\n",
        "#     batch_questions = questions[i:i+batch_size]\n",
        "#     batch_answers = answer_query(batch_questions)  # returns a list of answers\n",
        "#     batch_gt = groundtruth_answers[i:i+batch_size]\n",
        "#     for q, ans, gt in zip(batch_questions, batch_answers, batch_gt):\n",
        "#         #print(instance)\n",
        "#         eval_dict.append({\n",
        "#             'question': q,\n",
        "#             'groundtruth_answer': gt,\n",
        "#             'agent_answer': ans\n",
        "#         })\n",
        "\n",
        "# Save results\n",
        "with open(f\"{save_dir}/results_updated.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(eval_dict, f, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vjjnD_giCe"
      },
      "source": [
        "6.8 Run these helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvYHVi9UmS9d"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_answer(output_text):\n",
        "    \"\"\"\n",
        "    Extracts the content inside <answer>...</answer> or full-width ＜answer＞...＜/answer＞.\n",
        "    Returns None if no answer tag is found.\n",
        "    \"\"\"\n",
        "    if output_text is None:\n",
        "      return None\n",
        "    pattern = r\"[<＜]answer[>＞](.*?)[<＜]/answer[>＞]\"\n",
        "    match = re.search(pattern, output_text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "def evaluate(agent_answers, groundtruth_answers): #groundtruth_answers should be a list of answers\n",
        "    total = len(agent_answers)\n",
        "    agent_answers = [(ans.lower().strip() if ans is not None else None) for ans in agent_answers]\n",
        "    if type(groundtruth_answers[0]) == list:\n",
        "        groundtruth_answers = [[ans.lower() for ans in answers] for answers in groundtruth_answers]\n",
        "        correct = sum(agent_answer in gt for agent_answer, gt in zip(agent_answers, groundtruth_answers))\n",
        "    else:\n",
        "        groundtruth_answers = [ans.lower() for ans in groundtruth_answers]\n",
        "        correct = sum(agent_answer == gt for agent_answer, gt in zip(agent_answers, groundtruth_answers))\n",
        "    return correct / total\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehAjYJbZgpk8"
      },
      "source": [
        "6.9 Parse model answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul1KGsfw7TJ-"
      },
      "outputs": [],
      "source": [
        "for item in eval_dict:\n",
        "  agent_answer = item['agent_answer']\n",
        "  agent_answer = extract_answer(agent_answer)\n",
        "  item['parsed_agent_answer'] = agent_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "007Uh326g9tk"
      },
      "source": [
        "Deal with special cases (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9bj_--SCKaq"
      },
      "outputs": [],
      "source": [
        "# Check which answers couldn't be parsed\n",
        "for idx, instance in enumerate(agent_answers):\n",
        "  if instance == None:\n",
        "    print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def strong_parse(output_text):\n",
        "    \"\"\"\n",
        "    Extracts content from <answer>...</answer>, allowing malformed tags and\n",
        "    cases where the starting tag is missing but the closing tag exists.\n",
        "    Supports:\n",
        "      - missing or malformed starting tags\n",
        "      - missing or malformed closing tags\n",
        "      - full-width + half-width brackets\n",
        "      - whitespace\n",
        "      - mixed brackets\n",
        "    \"\"\"\n",
        "    if not output_text:\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "    # --- Remove everything before the first </information> (inclusive) ---\n",
        "    info_matches = list(re.finditer(r'</information>', output_text, re.IGNORECASE))\n",
        "    if info_matches:\n",
        "        last_match = info_matches[-1]\n",
        "        output_text = output_text[last_match.end():].lstrip()\n",
        "\n",
        "        # --- Strip leading whitespace  ---\n",
        "    output_text = output_text.lstrip()\n",
        "\n",
        "    # --- Remove leading </answer> if present ---\n",
        "    if output_text.lower().startswith(\"</answer>\"):\n",
        "        output_text = output_text[len(\"</answer>\"):].lstrip()\n",
        "\n",
        "    # --- 1) Try normal extraction (even malformed brackets, missing >, etc.) ---\n",
        "    pattern = (\n",
        "        r\"(?:<|＜)\\s*answer\\s*(?:>|＞)?\"   # starting tag (optional closing bracket)\n",
        "        r\"(.*?)\"                          # content\n",
        "        r\"(?:<|＜)\\s*/\\s*answer\\s*(?:>|＞)?\"  # closing tag (optional closing bracket)\n",
        "    )\n",
        "\n",
        "    match = re.search(pattern, output_text, re.IGNORECASE | re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "\n",
        "    # --- 2) If starting tag is missing but closing tag exists ---\n",
        "    closing_tag_pattern = r\"(?:<|＜)\\s*/\\s*answer\\s*(?:>|＞)?\"\n",
        "    close_match = re.search(closing_tag_pattern, output_text, re.IGNORECASE)\n",
        "\n",
        "    if close_match:\n",
        "        # Extract everything *before* closing tag\n",
        "        return output_text[:close_match.start()].strip()\n",
        "\n",
        "    # One remaining case: starts with <answer> (cuz missing closing tag)\n",
        "    # --- Remove leading <answer> if present ---\n",
        "    if output_text.lower().startswith(\"<answer>\"):\n",
        "        output_text = output_text[len(\"<answer>\"):].lstrip()\n",
        "    # --- Remove trailing <answer> if present - for some reason it's here ---\n",
        "    tag = \"<answer>\"\n",
        "    if output_text.lower().endswith(tag):\n",
        "        output_text = output_text[:-len(tag)].strip()\n",
        "\n",
        "    return output_text\n",
        "\n"
      ],
      "metadata": {
        "id": "wO41TlpFix4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fASxmeWuTzU-",
        "outputId": "0b7fead6-37be-45c2-acc8-463fb1b0e8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview whether stronger parsing works\n",
        "\n",
        "print(\"Data:\\n\")\n",
        "for idx,instance in enumerate(eval_dict):\n",
        "    # print(f\"Question: {instance['question']} \\nAnswer: {instance['parsed_agent_answer']}\")\n",
        "    if instance['parsed_agent_answer'] == None:\n",
        "      # if idx == 18 : print(instance['question'])\n",
        "      print(idx)\n",
        "\n",
        "      print(strong_parse(instance['agent_answer']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If yes, perform parsing\n",
        "print(\"Search R1:\\n\")\n",
        "for idx,instance in enumerate(eval_dict):\n",
        "    #print(f\"Question: {instance['question']} \\nAnswer: {instance['parsed_agent_answer']}\")\n",
        "    if instance['parsed_agent_answer'] == None:\n",
        "      # if idx == 59 : print(instance['reasoning_chain'])\n",
        "      # print(idx)\n",
        "\n",
        "      instance['parsed_agent_answer'] = strong_parse(instance['agent_answer'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNh4YwovoRIP",
        "outputId": "610af1c9-c9ec-4e95-910c-02d073a00280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search R1:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okmO-IVwhD9b"
      },
      "source": [
        "6.10 Save parsed results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCkPbRcBhDpp"
      },
      "outputs": [],
      "source": [
        "# Save results\n",
        "with open(f\"{save_dir}/parsed_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(eval_dict, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGH2oyyVhRX3"
      },
      "source": [
        "6.11 Run evaluation if there are correct answers. (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gBMAsZ4K8gOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9078a91b-e4d8-4b65-af86-5f3451bcdfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is no correct answer.\n"
          ]
        }
      ],
      "source": [
        "# prepare answers\n",
        "import ast\n",
        "\n",
        "if have_groundtruth:\n",
        "    agent_answers = [instance['parsed_agent_answer'] for instance in eval_dict]\n",
        "    #groundtruth_answers = [instance['groundtruth_answer']['aliases'] for instance in loaded_eval_dict]\n",
        "    #groundtruth_answers = [ast.literal_eval(instance['groundtruth_answer']) for instance in loaded_eval_dict]\n",
        "    groundtruth_answers = [instance['groundtruth_answer'] for instance in eval_dict]\n",
        "    score = evaluate(agent_answers, groundtruth_answers)\n",
        "    print(score)\n",
        "else:\n",
        "    print(\"There is no correct answer.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKFVIBZgEE1n"
      },
      "outputs": [],
      "source": [
        "# View which questions the search agent got correct:\n",
        "for idx, (agent_answer, groundtruth_answer) in enumerate(zip(agent_answers, groundtruth_answers)):\n",
        "    score = evaluate([agent_answer], [groundtruth_answer])\n",
        "    if score == 1:\n",
        "      print(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBTzcmBT93_4",
        "outputId": "4dd8dbf5-839f-4054-c8d1-a3549b480dba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 None yes\n",
            "1 US Senator Chief of Protocol\n",
            "2 Animorphs Animorphs\n",
            "3 No no\n",
            "4 New York City Greenwich Village, New York City\n",
            "5 SM Entertainment YG Entertainment\n",
            "6 Raun Kaufman Eenasul Fateh\n",
            "7 6290 3,677 seated\n",
            "8 Annie Morton Terry Richardson\n",
            "9 No yes\n",
            "10 Rock Chalk, Jayhawk Kansas Song\n",
            "11 None David Weissman\n",
            "12 1991 1999\n",
            "13 Yes no\n",
            "14 1990 to 2008 from 1986 to 2013\n",
            "15 3,000,251 9,984\n",
            "16 Patriot League the North Atlantic Conference\n",
            "17 Yes yes\n",
            "18 1963-1969 1969 until 1974\n",
            "19 Robert Erskine Childers Robert Erskine Childers DSC\n",
            "20 Carlos Sainz Jnr. Pedro Rodríguez\n",
            "21 No Sonic\n",
            "22 Apple TV keyboard function keys\n",
            "23 Badly Drawn Boy Badly Drawn Boy\n",
            "24 Peter Schmeichel World's Best Goalkeeper\n",
            "25 Jim Cropper Barton Lee Hazlewood\n",
            "26 1838 1838\n",
            "27 No yes\n",
            "28 Henry Chisholm Henry J. Kaiser\n",
            "29 Circle of Ice Arena of Khazan\n",
            "30 October 25, 2010 2000\n",
            "31 None Fujioka, Gunma\n",
            "32 René Fonck Charles Eugène\n",
            "33 No no\n",
            "34 Letters to Cleo Letters to Cleo\n",
            "35 November 7, 1917 October 1922\n",
            "36 1983 2000\n",
            "37 Great War World War II\n",
            "38 No no\n",
            "39 Minneapolis New York City\n",
            "40 Scotch Collie Scotch Collie\n",
            "41 Louisville, Colorado Mumbai\n",
            "42 1847 1962\n",
            "43 Italian control over Corsica and the Mediterranean coast sovereignty\n",
            "44 Harry S. Truman Nelson Rockefeller\n",
            "45 Firth of Forth Yellowcraig\n",
            "46 Bono Phil Spector\n",
            "47 Valdai Discussion Club Organizations could come together to address global issues\n",
            "48 No yes\n",
            "49 Hawker Typhoon English Electric Canberra\n"
          ]
        }
      ],
      "source": [
        "# If there are correct answers, you can print the model's answers and groundtruth answers side by side:\n",
        "if have_groundtruth:\n",
        "  for idx, (agent_answer, groundtruth_answer) in enumerate(zip(agent_answers, groundtruth_answers)):\n",
        "    print(idx, agent_answer, groundtruth_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEnnG46Tf_B-"
      },
      "source": [
        "6.12 View Questions and Answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inpDBtR8f_5R"
      },
      "outputs": [],
      "source": [
        "# Save results\n",
        "import json\n",
        "import os\n",
        "path = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/results/QACC\"\n",
        "\n",
        "\n",
        "save_path = f\"{os.path.join(path, \"search-r1\")}/parsed_results.json\"\n",
        "\n",
        "with open(save_path, \"r\", encoding=\"utf-8\") as f: #, \"other_prompts\"\n",
        "    data = json.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jio06WgjVdDq",
        "outputId": "b8c33599-bb92-4893-a9b2-df1d848e99a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S3:\n",
            "\n",
            "Question: how did the quota system limit immigration \n",
            "Answer: The quota system limited immigration by setting strict numerical limits on the number of immigrants from specific countries based on their representation in the U.S. population from 1890, thereby favoring immigrants from northern and western Europe over those from other regions.\n",
            "Question: how computerisation can lead to better jobs and better payment \n",
            "Answer: Computerization can lead to better jobs and better payment by increasing efficiency, improving quality, creating new roles, raising skill requirements, and enabling data-driven decision-making.\n",
            "Question: why do people move to the suburbs \n",
            "Answer: People move to the suburbs primarily for more affordable housing, more space and privacy, better schools, safer neighborhoods, access to nature and outdoor activities, and less noise and pollution.\n",
            "Question: why do corns grow so much in the aztec empire \n",
            "Answer: The Aztecs likely experienced increased corn production due to population growth or economic prosperity, which increased their demand for corn as a staple food.\n",
            "Question: how did democracy spread \n",
            "Answer: Democracy spread through key historical events like the American and French Revolutions, the influence of influential figures such as Thomas Jefferson and John Locke, the spread of democratic ideas through communication, and the inherent benefits of democratic systems such as economic efficiency and the protection of individual freedoms.\n",
            "Question: why were the jews persecuted \n",
            "Answer: Religious differences, political and economic factors, social isolation, natural disasters and scapegoating, cultural and linguistic differences, and systematic policies have all contributed to the persecution of Jews throughout history.\n",
            "Question: how social media affects healthcare \n",
            "Answer: Social media affects healthcare by providing educational resources, enabling direct communication between patients and providers, and facilitating telemedicine. However, it also raises concerns about misinformation, privacy, and mental health.\n",
            "Question: what causes change in organisations \n",
            "Answer: Changes in organizations are caused by both internal and external factors including shifts in leadership, strategic repositioning, technological advancements, market conditions, regulatory requirements, customer demands, and economic conditions.\n",
            "Question: how can a bank anticipate and respond to chnages in applicable consumer protection laws \n",
            "Answer: A bank can anticipate and respond to changes in applicable consumer protection laws by staying informed, conducting regular reviews, providing training programs, consulting legal experts, and ensuring customer communication.\n",
            "Question: is chiropractic care safe \n",
            "Answer: Yes, chiropractic care is generally considered safe, but it is important to discuss individual risks and concerns with a qualified chiropractor.\n",
            "Question: what can occupational health do \n",
            "Answer: Occupational health can conduct risk assessments, provide health education and training, offer medical examinations, implement health and safety policies, advise on work-life balance and stress management, and handle claims and manage workers' compensation.\n",
            "Question: why did the 13 colonies revolt \n",
            "Answer: The 13 colonies revolted against British rule due to heavy taxation, trade restrictions, lack of representation in Parliament, and the desire for self-governance.\n",
            "Question: why is unemployment an economic problem? \n",
            "Answer: Unemployment is an economic problem because it reduces economic output, lowers tax revenues, decreases consumer spending, and can lead to skill loss and disengagement from the workforce.\n",
            "Question: what influenced picasso \n",
            "Answer: None\n",
            "Question: is regionalism good or bad for a country \n",
            "Answer: good\n",
            "Question: how does the dairy industry work \n",
            "Answer: The dairy industry involves raising and milking cows, maintaining high standards of health and nutrition, and producing a variety of dairy products. It uses modern technologies and practices to enhance efficiency and safety but also faces criticism regarding animal welfare and environmental impact.\n",
            "Question: how has air pollution changed over time \n",
            "Answer: Air pollution has generally decreased in many developed countries since the 1970s due to stricter regulations, but it remains a significant issue, particularly in developing countries. The overall trend indicates that air pollution continues to be a major global challenge.\n",
            "Question: can the u.s. increase the number of qualified production workers? \n",
            "Answer: Yes, the U.S. can increase the number of qualified production workers through enhanced education and training programs, adjusted immigration policies, and economic incentives for training.\n",
            "Question: what influence did the wiz have on other media \n",
            "Answer: None\n",
            "Question: why did some women oppose women's suffrage \n",
            "Answer: Concerns about family roles, perceived physical and mental capabilities, existing social influence, and the belief that most women did not desire suffrage.\n",
            "Question: how does the census impact the house of representatives? \n",
            "Answer: The census impacts the House of Representatives by determining each state's allocation of seats based on population.\n",
            "Question: what factors cause dance styles to change over time? \n",
            "Answer: Societal and cultural changes, technological advancements, economic conditions, changes in educational methods and resources, political and legal influences, and international exchange and globalization\n",
            "Question: why is whitewashing so common \n",
            "Answer: Whitewashing is common due to racial discrimination, lack of representation, economic and practical reasons, historical precedent, and pressure to fit in. Addressing it involves supporting independent media and fostering empathy and open communication.\n",
            "Question: how changes to attitude and lifestyle can promote mental wellbeing in scotland \n",
            "Answer: None\n",
            "Question: why is “process” rather than “sale” important in contemporary art-making? \n",
            "Answer: \"Process\" is important in contemporary art-making because it emphasizes the creative journey, experimentation, documentation, and interaction, which are central to many contemporary artistic practices.\n",
            "Question: what environmental issues gave people reason to speak out and demand change in 1970? \n",
            "Answer: Air pollution, water pollution, deforestation, pesticide use, and the creation of the Environmental Protection Agency (EPA) in 1970 were among the major environmental issues that gave people reason to speak out and demand change.\n",
            "Question: are children who are abused become abusers \n",
            "Answer: No, not all children who are abused become abusers.\n",
            "Question: how mental distress manifests itself \n",
            "Answer: Mental distress can manifest itself through various physical and psychological symptoms, such as grinding of teeth, difficulty breathing, excessive sweating, waking up frequently at night, repetitive movements, eating or speaking more quickly, digestive issues, feeling more tired than usual, shoulder and neck tension, and detachment from oneself (dissociation). These symptoms can occur even when a person does not feel overtly stressed or anxious.\n",
            "Question: how did the transcontinental railroad change america \n",
            "Answer: The Transcontinental Railroad changed America by significantly reducing travel time between the East and West, facilitating faster trade and communication, promoting westward expansion, and integrating the western territories more closely into the national economy and culture.\n",
            "Question: why are there limits to freedom of speech \n",
            "Answer: There are limits to freedom of speech due to concerns about harm, national security, public order, privacy, and defamation. These limitations aim to balance the need for free expression with other important societal values.\n",
            "Question: how does solitary confinement violate rights \n",
            "Answer: Solitary confinement violates rights such as the right to freedom from cruel and unusual punishment, the right to freedom and liberty, and the right to protection against arbitrary detention. It can cause severe psychological harm and is often excessive and disproportionate.\n",
            "Question: how did thoreau influence martin luther king \n",
            "Answer: Thoreau's influence on Martin Luther King Jr. came through Thoreau's ideas on civil disobedience and nonviolent resistance, which King adopted and applied in the Civil Rights Movement.\n",
            "Question: how significant were native americans in their development between 1945 to 1992 \n",
            "Answer: Native Americans were significant in their development between 1945 to 1992 through cultural and educational initiatives that helped stabilize communities and foster a sense of identity and responsibility among youth. They also contributed to broader social and political movements by reclaiming and reinstating cultural practices.\n",
            "Question: why have attitudes about sexual aggression varied so widely by culture and by era? \n",
            "Answer: None\n",
            "Question: explain key factors that affect the likelihood of suicide \n",
            "Answer: Key factors that affect the likelihood of suicide include mental health conditions, life events, social support, access to means, age and demographics, history of previous suicide attempts, substance abuse, family history, childhood trauma and abuse, media depiction, gender, racism and discrimination, social media use, and suicide contagion.\n",
            "Question: how would you describe physical and cognitive development in middle childhood and adolescence? \n",
            "Answer: Physical development in middle childhood involves growth spurts and the maturation of motor skills, while in adolescence, there is another phase of rapid growth associated with puberty. Cognitive development transitions from concrete operational thought to formal operational thought, allowing for more abstract thinking and problem-solving.\n",
            "Question: what can we do to make the environment better \n",
            "Answer: Using reusable bags, printing minimally, recycling, using reusable containers, growing food locally, eating locally, reducing energy use, avoiding products from endangered species, eating less meat, and using data science to track climate change are effective ways to make the environment better.\n",
            "Question: why is traffic bad for the environment \n",
            "Answer: Traffic is bad for the environment due to increased air pollution and fuel consumption, leading to issues like air quality degradation, climate change, and resource depletion.\n",
            "Question: how did emancipation proclamation change war \n",
            "Answer: It shifted the focus of the conflict and had significant impacts on both the morale and the manpower of the Union forces.\n",
            "Question: how have zoning ordinances contributed to racial segregation in neighborhoods? \n",
            "Answer: Zoning ordinances have contributed to racial segregation by historically enforcing racial restrictions, creating barriers to integration, limiting housing options, and impacting economic mobility and wealth accumulation.\n",
            "Question: why did italy turn fascist \n",
            "Answer: Italy turned fascist due to the political, economic, and social instability following World War I, combined with the rise of the Socialist Party and the dissatisfaction with the post-war government. The Fascist Party, led by Benito Mussolini, offered a solution through promises of order, stability, and a return to traditional values, appealing to many Italians at the time.\n",
            "Question: how will last week's learning impact your future social work practice? \n",
            "Answer: None\n",
            "Question: why is climate change occurring \n",
            "Answer: Climate change is primarily caused by human activities, especially the emission of greenhouse gases due to burning fossil fuels, deforestation, and industrial processes, which enhance the natural greenhouse effect and lead to global warming.\n",
            "Question: what perspective places greater emphasis on the individual within the family? \n",
            "Answer: Individualism\n",
            "Question: why should the government provide health care \n",
            "Answer: The government should provide health care to ensure public health, maintain economic stability, promote social equity, and fulfill its ethical responsibility to its citizens.\n",
            "Question: what causes poor service delivery \n",
            "Answer: Resource constraints, political and administrative issues, economic factors, and social dynamics\n",
            "Question: why racial discrimination is a problem \n",
            "Answer: Racial discrimination is a problem because it violates human rights, promotes social division, and hinders social progress and unity.\n",
            "Question: why do children want to marry their older siblings \n",
            "Answer: The provided information does not directly address why children would want to marry their older siblings. The context suggests that children often become caregivers for their siblings under challenging circumstances, but it does not discuss marital desires.\n",
            "Question: how do you leverage home language and cultural assets? \n",
            "Answer: To leverage home language and cultural assets, you can use them in education, communication, and personal development by recognizing their value, integrating them into daily activities, and applying them to enhance understanding and communication.\n",
            "Question: how do you think sociology can help us understand society and face its challenges? \n",
            "Answer: Sociology can help us understand society and face its challenges by examining social structures, behaviors, and interactions, and by offering insights and solutions to various societal issues.\n",
            "Question: how managed care control costs \n",
            "Answer: None\n",
            "Question: how are citizens involved in the executive branch \n",
            "Answer: Citizens can influence the executive branch through voting, public opinion, and lobbying, but there are no specific mechanisms for direct citizen involvement in the day-to-day operations of the executive branch.\n",
            "Question: how did the great satchmo and langston hughes influence culture during the roaring 20s? \n",
            "Answer: Louis Armstrong and Langston Hughes both had significant influences during the Roaring 20s. Armstrong transformed jazz music into a more individualistic form, while Hughes was a key voice in the Harlem Renaissance, addressing themes of racial identity and social justice in his poetry.\n",
            "Question: what caused urbanization during the industrial revolution \n",
            "Answer: Improvements in agriculture, transportation, and economic growth\n",
            "Question: how can we stop animal extinction \n",
            "Answer: None\n",
            "Question: what are some ways in which governments address economic and social inequality? \n",
            "Answer: Governments address economic and social inequality through measures such as progressive taxation, social welfare programs, labor law enforcement, educational investments, industry regulation, and subsidies for essential services.\n",
            "Question: what colleges look for in students \n",
            "Answer: Colleges look for a combination of academic achievement, particularly in challenging courses and standardized test scores, extracurricular involvement, leadership, and personal qualities. They also consider a student's potential to contribute positively to the campus community and their demonstrated interest in attending the institution. Each college may prioritize these factors differently.\n",
            "Question: how can a manager determine whether his or her firm needs improvement in control? \n",
            "Answer: None\n",
            "Question: is the capitalistic system of producing goods and services the best economic system? \n",
            "Answer: Whether the capitalistic system of producing goods and services is the best economic system depends on the perspective and the specific context. It excels in fostering innovation, providing opportunities, and promoting efficiency, but it also faces challenges such as inequality, environmental degradation, and monopolistic practices.\n",
            "Question: how is data analysis changing in the world \n",
            "Answer: Data analysis is changing through advancements in future prediction, enhanced security, social good initiatives, technological improvements, and addressing regulatory compliance and privacy concerns.\n",
            "Question: how has law changed over time \n",
            "Answer: None\n",
            "Question: why do scientists accept the big bang theory \n",
            "Answer: Scientists accept the Big Bang theory because it is supported by multiple lines of evidence including the cosmic microwave background radiation, the expansion of the universe, the abundance of light elements, and the large-scale structure of the universe.\n",
            "Question: why doping in sports is bad \n",
            "Answer: Doping in sports is bad because it poses significant health risks, provides an unfair advantage, goes against ethical sportsmanship, has long-term effects, and undermines the integrity of competitions.\n",
            "Question: how big companies avoid taxes \n",
            "Answer: Large companies avoid taxes through strategies such as offshoring profits, accelerated depreciation, tax credits, restricted stock units (RSUs), and managing global intangible low-taxed income (GILTI).\n",
            "Question: why did the hippie movement die \n",
            "Answer: The hippie movement declined due to the end of the Vietnam War, economic challenges, changing social norms, and political disillusionment.\n",
            "Question: how do diversity and inclusion differ? \n",
            "Answer: Diversity and inclusion differ in that diversity focuses on recognizing and valuing differences among people, whereas inclusion focuses on creating an environment where everyone feels valued and is able to participate and contribute fully.\n",
            "Question: how gender stereotypes harm women \n",
            "Answer: Gender stereotypes harm women by limiting their opportunities, lowering expectations, leading to discrimination, causing mental health issues, and reducing support.\n",
            "Question: how artists make money \n",
            "Answer: Direct sales, teaching, working in the art industry, licensing, crowdfunding, social media marketing, and effective networking.\n",
            "Question: why do we need to know our culture \n",
            "Answer: We need to know our culture because it enhances self-awareness, aids in identity formation, improves communication, fosters empathy, and helps in adapting to diverse environments.\n",
            "Question: how digital marketing helps to grow your business \n",
            "Answer: Digital marketing helps grow a business by increasing visibility, enabling targeted advertising, fostering customer engagement, being cost-effective, and providing measurable results.\n",
            "Question: how did mondrian view the relationship between cubism and de stijl? \n",
            "Answer: Piet Mondrian viewed Cubism as a precursor to his own artistic philosophy, seeing it as a step towards pure abstraction, but also recognizing its limitations in achieving this goal. He eventually moved towards a more simplified, geometric style in line with the principles of De Stijl.\n",
            "Question: should schools get involved in cyberbullying \n",
            "Answer: Yes, schools should get involved in addressing cyberbullying. They can create awareness, implement policies, and provide support, while respecting legal and ethical boundaries regarding student privacy and freedom of expression.\n",
            "Question: how airbnb survived the pandemic \n",
            "Answer: Airbnb survived the pandemic through cost cutting, focusing on their core business, providing excellent customer care, supporting their employees, and maintaining long-term optimism.\n",
            "Question: what has happened to venezuela's rate of inflation? \n",
            "Answer: The inflation rate in Venezuela has been extremely high, with the latest reported rate being around 172% in April 2025, and historically reaching as high as 344,509.50% in February 2019.\n",
            "Question: how can chd affect your lifestyle \n",
            "Answer: None\n",
            "Question: how does global warming affect sea life \n",
            "Answer: Global warming affects sea life through ocean warming, coral bleaching, ocean acidification, changes in species distribution and behavior, rising sea levels, and more frequent storms.\n",
            "Question: why did people start using money instead of bartering for their wants and needs? \n",
            "Answer: People started using money instead of bartering because money provided a standardized and more convenient medium of exchange that could represent value in a way that was easier to agree upon and use across different goods and services.\n",
            "Question: how does food bring cultures together \n",
            "Answer: Food brings cultures together through shared traditions, social bonding, cultural exchange, historical and cultural significance, and economic and social impacts.\n",
            "Question: why did hoverboards fail \n",
            "Answer: None\n",
            "Question: how does police corruption affect the public \n",
            "Answer: Police corruption can significantly affect the public by eroding trust in law enforcement, leading to ineffective crime prevention and investigation, and contributing to a sense of injustice among citizens.\n",
            "Question: why is there no long-run trade-off between unemployment and inflation? \n",
            "Answer: There is no long-run trade-off between unemployment and inflation because the economy adjusts to policy changes aimed at reducing unemployment below the natural rate, leading to higher inflation but not lower unemployment in the long run.\n",
            "Question: is terrorism socially constructed \n",
            "Answer: Yes, terrorism is socially constructed.\n",
            "Question: why women are judged for their appearance \n",
            "Answer: Women are judged more for their appearance due to cultural norms, media influence, and societal expectations that place a higher emphasis on physical attractiveness for women, particularly in social and professional contexts.\n",
            "Question: explain how crime leads to social injustices \n",
            "Answer: Crime leads to social injustices through perpetuating inequality, over-policing and racial profiling, mass incarceration, economic impacts, and social stigma.\n",
            "Question: why was the black church so important \n",
            "Answer: The Black Church was so important because it provided spiritual guidance, community support, a platform for activism and resistance, and education and advocacy for social and economic issues.\n",
            "Question: why did congress take over reconstruction \n",
            "Answer: Congress took over Reconstruction primarily to ensure the protection of civil rights for freed slaves, address concerns about the loyalty of Southern states, balance the power between the executive and legislative branches, and respond to the increasing violence and resistance from white Southerners.\n",
            "Question: how do we lower inflation \n",
            "Answer: There are multiple methods to lower inflation, including monetary policies like raising interest rates and reducing the money supply, as well as fiscal policies like decreasing government spending and increasing taxes. Additionally, enhancing productivity and supply chain efficiency can help reduce prices in the long term.\n",
            "Question: why were so many enslaved african americans devout christians \n",
            "Answer: Enslaved African Americans were often devout Christians because religion provided a means of resistance, maintained cultural identity, offered community support, provided hope and a moral framework, and sometimes conveyed messages of hope and rebellion.\n",
            "Question: do deaf people live in a silent world \n",
            "Answer: No, deaf people do not live in a silent world. They experience their environment through various means such as sign language, visual cues, and sometimes residual hearing or vibrations.\n",
            "Question: relationship between public administration and history \n",
            "Answer: The relationship between public administration and history is multifaceted, involving the use of historical context, case studies, and lessons learned to inform and improve modern public administration practices.\n",
            "Question: how does foster care work \n",
            "Answer: Foster care is a system where children in need are placed in temporary homes with foster parents until they can return to their biological families or are adopted.\n",
            "Question: what makes an app successful \n",
            "Answer: simplicity, regular updates, offline functionality, target audience, problem-solving, uniqueness, cross-platform development, core feature focus, user engagement, marketing, free offerings, and analytics\n",
            "Question: does behavior modification work for elderly \n",
            "Answer: Yes, behavior modification techniques, such as applied behavior analysis (ABA), can work effectively for managing behavior issues in elderly individuals.\n",
            "Question: how did christianity come to america \n",
            "Answer: Christianity came to America through the exploration and colonization efforts of European powers, beginning in the late 15th century. Both Catholicism and various forms of Protestantism were introduced during this period.\n",
            "Question: how do native americans view death \n",
            "Answer: None\n",
            "Question: how do the pigs ‘alter reality’ to handle the food crisis? \n",
            "Answer: By manipulating the truth and rewriting history, claiming that there was never a shortage of food or that the pigs are sharing equally, which distracts the other animals from the actual situation and keeps them compliant.\n",
            "Question: how did inventions change people's lives \n",
            "Answer: Inventions have changed people's lives by transforming communication, transportation, access to information, healthcare, education, entertainment, economic development, and environmental awareness.\n",
            "Question: explain how an increase in the price level affects the real value of money \n",
            "Answer: The real value of money decreases when the price level increases.\n",
            "Question: why is the canadian dollar rising \n",
            "Answer: The Canadian dollar is rising due to the weakening U.S. dollar index, the impact of oil prices, interest rate differentials, and positive economic data.\n",
            "Question: how does sensory impairment affect children \n",
            "Answer: Sensory impairment can affect children in multiple ways, including developmental delays, communication issues, social interaction challenges, learning difficulties, emotional well-being, and physical development.\n"
          ]
        }
      ],
      "source": [
        "print(\"Data:\\n\")\n",
        "for idx,instance in enumerate(data):\n",
        "    print(f\"Question: {instance['question']} \\nAnswer: {instance['parsed_agent_answer']}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqhtCAcoieTz"
      },
      "source": [
        "# Other Utils\n",
        "\n",
        "Only run these if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HITUMpOFp_is",
        "outputId": "20273501-2b8c-44e5-b221-ee2032e6f1c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEiqf1JYp6Op"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-oI3Yf-yHwO"
      },
      "outputs": [],
      "source": [
        "indices = [1577, 1722, 165, 1060, 2094, 1990, 1658, 1242, 1952, 1466, 2389, 894, 2067, 570, 1154, 572, 388, 1026, 2181, 2465, 601, 1270, 404, 302, 1352, 1933, 2292, 412, 1449, 1778, 1295, 837, 2263, 1953, 1813, 2135, 1066, 255, 2247, 57, 382, 1633, 4, 2021, 1364, 999, 1332, 257, 782, 2324, 908, 977, 583, 2224, 1834, 373, 329, 1310, 2080, 2004, 446, 1234, 2257, 1192, 511, 2242, 1362, 2213, 832, 2470, 2241, 2406, 1178, 1822, 375, 2442, 1576, 1298, 2357, 991, 1189, 753, 775, 764, 135, 1065, 1951, 282, 367, 533, 612, 158, 328, 2214, 1602, 2148, 1128, 2137, 964, 881]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypZ0unw5oVyN",
        "outputId": "04c968fb-b323-4c95-d952-32a8745497cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'question_id', 'url', 'contents'],\n",
            "    num_rows: 7993\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_documents.jsonl\"\n",
        "dataset = load_dataset('json', data_files=data_path)['train']\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70qTM3EBzBX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0bf23e-88bc-449f-cb7d-9914d0235df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trafilatura\n",
            "  Downloading trafilatura-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2025.10.5)\n",
            "Requirement already satisfied: charset_normalizer>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (3.4.4)\n",
            "Collecting courlan>=1.3.2 (from trafilatura)\n",
            "  Downloading courlan-1.3.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting htmldate>=1.9.2 (from trafilatura)\n",
            "  Downloading htmldate-1.9.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura)\n",
            "  Downloading justext-3.0.2-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (5.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from trafilatura) (2.5.0)\n",
            "Requirement already satisfied: babel>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
            "Collecting tld>=0.13 (from courlan>=1.3.2->trafilatura)\n",
            "  Downloading tld-0.13.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.9.2->trafilatura)\n",
            "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /usr/local/lib/python3.12/dist-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (5.3.1)\n",
            "Collecting lxml_html_clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura)\n",
            "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.17.0)\n",
            "Downloading trafilatura-2.0.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading courlan-1.3.2-py3-none-any.whl (33 kB)\n",
            "Downloading htmldate-1.9.4-py3-none-any.whl (31 kB)\n",
            "Downloading justext-3.0.2-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tld-0.13.1-py2.py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: tld, lxml_html_clean, dateparser, courlan, justext, htmldate, trafilatura\n",
            "Successfully installed courlan-1.3.2 dateparser-1.2.2 htmldate-1.9.4 justext-3.0.2 lxml_html_clean-0.4.3 tld-0.13.1 trafilatura-2.0.0\n",
            "Collecting langid\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from langid) (2.0.2)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=f106e8b724cc4ffd2d7f98a91ddf50733c0941e096243095d6aee8cf67eed08c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/bc/9d/266e27289b9019680d65d9b608c37bff1eff565b001c977ec5\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install trafilatura\n",
        "!pip install langid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indices =\n",
        "filtered_dataset = dataset.filter(lambda example: example['question_id'] in indices)\n",
        "\n",
        "# Check result\n",
        "print(filtered_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "7734f189195f4858902479f1cc249f60",
            "332e3f831bb049199c9ab8a3e8b5f72d",
            "6d15125025bd46dab816b8db6405beb2",
            "cfb2af23d09b43c5a8ac93a61e55c143",
            "2b6ce3d193e943bc82b8512264fd6086",
            "718f7a85f9294146abb1cd2642414a4a",
            "f48fb182310d4532874ead31729cd990",
            "336b4b875b784dcd914622134ef8ce9d",
            "a13307a8b9714699be36a35a9493fc3e",
            "1f6a0d1c7c7e48658c0aa2516dfbd94e",
            "9d373ff63c974ee6b12e22d37ee47944"
          ]
        },
        "id": "zfDVGA-w6ltK",
        "outputId": "926e4f68-2744-4e91-b7ac-5f517f6b7877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/7993 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7734f189195f4858902479f1cc249f60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'question_id', 'url', 'contents'],\n",
            "    num_rows: 297\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_url(url):\n",
        "    # Remove the unwanted substring if present\n",
        "    return url.replace(\"&prev=search&pto=aue\", \"\")\n",
        "\n",
        "# Apply cleaning function to all URLs\n",
        "cleaned_dataset = filtered_dataset.map(\n",
        "    lambda example: {\"url\": clean_url(example[\"url\"])},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "18498158badc4fa9b07a2521cbe3057d",
            "4f863f7200ce4ac284f7dd57ac5708aa",
            "b12d16c97ccf45d0a8295705fa1a5f59",
            "fe752c1ca57e4868840fb5e3c263d3ca",
            "3c1a18a938614014a9c0ac70469abdf1",
            "27be3c158dd740ec8bc3b7ecc98e051f",
            "8e296f33c6354337b08ac038a48f86fa",
            "fe6671f95a5e4f30894b064e7e940042",
            "479f11996f714bd7aecf03080beffee8",
            "2919921abde546239d517ca801049a62",
            "c568385f6bdd4f66ae730254285bff6a"
          ]
        },
        "id": "pasXLMJD6vFC",
        "outputId": "ac401b6b-808e-4e1f-b8bc-54871b084724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/297 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18498158badc4fa9b07a2521cbe3057d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTCVsOVby7zn",
        "outputId": "a16cc649-8233-413a-bf6c-8a43867664e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ERR] Attempt 1/3 for https://www.fcc.gov/media/radio/public-and-broadcasting: HTTPSConnectionPool(host='www.fcc.gov', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 2/3 for https://www.fcc.gov/media/radio/public-and-broadcasting: HTTPSConnectionPool(host='www.fcc.gov', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 3/3 for https://www.fcc.gov/media/radio/public-and-broadcasting: HTTPSConnectionPool(host='www.fcc.gov', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 1/3 for https://www.imf.org/en/Blogs/Articles/2020/06/19/blog-weo-chapter4-migration-to-advanced-economies-can-raise-growth: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 2/3 for https://www.imf.org/en/Blogs/Articles/2020/06/19/blog-weo-chapter4-migration-to-advanced-economies-can-raise-growth: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 3/3 for https://www.imf.org/en/Blogs/Articles/2020/06/19/blog-weo-chapter4-migration-to-advanced-economies-can-raise-growth: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ERR] Attempt 1/3 for https://www.imf.org/en/Publications/fandd/issues/2021/09/quantum-computings-possibilitiesand-perils-deodoro: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 2/3 for https://www.imf.org/en/Publications/fandd/issues/2021/09/quantum-computings-possibilitiesand-perils-deodoro: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=20)\n",
            "[ERR] Attempt 3/3 for https://www.imf.org/en/Publications/fandd/issues/2021/09/quantum-computings-possibilitiesand-perils-deodoro: HTTPSConnectionPool(host='www.imf.org', port=443): Read timed out. (read timeout=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trafilatura.core:discarding data: None\n",
            "WARNING:trafilatura.core:discarding data: None\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "from datasets import Dataset\n",
        "from pathlib import Path\n",
        "import trafilatura\n",
        "\n",
        "# ---------- Config ----------\n",
        "BASE = Path(\"./output\")\n",
        "RAW = BASE / \"raw_html\"\n",
        "RAW.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# List of common User-Agents\n",
        "UA_LIST = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.6 Safari/605.1.15\",\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) Gecko/20100101 Firefox/119.0\",\n",
        "]\n",
        "\n",
        "TIMEOUT = 20\n",
        "SLEEP_MIN = 0.5\n",
        "SLEEP_MAX = 1.5\n",
        "MAX_CHARS = 4000\n",
        "OVERLAP = 300\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "# ---------- Helper Functions ----------\n",
        "def clean_url(url: str) -> str:\n",
        "    return url.replace(\"&prev=search&pto=aue\", \"\")\n",
        "\n",
        "def fetch_url_to_raw(doc_id: str, url: str) -> Path:\n",
        "    \"\"\"Fetch URL with retries and save raw HTML. Returns Path or None.\"\"\"\n",
        "    raw_fp = RAW / f\"{doc_id}.html\"\n",
        "    if raw_fp.exists():\n",
        "        return raw_fp\n",
        "\n",
        "    if not url.startswith(\"http\"):\n",
        "        url = \"https://\" + url.lstrip(\"/\")\n",
        "\n",
        "    session = requests.Session()\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            ua = random.choice(UA_LIST)\n",
        "            session.headers.update({\"User-Agent\": ua})\n",
        "            r = session.get(clean_url(url), timeout=TIMEOUT)\n",
        "            ctype = r.headers.get(\"Content-Type\", \"\").lower()\n",
        "\n",
        "            if r.status_code == 200 and r.text and (\"text/html\" in ctype or \"charset\" in ctype or ctype == \"\"):\n",
        "                raw_fp.write_text(r.text, encoding=\"utf-8\", errors=\"ignore\")\n",
        "                return raw_fp\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"[ERR] Attempt {attempt}/{MAX_RETRIES} for {url}: {e}\")\n",
        "        # Wait before retrying\n",
        "        time.sleep(1 * attempt)\n",
        "\n",
        "    return None\n",
        "\n",
        "def clean_html_to_text(html_text: str) -> str:\n",
        "    \"\"\"Extract readable text using trafilatura with regex fallback.\"\"\"\n",
        "    text = trafilatura.extract(html_text, include_comments=False, include_tables=False)\n",
        "    if not text:\n",
        "        text = re.sub(r\"<[^>]+>\", \" \", html_text)\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text or \"\"\n",
        "\n",
        "def slice_text_with_title(text: str, title: str, max_chars=MAX_CHARS, overlap=OVERLAP):\n",
        "    \"\"\"Slice text into overlapping chunks, prepending title.\"\"\"\n",
        "    pos = 0\n",
        "    n = len(text)\n",
        "    while pos < n:\n",
        "        available_chars = max_chars - len(title) - 2 if title else max_chars\n",
        "        end = min(pos + available_chars, n)\n",
        "        chunk_body = text[pos:end]\n",
        "        chunk_text = f\"{title}\\n\\n{chunk_body}\" if title else chunk_body\n",
        "        yield chunk_text\n",
        "        if end == n:\n",
        "            break\n",
        "        pos = end - overlap\n",
        "\n",
        "# ---------- Main Function ----------\n",
        "def build_chunked_dataset(dataset: Dataset) -> Dataset:\n",
        "    chunk_ids = []\n",
        "    contents = []\n",
        "\n",
        "    for example in dataset:\n",
        "        doc_id = str(example['id'])\n",
        "        url = example['url']\n",
        "        title = example.get('title', '').strip()\n",
        "\n",
        "        raw_fp = fetch_url_to_raw(doc_id, url)\n",
        "        time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))\n",
        "\n",
        "        if raw_fp:\n",
        "            html_text = raw_fp.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "            text = clean_html_to_text(html_text)\n",
        "            if text:\n",
        "                for idx, chunk in enumerate(slice_text_with_title(text, title)):\n",
        "                    chunk_ids.append(f\"{doc_id}#p{idx:04d}\")\n",
        "                    contents.append(chunk)\n",
        "                continue\n",
        "\n",
        "        # Add None placeholder if fetch failed\n",
        "        chunk_ids.append(doc_id)\n",
        "        contents.append(None)\n",
        "\n",
        "    return Dataset.from_dict({\"id\": chunk_ids, \"contents\": contents})\n",
        "\n",
        "# ---------- Use Case ----------\n",
        "# filtered_dataset should already have 'id', 'url', 'title'\n",
        "chunked_dataset = build_chunked_dataset(filtered_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datamap = {instance['id']:idx for idx, instance in enumerate(filtered_dataset)}"
      ],
      "metadata": {
        "id": "QL0WnhXKPDLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset[datamap[611]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3_n3EacPTMB",
        "outputId": "e328be8e-92e9-4ae4-9fa2-41bd01e8c574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 611,\n",
              " 'question_id': 158,\n",
              " 'url': 'https://www.defense.gov/News/Releases/Release/Article/3326875/department-of-defense-releases-the-presidents-fiscal-year-2024-defense-budget/',\n",
              " 'contents': 'Statement by Secretary of Defense Lloyd J. Austin III on the President\\'s Fiscal Year 2024 Budget\\n\\n\"The FY 2024 budget is the most strategy-driven request we\\'ve ever produced from the Department of Defense. And as our National Defense Strategy makes clear, the People\\'s Republic of China (PRC) is our pacing challenge. This budget seeks to meet this critical challenge today, tomorrow, and into the future by providing the resources today to continue to implement our National Defense Strategy and keep our nation safe while delivering a combat credible Joint Force that is the most lethal, resilient, agile, and responsive in the world.\\n\\nAs the PRC races to modernize its military, this budget will sharpen our edge by making critical investments across all timeframes, theaters, and domains. Among numerous important actions that bolster our combat credibility in the short term, this budget makes the Department\\'s largest-ever investments in readiness and procurement – and our largest investment in research and development.\\n\\nTo sustain our military advantage over China, it makes major investments in integrated air and missile defenses and operational energy efficiency, as well as in our air dominance, our maritime dominance, and in munitions, including hypersonics. This budget includes the largest ever request for the Pacific Deterrence Initiative, which we are using to invest in advanced capabilities, new operational concepts, and more resilient force posture in the Indo-Pacific region. It also enables groundbreaking posture initiatives in Guam, Mariana Islands, the Philippines, Japan, and Australia.\\n\\nWe are also investing in resiliency in key parts of the defense supply chain to ensure stability in the industrial base\\'s ability to produce what the Joint Force needs. That includes working closely with Congress to secure multi-year procurement authorities—and allow us to meet the needs of tomorrow. And this year\\'s budget also increases funding to continue modernizing all three legs of our nuclear triad to maintain a safe, secure, and effective strategic deterrent against advanced and persistent threats around the world.\\n\\nThe United States has the strongest military in the world because we have the best team in the world. And we owe it to the brave men and women who serve to take care of our people and their families. So this budget includes the largest military and civilian pay raise in decades, and it builds on progress we\\'ve already made to make life a little easier by lowering every day costs, including by reducing the cost of goods in the commissary and making childcare more accessible and affordable.\\n\\nAs the Secretary of Defense, my priority will always be to ensure that our forces are ready and resilient, and that our military remains the world\\'s preeminent fighting force, today, tomorrow, and for generations to come. I look forward to working with Congress to support the President\\'s request.\"\\n\\nOn March 9, 2023, the Biden-Harris Administration submitted to Congress a proposed Fiscal Year (FY) 2024 Budget request of $842 billion for the Department of Defense (DoD), an increase of $26 billion over FY 2023 levels and $100 billion more than FY 2022. The FY 2024 Defense Budget is driven by strategy and provides us with the capabilities and investments to advance the Secretary\\'s three key priorities: defending the nation, taking care of our people, and succeeding through teamwork.\\n\\nTo achieve these priorities, this budget request links strategy to resources to continue executing our 2022 National Defense Strategy (NDS), which aligns with the President\\'s National Security Strategy. These guiding documents determine the vision and direction of the Department of Defense in what the President has called the \"decisive decade.\" The NDS outlines the Department\\'s defense and security priorities:\\n\\n*   Defending the homeland, paced to the growing multi-domain threat posed by the People\\'s Republic of China (PRC).\\n*   Deterring strategic attacks against the United States, our allies, and our partners.\\xa0\\n*   Deterring aggression, while being prepared to prevail in conflict when necessary - prioritizing the PRC challenge in the Indo-Pacific region, then the Russia challenge in Europe.\\n*   Building a resilient joint force and defense ecosystem.\\n\\nThe NDS positions the U.S. military to meet growing threats through integrated deterrence, campaigning, and taking actions that build enduring advantages. The FY 2024 DoD budget request of $842 billion enables the Department to successfully advance these defense and security goals by purposefully aligning resources to best position our warfighters, allies, and partners for success.\\n\\n**Integrated Deterrence**\\n\\nThe FY 2024 President\\'s Budget allows the DoD to invest in capabilities that will ensure we maintain a ready, lethal, and combat-credible joint force with a laser focus on China as the Department\\'s pacing challenge and addressing the acute threat posed by Russia. The budget makes critical investments to revitalize the defense industrial base, drive innovation, and take care of our people. The FY 2024 budget request once again includes a record investment in research, development, test, and evaluation (RDT&E) \\xa0of $145 billion. This budget also funds $170 billion for procurement, the largest in history. Combined, these investments will ensure combat-credible forces across all domains.\\n\\nSecretary Austin has called deterrence the \"cornerstone of defense.\" In FY 2024, the DoD supports the concept of Integrated Deterrence by ensuring combat-credible forces and a safe, secure, and effective nuclear deterrent. Investments across all domains include:\\n\\n*   $61.1 billion for air power to continue developing, modernizing, and procuring lethal air forces, including a focus on fighters, including F-22, F-35, F-15EX; the B-21 bomber, mobility aircraft, including KC-46A; specialized support aircraft; and unmanned aircraft systems.\\xa0\\n*   $48.1 billion for sea power including new construction of nine battle force fleet ships and continued funding for the incremental construction of Ford class nuclear powered aircraft carriers and Columbia ballistic missile submarines.\\xa0\\n*   $13.9 billion for land power supporting modernization of Army and Marine Corps combat equipment: Armored Multi-Purpose Vehicle, Amphibious Combat Vehicle, and Optionally Manned Fighting Vehicle.\\n*   $37.7 billion for Nuclear Enterprise Modernization, including:\\n    *   Continued development and procurement of the B-21 program - $5.3 billion.\\xa0\\n    *   Production of the second Columbia ballistic missile submarine - $6.2 billion.\\n    *   First year advance procurement funding for the LGM-35A Sentinel program.\\xa0\\n    *   Development efforts supporting nuclear command, control, and communications systems.\\xa0\\n*   $29.8 billion to enhance Missile Defeat and Defense, including:\\n    *   Development of the Next Generation Interceptor for Ground-Based Midcourse Defense, and extending the service life of the current interceptor fleet.\\xa0\\n    *   Increased investments in regional missile defense network with Patriot Missiles, a Lower Tier Air and Missile Defense Sensor, additional Short-Range Air Defense Battalions, and hypersonic weaponry and defenses.\\n    *   Development of a resilient overhead persistent infrared capability in low earth orbit and medium earth orbit, and continuing to field the Next Generation Polar program.\\n    *   Integration of the THAAD Battery capability into the Army\\'s Integrated Air and Missile Defense Battle Command System planning process, and continuing development of the eighth THAAD Battery.\\xa0\\n    *   Advanced innovation technologies and demonstrations, including those involving cyber operations and hypersonic strike capabilities.\\n    *   Defense of Guam against the missile threat from China - $1.5 billion.\\n*   $11.0 billion to deliver a mix of highly lethal precision weapons. Investments include:\\xa0\\n    *   Continued development, testing, and procurement of hypersonic missiles and other long-range fires.\\n    *   Extensive hypersonic prototyping efforts.\\n    *   Procurement of 24 hypersonic missiles.\\xa0\\n    *   Maximizing Joint Air-to-Surface Standoff Missile, and Long-Range Anti-Ship Missile, and Standard Missile 6 capacity through multi-year procurements.\\n*   $33.3 billion in vital space capabilities, resilient architectures, and enhanced space command and control. Investments include:\\n    *   Development of new proliferated resilient missile warning / missile tracking architectures, Next-Gen Overhead Persistent Infrared space and associated ground architectures - $5.0 billion.\\n    *   Position, navigation, and timing for GPS III Follow-On satellite support and Next-Generation Operational Control System development - $1.3 billion.\\n    *   15 launch vehicles and launch range upgrades - $3.0 billion.\\n    *   Protected Tactical, Wideband, and Narrowband robust secure/survivable/jam-resistant capabilities, and Space Development Agency proliferated Low Earth Orbit Transport Layer development - $4.7 billion.\\n\\n**Campaigning**\\n\\nThe budget prioritizes ongoing force readiness, ensuring the urgent competing demands of the present are carefully balanced with preparing for the future. \\xa0The Department\\'s FY 2024 budget continues to prioritize joint force readiness, investing $146.0 billion to strategically build and maintain warfighting forces and capabilities. Investments to fund a high level of force readiness include:\\n\\n*   Army readiness - $28.8 billion.\\n*   Navy readiness - $52.8 billion.\\n*   Marine Corps readiness - $4.4 billion.\\n*   Air Force readiness - $39.9 billion.\\n*   Space Force readiness - $3.3 billion.\\n*   U.S. Special Operations Command readiness - $9.7 billion.\\n*   Joint Capabilities - $7.1 billion.\\n\\nThe FY 2024 budget includes $9.1 billion in support of the Pacific Deterrence Initiative (PDI), a 40 percent increase from FY 2023. The effort includes resilient and distributed air basing, new missile warning and tracking architecture, construction to enable enhanced posture, funding for defense of Guam and Hawaii, and multinational information sharing, training, and experimentation.\\n\\nIn Europe, the FY 2024 budget allows the Department to continue to counter Russian aggression against NATO allies and partners. Investments include:\\n\\n*   European Deterrence Initiative - $3.6 billion.\\n*   NATO Military Contribution - $601.0 million.\\n*   NATO Security Investment Program - $293.0 million.\\n*   Ukraine Security Assistance Initiative - $300.0 million.\\n\\n**Building Enduring Advantages**\\n\\nAs highlighted in both the NSS and NDS, the Department\\'s people are its most valuable asset. The DoD aims to support its all-volunteer military and civilian workforce by focusing on economic stabilization and supporting families. Investments to Take Care of People include:\\n\\n*   5.2 percent pay increase for military and civilian personnel, the highest pay raise in over 20 years for our military and over 40 years for our civilians.\\n*   $193.0 million to ease military moves, through enhancements for lodging expenses and dislocation allowances.\\xa0\\n*   Over $212.0 million in additional funding for commissaries to ensure our service members have food savings of over 25 percent compared to the local marketplace.\\xa0\\n*   $33.0 million to standardize a 50 percent childcare employee discount for the first child of our child development program direct-care workers.\\xa0\\n*   $90.4 million to expand full-day pre-kindergarten at DoD Education Activity schools for eligible dependents.\\xa0\\n*   $1.9 billion to support family housing to provide safe and quality residences to service members and their families.\\n*   $209 million to provide full spectrum support for suicide prevention, including counseling services for at-risk Service members as well as efforts to reduce stigma and barriers to \"seeking help.\"\\n    *   Currently assessing over 120 recommendations made by the Suicide Prevention & Response Independent Review Committee\\n*   The Department is investing in Sexual Assault Prevention and Response, including $637 million for the continued implementation of the 82 recommendations made by the Independent Review Commission on Sexual Assault in the Military as approved and funding for the Sexual Assault Prevention and Response Education and Training Center of Excellence.\\n\\nThe FY 2024 budget continues the DoD\\'s progress to modernize and innovate, including $145.0 billion in RDT&E, a 4.0 percent increase over the FY 2023 enacted level. Investments include:\\n\\n*   Science and Technology - $17.8 billion.\\n*   Artificial Intelligence - $1.8 billion.\\xa0\\n*   Rapid Defense Experimentation Reserve - $687.0 million.\\n*   Joint All Domain Command and Control (JADC2) - $1.4 billion to transform warfighting capability by delivering information advantage at the speed of relevance across all domains and partners.\\n*   Office of Strategic Capital, established to enable the Department to attract and scale private capital in our most critical technologies - $115.0 million.\\n\\nThe FY 2024 budget request includes $30.6 billion for munitions, an increase of $5.8 billion above last year\\'s request, for both conventional ammunition and Precision Guided Munitions, including:\\n\\n*   Ammunition - $5.6 billion.\\n*   Tactical Missiles - $17.3 billion.\\n*   Strategic Missiles - $7.3 billion.\\n*   Technology Development - $600.0 million.\\n*   Munitions Industrial Base over $1.0 billion.\\n\\nThis budget leverages unprecedented use of multi-year procurement (MYP) authorities provided by Congress to deliver critical munitions affordably, while bolstering our inventories and providing a more predictable demand signal to the industry. \\xa0This strategy will facilitate industrial production efficiencies because the industry would be incentivized to organize in a more cost-effective manner. MYPs in the FY 2024 budget request include:\\n\\n*   Naval Strike Missile.\\xa0\\n*   RIM-174 Standard Missile.\\xa0\\n*   Advanced Medium Range Air-to-Air Missile.\\n*   Long Range Anti-Ship Missile.\\n*   Joint Air-to-Surface Standoff Missile - Extended Range.\\n\\nThe FY 2024 budget request invests $5.1 billion to increase resilience of military bases and the critical capabilities housed there against threats like extreme weather and cyber-attacks. \\xa0Also, the budget invests in improving the fuel efficiency of DoD operational platforms, enhancing capability, mitigating logistics risk, and making our forces more agile, and survivable in this complex and changing environment. \\xa0Some investments include:\\n\\n*   $3.7 billion for Installation Resilience and Adaptation, including cyber-secure microgrids with backup power and battery storage, and electrical transmission and distribution improvements.\\n*   $271 million for Army to modernize next-generation combat vehicles with silent watch and mobility, increased operational duration and more on-board electrical power.\\n*   $84 million for prototyping new platforms like blended wing body aircraft that targets a 30% improvement in aerodynamic efficiency to increase range and payload.\\n\\nContinuing to build on prior investments, the FY 2024 budget includes $19.2 billion for Facilities Sustainment, Restoration, and Modernization and $16.7 billion in Construction and Family Housing programs supporting our people, enhancing deterrence, and improving critical operational infrastructure. Investments include:\\n\\n*   Facilities that support readiness improvements - $4.6 billion.\\n*   Projects advancing the European Deterrence Initiative, Pacific Deterrence Initiative, and the Ground Based Strategic Deterrent program - $2.4 billion.\\n*   Critical naval infrastructure improvements through the Shipyard Infrastructure Optimization Program - $2.3 billion.\\xa0\\n*   Family housing - $1.9 billion.\\n*   Construction of quality-of-life and medical facilities - $1.5 billion.\\xa0\\n\\nThe Department is committed to acting as responsible stewards of taxpayer funds. In October 2022, Deputy Secretary of Defense Kathleen Hicks established and initiated implementation of the Defense Management Performance Improvement (PI) Framework to define, identify, track and report on measures critical to realize the DoD\\'s Strategic Management Plan. These efforts enable the Department to modernize capabilities and better meet NDS priorities. Key areas of the PI include:\\n\\n*   Enabling Future Capabilities Transition - Strategically divesting vulnerable platforms and systems that can no longer be affordably modernized or maintained to enable the transition to a more modern and capable force.\\xa0\\n*   Continuous Process Improvements - Enhancing management practices, streamlining processes, and adjusting systems within the Components\\' organizational levels.\\xa0\\n*   Reforms - Larger-scale and time-bounded efforts designed to remediate structural and/or process gaps within the DoD\\'s existing business model. \\xa0\\n*   Transformation - Altering the DoD\\'s business model—often through reorganization, the creation of new entities/capabilities, and innovative management practices—to fundamentally improve how the Department functions and delivers services. \\xa0\\n\\nThe FY 2024 Defense Budget will help position the Department to best support its people and Allies through this \"decisive decade\" and ensure the United States is prepared to meet the challenges of today, tomorrow and into the future.\\n\\nThe entire budget proposal and additional materials are available at: [https://www.defense.gov/cj](https://www.defense.gov/cj)',\n",
              " 'fetched_html': '',\n",
              " 'cleaned_text': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_dataset[22])"
      ],
      "metadata": {
        "id": "BI2JEGLeO_J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunked_dataset[22])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVTu-sq_O3Vi",
        "outputId": "69861ef2-2b8e-4bae-a6a4-e549ef376df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '525', 'contents': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset[datamap[525]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZke2rNUTP_R",
        "outputId": "03cf5a99-86ca-4f59-ceee-611d7a9dde69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 525,\n",
              " 'question_id': 135,\n",
              " 'url': 'https://www.weforum.org/agenda/2018/05/200-years-of-karl-marx/',\n",
              " 'contents': \"On the 200th anniversary of Karl Marx’s birth on May 5, 1818, it isn’t far-fetched to suggest that his predictions have been falsified, his theories discredited, and his ideas rendered obsolete. So why should we care about his legacy in the twenty-first century?\\n\\nFrom 1949, when Mao Zedong’s communists triumphed in China’s civil war, until the collapse of the Berlin Wall 40 years later, Karl Marx’s historical significance was unsurpassed. Nearly four of every ten people on earth lived under governments that claimed to be Marxist, and in many other countries Marxism was the dominant ideology of the left, while the policies of the right were often based on how to counter Marxism.[1](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nOnce communism collapsed in the Soviet Union and its satellites, however, Marx’s influence plummeted. On the 200th anniversary of Marx’s birth on May 5, 1818, it isn’t far-fetched to suggest that his predictions have been falsified, his theories discredited, and his ideas rendered obsolete. So why should we care about his legacy in the twenty-first century?[](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nMarx’s reputation was severely damaged by the atrocities committed by regimes that called themselves Marxist, although there is no evidence that Marx himself would have supported such crimes. But communism collapsed largely because, as practiced in the Soviet bloc and in China under Mao, it failed to provide people with a standard of living that could compete with that of most people in the capitalist economies.\\n\\nThese failures do not reflect flaws in Marx’s depiction of communism, because Marx never depicted it: he showed not the slightest interest in the details of how a communist society would function. Instead, the failures of communism point to a deeper flaw: Marx’s false view of human nature.[](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nThere is, Marx thought, no such thing as an inherent or biological human nature. The human essence is, he wrote in his Theses on Feuerbach, “the ensemble of the social relations.” It follows then, that if you change the social relations – for example, by changing the economic basis of society and abolishing the relationship between capitalist and worker – people in the new society will be very different from the way they were under capitalism.\\n\\n[![Image 1: ](https://assets.weforum.org/editor/BaTfOSiy1DpI-rwFF_3rlAkLI3WunGXoPladHER6ImY.jpg)](https://commons.wikimedia.org/wiki/Karl_Marx#/media/File:Marx3.jpg)\\n\\nImage: Wikimedia Commons\\n\\nMarx did not arrive at this conviction through detailed studies of human nature under different economic systems. It was, rather, an application of Hegel’s view of history. According to Hegel, the goal of history is the liberation of the human spirit, which will occur when we all understand that we are part of a universal human mind. Marx transformed this “idealist” account into a “materialist” one, in which the driving force of history is the satisfaction of our material needs, and liberation is achieved by class struggle. The working class will be the means to universal liberation because it is the negation of private property, and hence will usher in collective ownership of the means of production.[](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nOnce workers owned the means of production collectively, Marx thought, the “springs of cooperative wealth” would flow more abundantly than those of private wealth – so abundantly, in fact, that distribution would cease to be a problem. That is why he saw no need to go into detail about how income or goods would be distributed. In fact, when Marx read a proposed platform for a merger of two German socialist parties, he described phrases like “fair distribution” and “equal right” as “obsolete verbal rubbish.” They belonged, he thought, to an era of scarcity that the revolution would bring to an end.[](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nThe Soviet Union proved that abolishing private ownership of the means of production does not change human nature. Most humans, instead of devoting themselves to the common good, continue to seek power, privilege, and luxury for themselves and those close to them. Ironically, the clearest demonstration that the springs of private wealth flow more abundantly than those of collective wealth can be seen in the history of the one major country that still proclaims its adherence to Marxism.[](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nUnder Mao, most Chinese lived in poverty. China’s economy started to grow rapidly only after 1978, when Mao’s successor, Deng Xiaoping (who had proclaimed that, “It doesn’t matter if a cat is black or white, as long as it catches mice”) allowed private enterprises to be established. Deng’s reforms eventually lifted 800 million people out of extreme poverty, but also created a society with greater income inequality than any European country (and much greater than the United States). Although China still proclaims that it is building “socialism with Chinese characteristics,” it is not easy to see what is socialist, let alone Marxist, about its economy.[5](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\n##### Have you read?\\n\\n*   ##### [It isn't social media that's shielding you from different political views. Here's why](https://www.weforum.org/agenda/2017/04/stuck-in-a-bubble-heres-why-you-shouldnt-blame-social-media)\\n    \\n*   ##### [Capitalism is losing support. It is time for a new deal](https://www.weforum.org/agenda/2017/11/capitalism-losing-support-we-need-a-new-deal)\\n    \\n*   ##### [Our shared values are under attack. They are also our best defence](https://www.weforum.org/agenda/2018/01/our-shared-values-are-under-attack-they-are-also-our-best-defence)\\xa0\\n    \\n\\nIf China is no longer significantly influenced by Marx’s thought, we can conclude that in politics, as in economics, he is indeed irrelevant. Yet his intellectual influence remains. His materialist theory of history has, in an attenuated form, become part of our understanding of the forces that determine the direction of human society. We do not have to believe that, as Marx once incautiously put it, the hand-mill gives us a society with feudal lords, and the steam-mill a society with industrial capitalists. In other writings, Marx suggested a more complex view, in which there is interaction among all aspects of society.[](https://www.project-syndicate.org/commentary/karl-marx-200th-birthday-by-peter-singer-2018-05##)\\n\\nThe most important takeaway from Marx’s view of history is negative: the evolution of ideas, religions, and political institutions is not independent of the tools we use to satisfy our needs, nor of the economic structures we organize around those tools, and the financial interests they create. If this seems too obvious to need stating, it is because we have internalized this view. In that sense, we are all Marxists now.\\n\",\n",
              " 'fetched_html': '',\n",
              " 'cleaned_text': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title = [\n",
        "    \"What is Karl Marx's legacy 200 years on from his birth?\",\n",
        "    \"Department of Defense Releases the President's Fiscal Year 2024 Defense Budget\",\n",
        "    \"Lobbying and influence\",\n",
        "    \"Corporate Capture Threatens Democratic Government\",\n",
        "    \"These Fossil Fuel Industry Tactics Are Fueling Democratic Backsliding\",\n",
        "    \"RAINN’s National Sexual Assault Hotline\",\n",
        "    \"The Public and Broadcasting\",\n",
        "    \"Executive Order on Improving the Nation's Cybersecurity\",\n",
        "    \"About the Affordable Care Act\",\n",
        "    \"Fact Sheet: Celebrating the Affordable Care Act\",\n",
        "    \"H.R.3590 - Patient Protection and Affordable Care Act\",\n",
        "    \"Police Function\",\n",
        "    \"my wife says my relationship with my coworker is inappropriate\",\n",
        "    \"Why hasn't the steam engine been reborn for modern cars?\",\n",
        "    \"Your Protections Against Discrimination Based on Conscience and Religion\",\n",
        "    \"Deforestation and forest degradation\",\n",
        "    \"Migration to Advanced Economies Can Raise Growth\",\n",
        "    \"Rehabilitate or punish?\",\n",
        "    \"Donald Trump's Anti-Environment Agenda is a Racist Agenda\",\n",
        "    \"Declaration on the Right and Responsibility of Individuals, Groups and Organs of Society to Promote and Protect Universally Recognized Human Rights and Fundamental Freedoms\",\n",
        "    \"Yes, Democrats Have Called Some Elections Illegitimate. GOP Election Denialism Is Far Worse.\",\n",
        "    \"S.Hrg. 107-1050 — HUMAN CLONING\",\n",
        "    \"Raising the Minimum Wage\",\n",
        "    \"Iraq: A Morally Justified Resort to War\",\n",
        "    \"Trump or Clinton: how would other countries have voted?\",\n",
        "    \"One Person, One Vote: How Does the Electoral College Work?\",\n",
        "    \"Home Instruction vs Home Schooling\",\n",
        "    \"Powering the Digital Economy: Opportunities and Risks of Artificial Intelligence in Finance\",\n",
        "    \"Quantum Computing's Possibilities and Perils\",\n",
        "    \"Quantum leap: why the next wave of computers will change the world\",\n",
        "    \"Refugees and Asylees in the United States\",\n",
        "    \"Should Polygamy Be Permitted in the United States?\",\n",
        "    \"Privacy Preference Center\", #can use following\n",
        "    \"Freedom Versus Security: Can We Find the Right Balance?\",\n",
        "    \"Places\",\n",
        "    \"Earnings of Men Aged 20–59, by Race and Ethnicity, 2005–2020\",\n",
        "    \"The Unspoken Privilege of Being White\",\n",
        "    \"Explaining White Privilege to a Broke White Person\",\n",
        "    \"Can the President Pardon Himself?\",\n",
        "    \"Clues from the Upcoming California Primary\",\n",
        "    \"Bernie Sanders (D)\",\n",
        "    \"DONALD J. TRUMP, PETITIONER v. CYRUS R. VANCE, JR., IN HIS OFFICIAL CAPACITY AS DISTRICT ATTORNEY OF THE COUNTY OF NEW YORK, ET AL., RESPONDENTS\",\n",
        "    \"Senate Select Committee on Intelligence: Statement for the Record Worldwide Threat Assessment of the US Intelligence Community\",\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "_i8Q5hJji2rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Config (same as before) ----------\n",
        "MAX_CHARS = 4000\n",
        "OVERLAP = 300\n",
        "\n",
        "def slice_text_with_title(text: str, title: str, max_chars=MAX_CHARS, overlap=OVERLAP):\n",
        "    \"\"\"Slice text into overlapping chunks, prepending title.\"\"\"\n",
        "    pos = 0\n",
        "    n = len(text)\n",
        "    while pos < n:\n",
        "        available_chars = max_chars - len(title) - 2 if title else max_chars\n",
        "        end = min(pos + available_chars, n)\n",
        "        chunk_body = text[pos:end]\n",
        "        chunk_text = f\"{title}\\n\\n{chunk_body}\" if title else chunk_body\n",
        "        yield chunk_text\n",
        "        if end == n:\n",
        "            break\n",
        "        pos = end - overlap\n",
        "\n",
        "# ---------- Add excluded samples back ----------\n",
        "new_ids = []\n",
        "new_contents = []\n",
        "\n",
        "cnt = 0\n",
        "for idx, instance in enumerate(chunked_dataset):\n",
        "    if instance['contents'] is None:\n",
        "        # Retrieve the original entry\n",
        "        data_entry = filtered_dataset[datamap[int(instance['id'])]]\n",
        "        data_title = title[cnt].strip()  # your saved title\n",
        "        data_contents = data_entry['contents']  # the full text\n",
        "\n",
        "        # Slice into overlapping chunks\n",
        "        for chunk_idx, chunk_text in enumerate(slice_text_with_title(data_contents, data_title)):\n",
        "            new_ids.append(f\"{instance['id']}#p{chunk_idx:04d}\")\n",
        "            new_contents.append(chunk_text)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "# ---------- Merge with existing dataset ----------\n",
        "from datasets import concatenate_datasets, Dataset\n",
        "\n",
        "# Convert new chunks to a Dataset\n",
        "new_dataset = Dataset.from_dict({\"id\": new_ids, \"contents\": new_contents})\n",
        "\n",
        "# Filter out the old None entries\n",
        "existing_dataset = Dataset.from_dict({\n",
        "    \"id\": [i['id'] for i in chunked_dataset if i['contents'] is not None],\n",
        "    \"contents\": [i['contents'] for i in chunked_dataset if i['contents'] is not None]\n",
        "})\n",
        "\n",
        "# Merge\n",
        "chunked_dataset = concatenate_datasets([existing_dataset, new_dataset])\n"
      ],
      "metadata": {
        "id": "940F54QOBZN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_json = \"/content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_corpus.jsonl\"\n",
        "chunked_dataset.to_json(output_json, orient=\"records\", lines=True)\n",
        "print(f\"[OK] Saved chunked dataset to {output_json}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "be697fdd4dd84e148b32e8434c0c4c15",
            "b724809d993944fca46a61034301ab7e",
            "b1864f5e87a94f3e906e44c56612b2e0",
            "2943de39c8f649cfbdc593aa63956cfc",
            "2872e0fe01b144ceb472decf1a37c556",
            "e3c1e2810e6d40319628db00665cab1d",
            "68ad509abd984d9a9da5c0002b319ae8",
            "0f17f320b7514694ab089a6ae3ba3545",
            "cbb253bad87249dca6ac1bb4bbaa80a0",
            "6a39b397a4f6498686ac770acafdeb94",
            "a175381fcd0e44e8896acda53f0dd7b3"
          ]
        },
        "id": "0QFrSGXgncJT",
        "outputId": "9a22d7a4-3e4f-4211-8ade-51825ccdda43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be697fdd4dd84e148b32e8434c0c4c15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Saved chunked dataset to /content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_corpus.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XNZNVJxnqIE"
      },
      "source": [
        "Select 100 eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "718988606a244019a446de824e356a5f",
            "3de37f9ce87942d48822cd98bd3372dd",
            "b25c30ec23f44b4cb92c3caa5272776c",
            "23dcbd1a01f8434bacfc6df98e6e6598",
            "1dc912fca3d8480c8a5a89cc61d5642c",
            "af0c6494351849039ee56b3d050fd908",
            "81f3fa708ca4407894ac761f52a5212c",
            "192f41d841cc4ac196301c5d756e3524",
            "7c185fef74b449bb9972ca486bed49b1",
            "df3405821f0749e7b8d4ac5890c3fea1",
            "9c53021120b64f9f8e207288c0a51f95"
          ]
        },
        "id": "kvUl1vxrnq8z",
        "outputId": "34d7533d-c20f-41f8-ab51-bddc2a5c3cc2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "718988606a244019a446de824e356a5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1577, 1722, 165, 1060, 2094, 1990, 1658, 1242, 1952, 1466, 2389, 894, 2067, 570, 1154, 572, 388, 1026, 2181, 2465, 601, 1270, 404, 302, 1352, 1933, 2292, 412, 1449, 1778, 1295, 837, 2263, 1953, 1813, 2135, 1066, 255, 2247, 57, 382, 1633, 4, 2021, 1364, 999, 1332, 257, 782, 2324, 908, 977, 583, 2224, 1834, 373, 329, 1310, 2080, 2004, 446, 1234, 2257, 1192, 511, 2242, 1362, 2213, 832, 2470, 2241, 2406, 1178, 1822, 375, 2442, 1576, 1298, 2357, 991, 1189, 753, 775, 764, 135, 1065, 1951, 282, 367, 533, 612, 158, 328, 2214, 1602, 2148, 1128, 2137, 964, 881]\n",
            "\n",
            "✅ Saved 100 random samples to /content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_eval_100.jsonl\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "# --- Configuration ---\n",
        "data_path = \"/content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_eval.jsonl\"\n",
        "num_samples = 100\n",
        "seed = 0\n",
        "\n",
        "# --- Load dataset ---\n",
        "dataset = load_dataset('json', data_files=data_path)['train']\n",
        "\n",
        "# --- Set random seed and sample indices ---\n",
        "random.seed(seed)\n",
        "indices = random.sample(range(len(dataset)), num_samples)\n",
        "print(indices)\n",
        "\n",
        "# --- Extract the 100 random samples ---\n",
        "sampled_data = [dataset[i] for i in indices]\n",
        "\n",
        "# # --- (Optional) Print a few examples ---\n",
        "# for i, sample in enumerate(sampled_data[:5]):\n",
        "#     print(f\"{i+1}. {sample.get('question', 'No question field found')}\")\n",
        "\n",
        "# --- (Optional) Save to a JSONL file ---\n",
        "import json\n",
        "output_path = \"/content/drive/MyDrive/CS329X_Project/datasets/DebateQA/DebateQA_eval_100.jsonl\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    for entry in sampled_data:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "print(f\"\\n✅ Saved 100 random samples to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEb5UgbDTwAr"
      },
      "source": [
        "Convert Corpus to JSONL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rewki1ZHMHNc",
        "outputId": "80a4ea7b-4a44-4760-8174-1bd1280b2229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled 209831 entries\n",
            "Saved sampled data to /content/drive/MyDrive/CS329X_Project/search_agent_code/wikipedia_corpus/mini-wiki-18.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Wiki Corpus:\n",
        "\n",
        "import gzip\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "input_file = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/wikipedia_corpus/wiki-18.jsonl.gz\"\n",
        "output_file = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/wikipedia_corpus/mini-wiki-18.jsonl\"\n",
        "\n",
        "# Sampling fraction\n",
        "sample_fraction = 0.01  # 1%\n",
        "\n",
        "sampled_data = []\n",
        "\n",
        "# Open in binary mode, decode line by line safely\n",
        "with gzip.open(input_file, 'rb') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            decoded_line = line.decode('utf-8', errors='ignore')  # ignore bad bytes\n",
        "            if decoded_line.strip():  # skip empty lines\n",
        "                if random.random() < sample_fraction:\n",
        "                    sampled_data.append(json.loads(decoded_line))\n",
        "        except Exception as e:\n",
        "            continue  # skip lines that cannot be decoded or parsed\n",
        "\n",
        "print(f\"Sampled {len(sampled_data)} entries\")\n",
        "\n",
        "# Save sampled data as regular .jsonl\n",
        "with open(output_file, 'w', encoding='utf-8') as f_out:\n",
        "    for entry in sampled_data:\n",
        "        f_out.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "print(f\"Saved sampled data to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7KlNx1oTqLY"
      },
      "source": [
        "Convert Corpus to JSONL (old. ignore)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "bf2df248b10f40cfbcde2fa3f6f3f4aa",
            "356ff4409a3848ec906dd73be9aeb3b4",
            "8bbef98562d54da49831d48acaa1fe64",
            "7e1ac0807a494629ad1aab8fcdc12afe",
            "3dddd929f5a94e0dab9a1a4b0cdbf8f0",
            "41c4366e03ee42c3833de92a190d6608",
            "9ba405ec0ec94b9b919e9f774f2052d2",
            "80bee39103d74788938d214a74e00ea2",
            "5da5cda27d7441888da01a33072a9ba3",
            "ef94f445452548faad79ab22a7b255bc",
            "cd74426a788843f9bd553c35da0e7875"
          ]
        },
        "id": "pwGz728BrP1F",
        "outputId": "ea9e92eb-e366-42b2-c415-f420606a916f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf2df248b10f40cfbcde2fa3f6f3f4aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset features: {'set': List(Value('string'))}\n",
            "First item: {'set': ['The greatest example has been in his present job ( then , Minister for Foreign Affairs ) , where he has perforce concentrated on Anglo-Irish relations and , in particular Northern Ireland ( .', 'The greatest example has been in his present job ( then , Minister for Foreign Affairs ) , where he has perforce concentrated on Anglo-Irish relations and , in particular the North ( i.e. , Northern Ireland ) .']}\n",
            "✅ Dataset saved as JSONL to: /content/drive/MyDrive/CS329X_Project/search_agent_code/mini_retrieval_dataset/corpus.jsonl\n"
          ]
        }
      ],
      "source": [
        "# from datasets import load_dataset\n",
        "# import json\n",
        "# import os\n",
        "\n",
        "# # -----------------------------\n",
        "# # Paths\n",
        "# # -----------------------------\n",
        "# arrow_file = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/mini_retrieval_dataset/train/data-00000-of-00001.arrow\"\n",
        "# output_dir = \"/content/drive/MyDrive/CS329X_Project/search_agent_code/mini_retrieval_dataset/\"\n",
        "# output_file = os.path.join(output_dir, \"corpus.jsonl\")\n",
        "\n",
        "# # Create output directory if it doesn't exist\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# # -----------------------------\n",
        "# # Load .arrow dataset\n",
        "# # -----------------------------\n",
        "# dataset = load_dataset(\n",
        "#     \"arrow\",\n",
        "#     data_files=arrow_file,\n",
        "#     split=\"train\"\n",
        "# )\n",
        "\n",
        "# # Inspect dataset fields\n",
        "# print(\"Dataset features:\", dataset.features)\n",
        "# print(\"First item:\", dataset[0])\n",
        "\n",
        "# # -----------------------------\n",
        "# # Convert to JSONL\n",
        "# # -----------------------------\n",
        "# with open(output_file, \"w\") as f:\n",
        "#     for item in dataset:\n",
        "#         # If title and text exist, combine them into 'contents' for retrieval pipeline\n",
        "#         if \"title\" in item and \"text\" in item:\n",
        "#             new_item = {\n",
        "#                 \"contents\": f\"{item['title']}\\n{item['text']}\",\n",
        "#                 \"title\": item[\"title\"],\n",
        "#                 \"text\": item[\"text\"]\n",
        "#             }\n",
        "#         else:\n",
        "#             # Fallback: dump all fields\n",
        "#             new_item = item\n",
        "\n",
        "#         json.dump(new_item, f)\n",
        "#         f.write(\"\\n\")\n",
        "\n",
        "# print(f\"✅ Dataset saved as JSONL to: {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "356ff4409a3848ec906dd73be9aeb3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c4366e03ee42c3833de92a190d6608",
            "placeholder": "​",
            "style": "IPY_MODEL_9ba405ec0ec94b9b919e9f774f2052d2",
            "value": "Generating train split: "
          }
        },
        "3dddd929f5a94e0dab9a1a4b0cdbf8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c4366e03ee42c3833de92a190d6608": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da5cda27d7441888da01a33072a9ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e1ac0807a494629ad1aab8fcdc12afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef94f445452548faad79ab22a7b255bc",
            "placeholder": "​",
            "style": "IPY_MODEL_cd74426a788843f9bd553c35da0e7875",
            "value": " 102225/0 [00:00&lt;00:00, 926089.41 examples/s]"
          }
        },
        "80bee39103d74788938d214a74e00ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8bbef98562d54da49831d48acaa1fe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80bee39103d74788938d214a74e00ea2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5da5cda27d7441888da01a33072a9ba3",
            "value": 1
          }
        },
        "9ba405ec0ec94b9b919e9f774f2052d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf2df248b10f40cfbcde2fa3f6f3f4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_356ff4409a3848ec906dd73be9aeb3b4",
              "IPY_MODEL_8bbef98562d54da49831d48acaa1fe64",
              "IPY_MODEL_7e1ac0807a494629ad1aab8fcdc12afe"
            ],
            "layout": "IPY_MODEL_3dddd929f5a94e0dab9a1a4b0cdbf8f0"
          }
        },
        "cd74426a788843f9bd553c35da0e7875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef94f445452548faad79ab22a7b255bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7734f189195f4858902479f1cc249f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_332e3f831bb049199c9ab8a3e8b5f72d",
              "IPY_MODEL_6d15125025bd46dab816b8db6405beb2",
              "IPY_MODEL_cfb2af23d09b43c5a8ac93a61e55c143"
            ],
            "layout": "IPY_MODEL_2b6ce3d193e943bc82b8512264fd6086"
          }
        },
        "332e3f831bb049199c9ab8a3e8b5f72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_718f7a85f9294146abb1cd2642414a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_f48fb182310d4532874ead31729cd990",
            "value": "Filter: 100%"
          }
        },
        "6d15125025bd46dab816b8db6405beb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336b4b875b784dcd914622134ef8ce9d",
            "max": 7993,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a13307a8b9714699be36a35a9493fc3e",
            "value": 7993
          }
        },
        "cfb2af23d09b43c5a8ac93a61e55c143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f6a0d1c7c7e48658c0aa2516dfbd94e",
            "placeholder": "​",
            "style": "IPY_MODEL_9d373ff63c974ee6b12e22d37ee47944",
            "value": " 7993/7993 [00:00&lt;00:00, 11452.21 examples/s]"
          }
        },
        "2b6ce3d193e943bc82b8512264fd6086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "718f7a85f9294146abb1cd2642414a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f48fb182310d4532874ead31729cd990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "336b4b875b784dcd914622134ef8ce9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13307a8b9714699be36a35a9493fc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f6a0d1c7c7e48658c0aa2516dfbd94e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d373ff63c974ee6b12e22d37ee47944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18498158badc4fa9b07a2521cbe3057d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f863f7200ce4ac284f7dd57ac5708aa",
              "IPY_MODEL_b12d16c97ccf45d0a8295705fa1a5f59",
              "IPY_MODEL_fe752c1ca57e4868840fb5e3c263d3ca"
            ],
            "layout": "IPY_MODEL_3c1a18a938614014a9c0ac70469abdf1"
          }
        },
        "4f863f7200ce4ac284f7dd57ac5708aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27be3c158dd740ec8bc3b7ecc98e051f",
            "placeholder": "​",
            "style": "IPY_MODEL_8e296f33c6354337b08ac038a48f86fa",
            "value": "Map: 100%"
          }
        },
        "b12d16c97ccf45d0a8295705fa1a5f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe6671f95a5e4f30894b064e7e940042",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_479f11996f714bd7aecf03080beffee8",
            "value": 297
          }
        },
        "fe752c1ca57e4868840fb5e3c263d3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2919921abde546239d517ca801049a62",
            "placeholder": "​",
            "style": "IPY_MODEL_c568385f6bdd4f66ae730254285bff6a",
            "value": " 297/297 [00:00&lt;00:00, 1611.91 examples/s]"
          }
        },
        "3c1a18a938614014a9c0ac70469abdf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27be3c158dd740ec8bc3b7ecc98e051f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e296f33c6354337b08ac038a48f86fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe6671f95a5e4f30894b064e7e940042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "479f11996f714bd7aecf03080beffee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2919921abde546239d517ca801049a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c568385f6bdd4f66ae730254285bff6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be697fdd4dd84e148b32e8434c0c4c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b724809d993944fca46a61034301ab7e",
              "IPY_MODEL_b1864f5e87a94f3e906e44c56612b2e0",
              "IPY_MODEL_2943de39c8f649cfbdc593aa63956cfc"
            ],
            "layout": "IPY_MODEL_2872e0fe01b144ceb472decf1a37c556"
          }
        },
        "b724809d993944fca46a61034301ab7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c1e2810e6d40319628db00665cab1d",
            "placeholder": "​",
            "style": "IPY_MODEL_68ad509abd984d9a9da5c0002b319ae8",
            "value": "Creating json from Arrow format: 100%"
          }
        },
        "b1864f5e87a94f3e906e44c56612b2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f17f320b7514694ab089a6ae3ba3545",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbb253bad87249dca6ac1bb4bbaa80a0",
            "value": 3
          }
        },
        "2943de39c8f649cfbdc593aa63956cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a39b397a4f6498686ac770acafdeb94",
            "placeholder": "​",
            "style": "IPY_MODEL_a175381fcd0e44e8896acda53f0dd7b3",
            "value": " 3/3 [00:01&lt;00:00,  1.67ba/s]"
          }
        },
        "2872e0fe01b144ceb472decf1a37c556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c1e2810e6d40319628db00665cab1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ad509abd984d9a9da5c0002b319ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f17f320b7514694ab089a6ae3ba3545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbb253bad87249dca6ac1bb4bbaa80a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a39b397a4f6498686ac770acafdeb94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a175381fcd0e44e8896acda53f0dd7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "718988606a244019a446de824e356a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3de37f9ce87942d48822cd98bd3372dd",
              "IPY_MODEL_b25c30ec23f44b4cb92c3caa5272776c",
              "IPY_MODEL_23dcbd1a01f8434bacfc6df98e6e6598"
            ],
            "layout": "IPY_MODEL_1dc912fca3d8480c8a5a89cc61d5642c"
          }
        },
        "3de37f9ce87942d48822cd98bd3372dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0c6494351849039ee56b3d050fd908",
            "placeholder": "​",
            "style": "IPY_MODEL_81f3fa708ca4407894ac761f52a5212c",
            "value": "Generating train split: "
          }
        },
        "b25c30ec23f44b4cb92c3caa5272776c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192f41d841cc4ac196301c5d756e3524",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c185fef74b449bb9972ca486bed49b1",
            "value": 1
          }
        },
        "23dcbd1a01f8434bacfc6df98e6e6598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3405821f0749e7b8d4ac5890c3fea1",
            "placeholder": "​",
            "style": "IPY_MODEL_9c53021120b64f9f8e207288c0a51f95",
            "value": " 2492/0 [00:02&lt;00:00, 1184.48 examples/s]"
          }
        },
        "1dc912fca3d8480c8a5a89cc61d5642c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af0c6494351849039ee56b3d050fd908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f3fa708ca4407894ac761f52a5212c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "192f41d841cc4ac196301c5d756e3524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7c185fef74b449bb9972ca486bed49b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df3405821f0749e7b8d4ac5890c3fea1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c53021120b64f9f8e207288c0a51f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8660deed496c47e5821e9cd144305f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be5bad62020c4b90b75281c9c9c371fc",
              "IPY_MODEL_b82f129c1a334ac0892da96ef933444c",
              "IPY_MODEL_ff5d484ead2a4e1c8ffb16688cea9a7e"
            ],
            "layout": "IPY_MODEL_95812e572488406d81cdd68135276dfe"
          }
        },
        "be5bad62020c4b90b75281c9c9c371fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34c774ab738544fa9bd0478c119c09be",
            "placeholder": "​",
            "style": "IPY_MODEL_c7d54fcf616848c9ac14f0be47173e4b",
            "value": "Generating train split: "
          }
        },
        "b82f129c1a334ac0892da96ef933444c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a5d6d11ee646f0a1c2c394200b0fae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52d178b313914beb9197b40508852907",
            "value": 1
          }
        },
        "ff5d484ead2a4e1c8ffb16688cea9a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738fcf7c4e284da3b5ed15a61a68779d",
            "placeholder": "​",
            "style": "IPY_MODEL_86f670f427d744a0b4025d77b954ce44",
            "value": " 14812/0 [00:00&lt;00:00, 22999.77 examples/s]"
          }
        },
        "95812e572488406d81cdd68135276dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c774ab738544fa9bd0478c119c09be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d54fcf616848c9ac14f0be47173e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a5d6d11ee646f0a1c2c394200b0fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52d178b313914beb9197b40508852907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "738fcf7c4e284da3b5ed15a61a68779d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f670f427d744a0b4025d77b954ce44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0be4525aaa06411dbd023134175cfc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc55da3fca6c4187a0953dd6069518c3",
              "IPY_MODEL_f145e8a8816f4501b17a30f409f14093",
              "IPY_MODEL_454a2ee4042c45bfa5cdb618a4341431"
            ],
            "layout": "IPY_MODEL_a8b1d829c2b945e691ef6fdf2da0232d"
          }
        },
        "bc55da3fca6c4187a0953dd6069518c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f33bcbcb994472883848fbbee38222",
            "placeholder": "​",
            "style": "IPY_MODEL_1a38998bbce3454f874e98b22451fdb5",
            "value": "config.json: 100%"
          }
        },
        "f145e8a8816f4501b17a30f409f14093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537a9c9d8f804539a6af523056e675e2",
            "max": 650,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c55a0cbabbdb4435b817f6f4dcd60378",
            "value": 650
          }
        },
        "454a2ee4042c45bfa5cdb618a4341431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b988783880a145109303f20df3d96fca",
            "placeholder": "​",
            "style": "IPY_MODEL_1de6ba139e234df5a1a973515d472caf",
            "value": " 650/650 [00:00&lt;00:00, 87.5kB/s]"
          }
        },
        "a8b1d829c2b945e691ef6fdf2da0232d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f33bcbcb994472883848fbbee38222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a38998bbce3454f874e98b22451fdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "537a9c9d8f804539a6af523056e675e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55a0cbabbdb4435b817f6f4dcd60378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b988783880a145109303f20df3d96fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1de6ba139e234df5a1a973515d472caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2c32915bf944ea6a3e96d9d130eb737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2136642b1cf414f820c291c30c61a82",
              "IPY_MODEL_65f4bd71b7934aaf9471275fc7885cdb",
              "IPY_MODEL_66b8446b54a2474899e742e3b5f7d02a"
            ],
            "layout": "IPY_MODEL_e7dbae1a1ff94d30b6e9d83866e7af4f"
          }
        },
        "d2136642b1cf414f820c291c30c61a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8bfb655e174817943099aa25db6f29",
            "placeholder": "​",
            "style": "IPY_MODEL_24161fe75a7a4a24aaf1a47a9546cdfc",
            "value": "model.safetensors: 100%"
          }
        },
        "65f4bd71b7934aaf9471275fc7885cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa8cca3be9434bd6acf6b9f5aff43cdb",
            "max": 437955512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa26fbc501d94f8aa97628a384fc90ed",
            "value": 437955512
          }
        },
        "66b8446b54a2474899e742e3b5f7d02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_060d5dd7caaf432786c4ae49a1ffa9dd",
            "placeholder": "​",
            "style": "IPY_MODEL_ab2771a615c6410f8dcaf59fb8692691",
            "value": " 438M/438M [00:02&lt;00:00, 257MB/s]"
          }
        },
        "e7dbae1a1ff94d30b6e9d83866e7af4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8bfb655e174817943099aa25db6f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24161fe75a7a4a24aaf1a47a9546cdfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa8cca3be9434bd6acf6b9f5aff43cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa26fbc501d94f8aa97628a384fc90ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "060d5dd7caaf432786c4ae49a1ffa9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2771a615c6410f8dcaf59fb8692691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93df9e0895944c57aeaffa3fb2b61d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c676df9c24b841eaa83eec8d784b51da",
              "IPY_MODEL_2d6d8b85dece4426b104383a24b75796",
              "IPY_MODEL_0ce1092eeca24e99ab32118317fa54b3"
            ],
            "layout": "IPY_MODEL_b9d6b40e6b1c4000a5123375c0cfe169"
          }
        },
        "c676df9c24b841eaa83eec8d784b51da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c47d1aa6c446afa9c897e2e06e8cf7",
            "placeholder": "​",
            "style": "IPY_MODEL_89ec1416d1674074a9ea63bbfb4cf3cc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2d6d8b85dece4426b104383a24b75796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_986e50d8a4d44e89aa4466a918774845",
            "max": 314,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0c437959ebb43ffa6c2ee61844d3262",
            "value": 314
          }
        },
        "0ce1092eeca24e99ab32118317fa54b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46b3cd93ee33490e9758fc0ccf5bfb88",
            "placeholder": "​",
            "style": "IPY_MODEL_533fb484453b4d378ef5cd90773cb93f",
            "value": " 314/314 [00:00&lt;00:00, 43.9kB/s]"
          }
        },
        "b9d6b40e6b1c4000a5123375c0cfe169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c47d1aa6c446afa9c897e2e06e8cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ec1416d1674074a9ea63bbfb4cf3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "986e50d8a4d44e89aa4466a918774845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c437959ebb43ffa6c2ee61844d3262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46b3cd93ee33490e9758fc0ccf5bfb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533fb484453b4d378ef5cd90773cb93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bedf4f5c3ce0487dbd61819c924241a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b13661c38a9c49138805b77e99647cb4",
              "IPY_MODEL_6791973c269848a48049a794007e8726",
              "IPY_MODEL_ef8a545e4a6544209565d229afcb2d9d"
            ],
            "layout": "IPY_MODEL_9a0074fe9dd843f98627329d80103d61"
          }
        },
        "b13661c38a9c49138805b77e99647cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870aee9f4c9e4b13bf31064034bbb704",
            "placeholder": "​",
            "style": "IPY_MODEL_b13754541c854f4d8187bbdc61dca290",
            "value": "vocab.txt: "
          }
        },
        "6791973c269848a48049a794007e8726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6827513b8f574b3085098c7e17798f74",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d27f1187ea624a178f89bd7d6fa82192",
            "value": 1
          }
        },
        "ef8a545e4a6544209565d229afcb2d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c4a7eee48574c2c998db314ae99d493",
            "placeholder": "​",
            "style": "IPY_MODEL_73e41db060e14462a2a3224b84f9b758",
            "value": " 232k/? [00:00&lt;00:00, 12.2MB/s]"
          }
        },
        "9a0074fe9dd843f98627329d80103d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870aee9f4c9e4b13bf31064034bbb704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13754541c854f4d8187bbdc61dca290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6827513b8f574b3085098c7e17798f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d27f1187ea624a178f89bd7d6fa82192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c4a7eee48574c2c998db314ae99d493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e41db060e14462a2a3224b84f9b758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d063054d71e40e49900ab705f57f2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86cd087d5b8f448da3660f172517d169",
              "IPY_MODEL_00f11cdb2bc84e4f9eb82431ac4992bd",
              "IPY_MODEL_de2a0b9da26940d1a9898a0db8cfc6d0"
            ],
            "layout": "IPY_MODEL_a7105427c82942be8a68206b65bd18f2"
          }
        },
        "86cd087d5b8f448da3660f172517d169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_817a36082cee4b0cbba5cd66a4578ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_a11002b97a504a4baf05ea6b768e7405",
            "value": "tokenizer.json: "
          }
        },
        "00f11cdb2bc84e4f9eb82431ac4992bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_095254d538354f34b0814c7351e65fd1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a47708b6c9fc435fb24e285dd82e9200",
            "value": 1
          }
        },
        "de2a0b9da26940d1a9898a0db8cfc6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19eb3d8a259d4c2d9dc710d6483d4bed",
            "placeholder": "​",
            "style": "IPY_MODEL_6371ae310b3f43c680581d122666a8bc",
            "value": " 711k/? [00:00&lt;00:00, 52.1MB/s]"
          }
        },
        "a7105427c82942be8a68206b65bd18f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "817a36082cee4b0cbba5cd66a4578ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11002b97a504a4baf05ea6b768e7405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "095254d538354f34b0814c7351e65fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a47708b6c9fc435fb24e285dd82e9200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19eb3d8a259d4c2d9dc710d6483d4bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6371ae310b3f43c680581d122666a8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dea30fce4b449589dbcef1df2b3743f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5341eeb40e9f482ea36f77485ddf51a0",
              "IPY_MODEL_19e2969215f645b198a9af3b08be0549",
              "IPY_MODEL_80d75000ab1c43bda2a58239ad8a72f4"
            ],
            "layout": "IPY_MODEL_037a12007c334a6ebbfb5a1d385f7eeb"
          }
        },
        "5341eeb40e9f482ea36f77485ddf51a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1035105d74604950929cfb4fb2b46188",
            "placeholder": "​",
            "style": "IPY_MODEL_cd6d8482f9344b6aaeba70a1422d35f0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "19e2969215f645b198a9af3b08be0549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12bf5a430064405b88af85238e585876",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9549df74dfc54c2a985b7bf45d614658",
            "value": 125
          }
        },
        "80d75000ab1c43bda2a58239ad8a72f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ecd176a498f4ced8832f5a0f925eed4",
            "placeholder": "​",
            "style": "IPY_MODEL_6198003c51b049bf8a09adc4e33a1f46",
            "value": " 125/125 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "037a12007c334a6ebbfb5a1d385f7eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1035105d74604950929cfb4fb2b46188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6d8482f9344b6aaeba70a1422d35f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12bf5a430064405b88af85238e585876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9549df74dfc54c2a985b7bf45d614658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ecd176a498f4ced8832f5a0f925eed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6198003c51b049bf8a09adc4e33a1f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "422080f5471545f38f53e758b003ea57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e6251b8b4474d4d9f3d40c3c0ae1716",
              "IPY_MODEL_f8362ffc7a6644f2be326ef3a08c4a64",
              "IPY_MODEL_72f2bb290dc84293924173bed45641c6"
            ],
            "layout": "IPY_MODEL_f0dd0a1d68cb41959916dfa54667ec32"
          }
        },
        "2e6251b8b4474d4d9f3d40c3c0ae1716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df454d16f374a59a656404f096e2099",
            "placeholder": "​",
            "style": "IPY_MODEL_d64f01efd9ba4be7b0314fcedf64a82d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f8362ffc7a6644f2be326ef3a08c4a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d6cc728e30431f885c648fa6cc7ebe",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b643596b9be4467287da3125c6c6fccf",
            "value": 4
          }
        },
        "72f2bb290dc84293924173bed45641c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bd5b70980364bb19b084b360177828f",
            "placeholder": "​",
            "style": "IPY_MODEL_2dd06ee52a554783ae0ce572e4fbe1eb",
            "value": " 4/4 [04:52&lt;00:00, 61.56s/it]"
          }
        },
        "f0dd0a1d68cb41959916dfa54667ec32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df454d16f374a59a656404f096e2099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64f01efd9ba4be7b0314fcedf64a82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89d6cc728e30431f885c648fa6cc7ebe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b643596b9be4467287da3125c6c6fccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bd5b70980364bb19b084b360177828f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dd06ee52a554783ae0ce572e4fbe1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4754cf65636476bb2f0475e391fbf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d10cefb3df3441e84002eebdee6d59b",
              "IPY_MODEL_9c424e06fbde4352ab979c10bc182c96",
              "IPY_MODEL_cfedc9cd4b0b48afaf1358f729f3118f"
            ],
            "layout": "IPY_MODEL_c9ab2c4172fc4a99ad442368fe49fdd0"
          }
        },
        "7d10cefb3df3441e84002eebdee6d59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0111cd9426d4469f905bc3fd7d1a6afa",
            "placeholder": "​",
            "style": "IPY_MODEL_d30cea283ad74809b8bafde7660a071c",
            "value": "Generating train split: "
          }
        },
        "9c424e06fbde4352ab979c10bc182c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8444ff87de21454ea9881ce80d3de421",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8461a26991004e23be431d5c79df902f",
            "value": 1
          }
        },
        "cfedc9cd4b0b48afaf1358f729f3118f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50471c8d3552400aae99763499b6a503",
            "placeholder": "​",
            "style": "IPY_MODEL_b56b8ac28d64456cb517d1aae8d6a4a5",
            "value": " 500/0 [00:00&lt;00:00, 39913.06 examples/s]"
          }
        },
        "c9ab2c4172fc4a99ad442368fe49fdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0111cd9426d4469f905bc3fd7d1a6afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30cea283ad74809b8bafde7660a071c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8444ff87de21454ea9881ce80d3de421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8461a26991004e23be431d5c79df902f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50471c8d3552400aae99763499b6a503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56b8ac28d64456cb517d1aae8d6a4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}